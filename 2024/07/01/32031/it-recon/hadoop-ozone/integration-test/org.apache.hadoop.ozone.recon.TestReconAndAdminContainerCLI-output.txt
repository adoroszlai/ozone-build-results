2024-07-01 06:00:13,154 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:13,301 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 126 ms to scan 7 urls, producing 158 keys and 370 values
2024-07-01 06:00:13,444 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:13,449 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(207)) - ServiceID for StorageContainerManager is null
2024-07-01 06:00:13,458 [main] WARN  ha.SCMHANodeDetails (SCMHANodeDetails.java:validateSCMHAConfig(180)) - Default/Configured value of config ozone.scm.ratis.enable conflicts with the expected value. Default/Configured: true. Expected: false. Falling back to the expected value. Current State of SCM: SCM is running without Ratis. Ratis SCM -> Non Ratis SCM is not supported.
2024-07-01 06:00:13,459 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(212)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-07-01 06:00:14,041 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(339)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:14,173 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(171)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:14,182 [main] INFO  utils.LeakDetector (LeakDetector.java:start(73)) - Starting leak detector thread ManagedRocksObject0.
2024-07-01 06:00:14,360 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-07-01 06:00:14,361 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-07-01 06:00:14,406 [main] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-07-01 06:00:14,419 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-07-01 06:00:14,576 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(369)) - upgrade localId to 113750153625600000
2024-07-01 06:00:14,577 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(379)) - upgrade delTxnId to 0
2024-07-01 06:00:14,583 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(396)) - upgrade containerId to 0
2024-07-01 06:00:14,586 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(433)) - upgrade CertificateId to 2
2024-07-01 06:00:14,588 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(240)) - Init the HA SequenceIdGenerator.
2024-07-01 06:00:14,636 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-07-01 06:00:14,649 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-07-01 06:00:14,651 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-07-01 06:00:14,660 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-07-01 06:00:14,674 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-07-01 06:00:14,674 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-07-01 06:00:14,680 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2024-07-01 06:00:14,680 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(127)) - Starting RatisPipelineUtilsThread.
2024-07-01 06:00:14,684 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(65)) - Starting BackgroundPipelineScrubber Service.
2024-07-01 06:00:14,686 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2024-07-01 06:00:14,692 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(65)) - Starting ExpiredContainerReplicaOpScrubber Service.
2024-07-01 06:00:14,696 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2024-07-01 06:00:14,719 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-07-01 06:00:14,719 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-07-01 06:00:14,743 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2024-07-01 06:00:14,828 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(296)) - Starting Replication Monitor Thread.
2024-07-01 06:00:14,831 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2024-07-01 06:00:14,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:14,841 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(91)) - containers with one replica threshold count 0
2024-07-01 06:00:14,845 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(176)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2024-07-01 06:00:14,848 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(193)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-07-01 06:00:14,909 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(440)) - SCM start with adminUsers: [runner]
2024-07-01 06:00:15,112 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-07-01 06:00:15,135 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:15,160 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15002
2024-07-01 06:00:15,167 [Socket Reader #1 for port 15002] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15002
2024-07-01 06:00:15,207 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-07-01 06:00:15,213 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:15,213 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15001
2024-07-01 06:00:15,214 [Socket Reader #1 for port 15001] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15001
2024-07-01 06:00:15,247 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-07-01 06:00:15,257 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:15,258 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15000
2024-07-01 06:00:15,259 [Socket Reader #1 for port 15000] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15000
2024-07-01 06:00:15,319 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2024-07-01 06:00:15,320 [main] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-07-01 06:00:15,323 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1538)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15000
2024-07-01 06:00:15,387 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2024-07-01 06:00:15,395 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2024-07-01 06:00:15,395 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2024-07-01 06:00:15,556 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(204)) - RPC server for Client  is listening at /0.0.0.0:15000
2024-07-01 06:00:15,557 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15000: starting
2024-07-01 06:00:15,558 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:15,573 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1551)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15001
2024-07-01 06:00:15,574 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(167)) - RPC server for Block Protocol is listening at /0.0.0.0:15001
2024-07-01 06:00:15,576 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:15,577 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15001: starting
2024-07-01 06:00:15,668 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15002
2024-07-01 06:00:15,671 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:15,672 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15002: starting
2024-07-01 06:00:15,703 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-43b08e6f-fbc8-49de-b9d0-a34c234775b3: Started
2024-07-01 06:00:15,705 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for scm at: http://0.0.0.0:15003
2024-07-01 06:00:15,706 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:00:15,729 [main] INFO  util.log (Log.java:initialized(170)) - Logging initialized @3748ms to org.eclipse.jetty.util.log.Slf4jLog
2024-07-01 06:00:15,818 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:00:15,824 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.scm is not defined
2024-07-01 06:00:15,829 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:00:15,832 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-07-01 06:00:15,832 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:00:15,832 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:00:15,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:15,862 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/webserver
2024-07-01 06:00:15,863 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15003
2024-07-01 06:00:15,864 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:00:15,892 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:00:15,892 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:00:15,894 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-07-01 06:00:15,904 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@54e680fe{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:00:15,906 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@53da2aec{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-07-01 06:00:15,943 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@55cc4c61{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-07-01 06:00:15,949 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@46ff1aad{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-07-01 06:00:15,949 [main] INFO  server.Server (Server.java:doStart(415)) - Started @3968ms
2024-07-01 06:00:15,951 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2024-07-01 06:00:15,951 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2024-07-01 06:00:15,952 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of scm listening at http://0.0.0.0:15003
2024-07-01 06:00:15,955 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:16,016 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for OMAudit to [].
2024-07-01 06:00:16,068 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-07-01 06:00:16,072 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15004
2024-07-01 06:00:16,072 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2024-07-01 06:00:16,072 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2024-07-01 06:00:16,076 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:16,080 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = QUOTA (version = 6), software layout = QUOTA (version = 6)
2024-07-01 06:00:16,154 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 72 ms to scan 2 urls, producing 188 keys and 546 values
2024-07-01 06:00:16,158 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2024-07-01 06:00:16,159 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2024-07-01 06:00:16,161 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:16,317 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-07-01 06:00:16,340 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-07-01 06:00:16,473 [main] INFO  om.OzoneManager (OzoneManager.java:<init>(678)) - OM start with adminUsers: [runner]
2024-07-01 06:00:16,485 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:16,502 [main] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-07-01 06:00:16,714 [main] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(812)) - S3 Multi-Tenancy is disabled
2024-07-01 06:00:16,741 [main] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(179)) - Ozone filesystem snapshot feature is enabled.
2024-07-01 06:00:16,748 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-07-01 06:00:16,787 [main] INFO  utils.NativeLibraryLoader (NativeLibraryLoader.java:loadLibrary(111)) - Loading Library: ozone_rocksdb_tools
2024-07-01 06:00:16,788 [main] ERROR snapshot.SnapshotDiffManager (SnapshotDiffManager.java:initNativeLibraryForEfficientDiff(287)) - Native Library for raw sst file reading loading failed.
org.apache.hadoop.hdds.utils.NativeLibraryNotLoadedException: Unable to load library ozone_rocksdb_tools from both java.library.path & resource file libozone_rocksdb_tools.so from jar.
	at org.apache.hadoop.hdds.utils.db.managed.ManagedRawSSTFileReader.loadLibrary(ManagedRawSSTFileReader.java:40)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.initNativeLibraryForEfficientDiff(SnapshotDiffManager.java:285)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.<init>(SnapshotDiffManager.java:259)
	at org.apache.hadoop.ozone.om.OmSnapshotManager.<init>(OmSnapshotManager.java:286)
	at org.apache.hadoop.ozone.om.OzoneManager.instantiateServices(OzoneManager.java:864)
	at org.apache.hadoop.ozone.om.OzoneManager.<init>(OzoneManager.java:688)
	at org.apache.hadoop.ozone.om.OzoneManager.createOm(OzoneManager.java:775)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createOM(MiniOzoneClusterImpl.java:689)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createAndStartSingleOM(MiniOzoneClusterImpl.java:673)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:535)
	at org.apache.hadoop.ozone.recon.TestReconAndAdminContainerCLI.init(TestReconAndAdminContainerCLI.java:134)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:728)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:128)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:70)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$13(ClassBasedTestDescriptor.java:412)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:410)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:216)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:85)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2024-07-01 06:00:16,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:16,841 [main] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4463)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2024-07-01 06:00:16,899 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-07-01 06:00:16,901 [main] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(476)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2024-07-01 06:00:16,912 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-07-01 06:00:16,931 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(168)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15007
2024-07-01 06:00:16,940 [main] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(589)) - TransactionInfo not found in OM DB.
2024-07-01 06:00:16,989 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-07-01 06:00:16,998 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:17,000 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15007 (fallback to raft.grpc.server.port)
2024-07-01 06:00:17,001 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:17,002 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15007 (fallback to raft.grpc.server.port)
2024-07-01 06:00:17,003 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-07-01 06:00:17,005 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15007 (custom)
2024-07-01 06:00:17,006 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 4194304 (custom)
2024-07-01 06:00:17,007 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-07-01 06:00:17,008 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-07-01 06:00:17,009 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-07-01 06:00:17,015 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:00:17,018 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-07-01 06:00:17,019 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-07-01 06:00:17,170 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2024-07-01 06:00:17,172 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:17,173 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-07-01 06:00:17,173 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:17,176 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/ratis] (custom)
2024-07-01 06:00:17,178 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-07-01 06:00:17,178 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-07-01 06:00:17,183 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - om1: addNew group-C5BA1605619E:[om1|localhost:15007] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@16b6493d[Not completed]
2024-07-01 06:00:17,184 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2168)) - OzoneManager Ratis server initialized at port 15007
2024-07-01 06:00:17,187 [main] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1228)) - Creating RPC Server
2024-07-01 06:00:17,190 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|localhost:15007] with OzoneManagerStateMachine:uninitialized
2024-07-01 06:00:17,191 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-07-01 06:00:17,192 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2024-07-01 06:00:17,192 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:17,192 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2024-07-01 06:00:17,192 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:17,192 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:17,193 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:17,198 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - om1@group-C5BA1605619E: ConfigurationManager, init=conf: {index: -1, cur=peers:[om1|localhost:15007]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:17,203 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2024-07-01 06:00:17,206 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:17,210 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2024-07-01 06:00:17,210 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:17,213 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:17,216 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:17,255 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-07-01 06:00:17,258 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:17,258 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:17,259 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:17,260 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:17,260 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:17,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:17,951 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 721 ms to scan 20 urls, producing 59 keys and 6593 values
2024-07-01 06:00:18,082 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:18,082 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 127.0.0.1:15004
2024-07-01 06:00:18,083 [Socket Reader #1 for port 15004] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15004
2024-07-01 06:00:18,107 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2024-07-01 06:00:18,117 [main] INFO  om.OzoneManager (OzoneManager.java:start(1650)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15004
2024-07-01 06:00:18,118 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(594)) - Starting OzoneManagerRatisServer om1 at port 15007
2024-07-01 06:00:18,120 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:18,121 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:18,121 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/ratis] (custom)
2024-07-01 06:00:18,125 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2024-07-01 06:00:18,131 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:18,135 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2024-07-01 06:00:18,137 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:18,144 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:18,144 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-07-01 06:00:18,146 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:18,146 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:18,150 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-07-01 06:00:18,155 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:18,155 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:18,156 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-07-01 06:00:18,157 [om1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[om1@group-C5BA1605619E-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:18,160 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2024-07-01 06:00:18,160 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-07-01 06:00:18,161 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2024-07-01 06:00:18,162 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-07-01 06:00:18,162 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:18,163 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:18,163 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:18,163 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:18,164 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-07-01 06:00:18,167 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2024-07-01 06:00:18,168 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-07-01 06:00:18,169 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:18,169 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:18,169 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2024-07-01 06:00:18,174 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:18,174 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:18,175 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - om1@group-C5BA1605619E: start as a follower, conf=conf: {index: -1, cur=peers:[om1|localhost:15007]|listeners:[], old=null}
2024-07-01 06:00:18,176 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:18,177 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-FollowerState
2024-07-01 06:00:18,178 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-07-01 06:00:18,178 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-07-01 06:00:18,180 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:18,180 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:18,180 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:18,181 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2024-07-01 06:00:18,181 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2024-07-01 06:00:18,182 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2024-07-01 06:00:18,183 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:18,183 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:18,186 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(408)) - om1: start RPC server
2024-07-01 06:00:18,217 [main] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - om1: GrpcService started, listening on 15007
2024-07-01 06:00:18,218 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-om1: Started
2024-07-01 06:00:18,219 [main] INFO  om.OzoneManager (OzoneManager.java:start(1666)) - Version File has different layout version (6) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2024-07-01 06:00:18,241 [main] INFO  client.ScmTopologyClient (ScmTopologyClient.java:start(72)) - Initial network topology fetched from SCM: /.
2024-07-01 06:00:18,241 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-07-01 06:00:18,241 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-07-01 06:00:18,261 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15005
2024-07-01 06:00:18,261 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:00:18,263 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:00:18,265 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.ozoneManager is not defined
2024-07-01 06:00:18,270 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:00:18,272 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2024-07-01 06:00:18,272 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:00:18,272 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:00:18,273 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/webserver
2024-07-01 06:00:18,276 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15005
2024-07-01 06:00:18,277 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:00:18,278 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:00:18,279 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:00:18,279 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-07-01 06:00:18,280 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6c8e0773{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:00:18,281 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5406ce9f{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-07-01 06:00:18,290 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1dfdac1f{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-07-01 06:00:18,291 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@157e14f2{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-07-01 06:00:18,292 [main] INFO  server.Server (Server.java:doStart(415)) - Started @6311ms
2024-07-01 06:00:18,292 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-07-01 06:00:18,293 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of ozoneManager listening at http://0.0.0.0:15005
2024-07-01 06:00:18,293 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:18,294 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15004: starting
2024-07-01 06:00:18,304 [main] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2121)) - Trash Interval set to 0. Files deleted won't move to trash
2024-07-01 06:00:18,367 [main] INFO  db.CodecBuffer (CodecBuffer.java:set(63)) - Successfully set constructor to org.apache.hadoop.hdds.utils.db.CodecBuffer$$Lambda$1152/0x00007fe940750f10@654fdde2
2024-07-01 06:00:18,489 [main] INFO  recon.ReconServer (StringUtils.java:startupShutdownMessage(132)) - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ReconServer
STARTUP_MSG:   host = fv-az1786-697/10.1.0.20
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/common/target/ozone-common-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.58.0/grpc-netty-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.58.0/grpc-core-1.58.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.23/animal-sniffer-annotations-1.23.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.58.0/grpc-context-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-util/1.58.0/grpc-util-1.58.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.109.Final/netty-codec-http2-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.109.Final/netty-common-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.109.Final/netty-buffer-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.109.Final/netty-codec-http-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.109.Final/netty-handler-proxy-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.109.Final/netty-codec-socks-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.65.Final/netty-tcnative-classes-2.0.65.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.26.0/commons-compress-1.26.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/client/target/hdds-client-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/ozone-interface-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.6/hadoop-hdfs-client-3.3.6.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.12.0/okhttp-4.12.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.6.0/okio-3.6.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.6.0/okio-jvm-3.6.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.9.24/kotlin-stdlib-jdk8-1.9.24.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.9.24/kotlin-stdlib-jdk7-1.9.24.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.24/kotlin-stdlib-common-1.9.24.jar:/home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/hdds-test-utils-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.26.0/assertj-core-3.26.0.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.14.16/byte-buddy-1.14.16.jar:/home/runner/.m2/repository/com/google/guava/guava/32.1.3-jre/guava-32.1.3-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.37.0/checker-qual-3.37.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/commons-io/commons-io/2.16.1/commons-io-2.16.1.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.10.3/junit-jupiter-api-5.10.3.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.10.3/junit-platform-commons-1.10.3.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.25/reload4j-1.2.25.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/2.0.13/slf4j-api-2.0.13.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/hdds-server-scm-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-server/target/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.37.2/nimbus-jose-jwt-9.37.2.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.3.4/commons-daemon-1.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/hdds-server-framework-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk18on/1.78.1/bcprov-jdk18on-1.78.1.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.6/metrics-core-3.2.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.12.0/commons-text-1.12.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/hdds-server-framework-1.5.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/hdds-interface-server-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/target/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/2.0.13/slf4j-reload4j-2.0.13.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.10.1/commons-configuration2-2.10.1.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.4/disruptor-3.4.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.54.v20240208/jetty-util-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.54.v20240208/jetty-server-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.54.v20240208/jetty-http-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.54.v20240208/jetty-io-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.54.v20240208/jetty-servlet-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.54.v20240208/jetty-security-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.54.v20240208/jetty-util-ajax-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.54.v20240208/jetty-webapp-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.54.v20240208/jetty-xml-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/3.1.0/ratis-server-3.1.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.6/ratis-thirdparty-misc-1.0.6.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/3.1.0/ratis-proto-3.1.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/3.1.0/ratis-common-3.1.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/3.1.0/ratis-client-3.1.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-api/3.1.0/ratis-metrics-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-dropwizard3/3.1.0/ratis-metrics-dropwizard3-3.1.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.16.0/simpleclient_dropwizard-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.16.0/simpleclient-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.16.0/simpleclient_common-0.16.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.16.2/jackson-datatype-jsr310-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.16.2/jackson-core-2.16.2.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.4.0/jgrapht-core-1.4.0.jar:/home/runner/.m2/repository/org/jheaps/jheaps/0.11/jheaps-0.11.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.4.0/jgrapht-ext-1.4.0.jar:/home/runner/.m2/repository/com/github/vlsi/mxgraph/jgraphx/3.9.8.1/jgraphx-3.9.8.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/ozone-manager-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/hdds-interface-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/ozone-interface-storage-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.10.2/reflections-0.10.2.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19.4/jersey-client-1.19.4.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.54.v20240208/jetty-client-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.16/httpcore-nio-4.4.16.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.6/hadoop-minikdc-3.3.6.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/ozone-s3gateway-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.30.2-GA/javassist-3.30.2-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.43/jersey-container-servlet-core-2.43.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.43/jersey-common-2.43.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.43/jersey-cdi1x-2.43.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.43/jersey-hk2-2.43.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.43/jersey-media-jaxb-2.43.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.16.2/jackson-dataformat-xml-2.16.2.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.2/stax2-api-4.2.2.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.16.2/jackson-module-jaxb-annotations-2.16.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.9/jaxb-runtime-2.3.9.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.9/txw2-2.3.9.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.12/istack-commons-runtime-3.0.12.jar:/home/runner/.m2/repository/com/sun/activation/jakarta.activation/1.2.2/jakarta.activation-1.2.2.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.58.0/grpc-protobuf-1.58.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.22.0/proto-google-common-protos-2.22.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.58.0/grpc-protobuf-lite-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.58.0/grpc-stub-1.58.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.109.Final/netty-transport-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.109.Final/netty-resolver-4.1.109.Final.jar:/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/ozone-csi-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/config/target/hdds-config-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.109.Final/netty-transport-classes-epoll-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.109.Final/netty-transport-native-unix-common-4.1.109.Final.jar:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/target/ozone-reconcodegen-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/guice/6.0.0/guice-6.0.0.jar:/home/runner/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/6.0.0/guice-assistedinject-6.0.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/6.0.0/guice-servlet-6.0.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.43/jersey-container-servlet-2.43.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.6.1/guice-bridge-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.43/jersey-server-2.43.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.43/jersey-client-2.43.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.43/jersey-media-json-jackson-2.43.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.43/jersey-entity-filtering-2.43.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.44.1.0/sqlite-jdbc-3.44.1.0.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.34/spring-jdbc-5.3.34.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.34/spring-beans-5.3.34.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.34/spring-core-5.3.34.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.34/spring-tx-5.3.34.jar:/home/runner/work/ozone/ozone/hadoop-ozone/client/target/ozone-client-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/ozone-filesystem-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/ozone-filesystem-common-1.5.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/tools/target/ozone-tools-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.661/aws-java-sdk-core-1.12.661.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.14/httpclient-4.5.14.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.16/httpcore-4.4.16.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.16.2/jackson-dataformat-cbor-2.16.2.jar:/home/runner/.m2/repository/joda-time/joda-time/2.12.7/joda-time-2.12.7.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.661/aws-java-sdk-s3-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.661/aws-java-sdk-kms-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.661/jmespath-java-1.12.661.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.11/metainf-services-1.11.jar:/home/runner/work/ozone/ozone/hadoop-hdds/tools/target/hdds-tools-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/3.1.0/ratis-tools-3.1.0.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.8.0/commons-cli-1.8.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.14.0/commons-lang3-3.14.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/ozone-manager-1.5.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-1.5.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-client/target/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.7.6/picocli-4.7.6.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.16.2/jackson-annotations-2.16.2.jar:/home/runner/work/ozone/ozone/hadoop-hdds/annotations/target/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/3.1.0/ratis-server-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/3.1.0/ratis-netty-3.1.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/3.1.0/ratis-grpc-3.1.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk18on/1.78.1/bcpkix-jdk18on-1.78.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcutil-jdk18on/1.78.1/bcutil-jdk18on-1.78.1.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.8.1/jaeger-client-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.8.1/jaeger-thrift-1.8.1.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.15.0/libthrift-0.15.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.8.1/jaeger-core-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.8.1/jaeger-tracerresolver-1.8.1.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.9.24/kotlin-stdlib-1.9.24.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.58.0/grpc-api-1.58.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.10.3/junit-platform-launcher-1.10.3.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.10.3/junit-platform-engine-1.10.3.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.6/hadoop-auth-3.3.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.2.0/hadoop-shaded-guava-1.2.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19.4/jersey-core-1.19.4.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19.4/jersey-server-1.19.4.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.10.0/commons-net-3.10.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19.4/jersey-servlet-1.19.4.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.20/jersey-json-1.20.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.7/re2j-1.7.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.9/dnsjava-2.1.9.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.16.2/jackson-databind-2.16.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/hdds-server-scm-1.5.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.6-3/zstd-jni-1.5.6-3.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.17.0/commons-codec-1.17.0.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.109.Final/netty-codec-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.109.Final/netty-handler-4.1.109.Final.jar:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-test/target/hdds-hadoop-dependency-test-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6-tests.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.10.3/junit-jupiter-engine-5.10.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.10.3/junit-jupiter-params-5.10.3.jar:/home/runner/.m2/repository/org/mockito/mockito-core/4.11.0/mockito-core-4.11.0.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.12.19/byte-buddy-agent-1.12.19.jar:/home/runner/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/runner/.m2/repository/org/mockito/mockito-inline/4.11.0/mockito-inline-4.11.0.jar:/home/runner/.m2/repository/org/mockito/mockito-junit-jupiter/4.11.0/mockito-junit-jupiter-4.11.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.6/hadoop-mapreduce-client-jobclient-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.6/hadoop-mapreduce-client-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.6/hadoop-yarn-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.6/hadoop-yarn-api-3.3.6.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.16.2/jackson-jaxrs-json-provider-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.16.2/jackson-jaxrs-base-2.16.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.6/hadoop-yarn-client-3.3.6.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.51.v20230217/websocket-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.51.v20230217/websocket-common-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.51.v20230217/websocket-api-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.6/hadoop-mapreduce-client-core-3.3.6.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.6/hadoop-annotations-3.3.6.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6-tests.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.2/hamcrest-2.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/2.0.13/jul-to-slf4j-2.0.13.jar:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/gradle-enterprise/test-listeners.jar:
STARTUP_MSG:   build = https://github.com/apache/ozone/9513e0bac6d1feabcf36c1d19be8bcd2e97a4180 ; compiled by 'runner' on 2024-07-01T05:49Z
STARTUP_MSG:   java = 17.0.11
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=8MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=4, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.factory.classname=org.apache.hadoop.hdds.fs.MockSpaceUsageCheckFactory$None, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=1s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=4MB, ozone.client.datastream.min.packet.size=256KB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=8MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=1MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=2MB, ozone.client.stream.buffer.size=1MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.csi.default-volume-size=1000000000, ozone.csi.mount.command=goofys --endpoint %s %s %s, ozone.csi.s3g.address=http://localhost:9878, ozone.csi.socket=/var/lib/csi.sock, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=ALL, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=20, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.init.default.layout.version=-1, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=4MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.s3.grpc.server_enabled=false, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1s, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.sql.db.auto.commit=true, ozone.recon.sql.db.conn.idle.max.age=3600s, ozone.recon.sql.db.conn.idle.test=SELECT 1, ozone.recon.sql.db.conn.idle.test.period=60s, ozone.recon.sql.db.conn.max.active=5, ozone.recon.sql.db.conn.max.age=1800s, ozone.recon.sql.db.conn.timeout=30000ms, ozone.recon.sql.db.driver=org.apache.derby.jdbc.EmbeddedDriver, ozone.recon.sql.db.jdbc.url=jdbc:derby:${ozone.recon.db.dir}/ozone_recon_derby.db, ozone.recon.sql.db.jooq.dialect=DERBY, ozone.recon.task.containercounttask.interval=60s, ozone.recon.task.missingcontainer.interval=300s, ozone.recon.task.pipelinesync.interval=300s, ozone.recon.task.safemode.wait.threshold=300s, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=4MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=1MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=1s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=4MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=20, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=100ms, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=3, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.test.test.key=value1, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256, test.scm.client.address=localhost, test.scm.client.bind.host=0.0.0.0, test.scm.client.class=java.lang.Object, test.scm.client.compression.enabled=true, test.scm.client.duration=1h, test.scm.client.enabled=true, test.scm.client.port=9878, test.scm.client.threshold=10, test.scm.client.wait=30m, yarn.app.mapreduce.am.container.log.backups=0, yarn.app.mapreduce.am.container.log.limit.kb=0, yarn.app.mapreduce.task.container.log.backups=0, yarn.nodemanager.container.stderr.pattern={*stderr*,*STDERR*}, yarn.nodemanager.container.stderr.tail.bytes=4096, yarn.nodemanager.windows-container.cpu-limit.enabled=false, yarn.nodemanager.windows-container.memory-limit.enabled=false, yarn.resourcemanager.container.liveness-monitor.interval-ms=600000}
************************************************************/
2024-07-01 06:00:18,496 [main] INFO  recon.ReconServer (SignalLogger.java:register(90)) - registered UNIX signal handlers for [TERM, HUP, INT]
2024-07-01 06:00:18,677 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 6 ms to scan 1 urls, producing 20 keys and 82 values
2024-07-01 06:00:18,835 [main] INFO  recon.ReconServer (ReconServer.java:call(118)) - Initializing Recon server...
2024-07-01 06:00:18,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:18,880 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/recon/ozone_recon_derby.db 
2024-07-01 06:00:19,343 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1166547444ns, electionTimeout:1159ms
2024-07-01 06:00:19,344 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2024-07-01 06:00:19,344 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:00:19,346 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:00:19,347 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-LeaderElection1
2024-07-01 06:00:19,350 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[om1|localhost:15007]|listeners:[], old=null}
2024-07-01 06:00:19,352 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-07-01 06:00:19,358 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[om1|localhost:15007]|listeners:[], old=null}
2024-07-01 06:00:19,358 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-07-01 06:00:19,358 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection1
2024-07-01 06:00:19,359 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:00:19,363 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:00:19,365 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-07-01 06:00:19,366 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-07-01 06:00:19,370 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2024-07-01 06:00:19,370 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:00:19,370 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:00:19,376 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:00:19,379 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:00:19,379 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-07-01 06:00:19,379 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:00:19,379 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-07-01 06:00:19,380 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:00:19,387 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2024-07-01 06:00:19,387 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - om1@group-C5BA1605619E: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:00:19,390 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/recon/ozone_recon_derby.db.
2024-07-01 06:00:19,390 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 2184ms
2024-07-01 06:00:19,418 [om1@group-C5BA1605619E-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:19,438 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - om1@group-C5BA1605619E: set configuration conf: {index: 0, cur=peers:[om1|localhost:15007]|listeners:[], old=null}
2024-07-01 06:00:19,447 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:19,467 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2024-07-01 06:00:19,554 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(212)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:15007"
startupRole: FOLLOWER
]
2024-07-01 06:00:19,555 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader om1@group-C5BA1605619E-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:00:19,610 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-07-01 06:00:19,611 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-07-01 06:00:19,633 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/recon/ozone_recon_derby.db 
2024-07-01 06:00:19,637 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/recon/ozone_recon_derby.db.
2024-07-01 06:00:19,638 [main] INFO  recon.ReconServer (ReconServer.java:call(142)) - Creating Recon Schema.
2024-07-01 06:00:19,836 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:19,932 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for recon at: http://0.0.0.0:15008
2024-07-01 06:00:19,932 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:00:19,934 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:00:19,936 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.recon is not defined
2024-07-01 06:00:19,938 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:00:19,939 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
2024-07-01 06:00:19,939 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:00:19,940 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:00:19,940 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of recon uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/webserver
2024-07-01 06:00:19,945 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task ContainerKeyMapperTask with controller.
2024-07-01 06:00:20,047 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task FileSizeCountTask with controller.
2024-07-01 06:00:20,051 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task OmTableInsightTask with controller.
2024-07-01 06:00:20,055 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task NSSummaryTask with controller.
2024-07-01 06:00:20,058 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(709)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-07-01 06:00:20,059 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(728)) - No OzoneManager ServiceID configured.
2024-07-01 06:00:20,323 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-07-01 06:00:20,323 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-07-01 06:00:20,403 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-07-01 06:00:20,406 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(240)) - Init the HA SequenceIdGenerator.
2024-07-01 06:00:20,410 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-07-01 06:00:20,412 [main] INFO  scm.ReconNodeManager (ReconNodeManager.java:loadExistingNodes(132)) - Loaded 0 nodes from node DB.
2024-07-01 06:00:20,412 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-07-01 06:00:20,414 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:20,414 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15009
2024-07-01 06:00:20,419 [Socket Reader #1 for port 15009] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15009
2024-07-01 06:00:20,424 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-07-01 06:00:20,442 [main] INFO  recon.ReconServer (ReconServer.java:call(157)) - Initializing support of Recon Features...
2024-07-01 06:00:20,444 [main] INFO  recon.ReconServer (ReconServer.java:start(221)) - Starting Recon server
2024-07-01 06:00:20,444 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Recon metrics system started (again)
2024-07-01 06:00:20,478 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15008
2024-07-01 06:00:20,478 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:00:20,480 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:00:20,480 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:00:20,480 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-07-01 06:00:20,481 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@589c341d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:00:20,481 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@f284158{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-07-01 06:00:20,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:21,194 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1c0db15{recon,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/webserver/jetty-0_0_0_0-15008-ozone-recon-1_5_0-SNAPSHOT_jar-_-any-889679813220921383/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/recon}
2024-07-01 06:00:21,195 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@74e37ad3{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-07-01 06:00:21,195 [main] INFO  server.Server (Server.java:doStart(415)) - Started @9214ms
2024-07-01 06:00:21,195 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-07-01 06:00:21,196 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of recon listening at http://0.0.0.0:15008
2024-07-01 06:00:21,196 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:start(256)) - Starting Ozone Manager Service Provider.
2024-07-01 06:00:21,201 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(234)) - Registered OmDeltaRequest task 
2024-07-01 06:00:21,204 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(244)) - Registered OmSnapshotRequest task 
2024-07-01 06:00:21,205 [main] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:start(82)) - Starting ReconOMMetadataManagerImpl
2024-07-01 06:00:21,205 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:start(222)) - Starting Recon Task Controller.
2024-07-01 06:00:21,207 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(395)) - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:15009
2024-07-01 06:00:21,355 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:initializePipelinesFromScm(495)) - Obtained 0 pipelines from SCM.
2024-07-01 06:00:21,356 [main] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-07-01 06:00:21,356 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(408)) - SCM DB initialized
2024-07-01 06:00:21,357 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15009
2024-07-01 06:00:21,360 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:21,360 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15009: starting
2024-07-01 06:00:21,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:22,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:23,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:24,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:25,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:26,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:27,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:28,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:29,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:30,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:31,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:32,408 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered PipelineSyncTask task 
2024-07-01 06:00:32,409 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting PipelineSyncTask Thread.
2024-07-01 06:00:32,412 [PipelineSyncTask] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-07-01 06:00:32,412 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerHealthTask task 
2024-07-01 06:00:32,412 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerHealthTask Thread.
2024-07-01 06:00:32,416 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerSizeCountTask task 
2024-07-01 06:00:32,416 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerSizeCountTask Thread.
2024-07-01 06:00:32,423 [main] INFO  recon.ReconServer (ReconServer.java:call(164)) - Recon server initialized successfully!
2024-07-01 06:00:32,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:32,431 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-Recon: Started
2024-07-01 06:00:32,467 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:32,468 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:32,468 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-07-01 06:00:32,483 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(237)) - HddsDatanodeService host:fv-az1786-697.10u40dmvycxuldx3oogyczyfqh.bx.internal.cloudapp.net ip:10.1.0.20
2024-07-01 06:00:32,491 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-07-01 06:00:32,493 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(293)) - Datanode State Machine Task Thread Pool size 2
2024-07-01 06:00:32,534 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-07-01 06:00:32,536 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds to VolumeSet
2024-07-01 06:00:32,539 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis to VolumeSet
2024-07-01 06:00:32,541 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-07-01 06:00:32,579 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for DNAudit to [].
2024-07-01 06:00:32,607 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-07-01 06:00:32,608 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:32,608 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15015 (custom)
2024-07-01 06:00:32,608 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:32,608 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15014 (custom)
2024-07-01 06:00:32,608 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-07-01 06:00:32,608 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15016 (custom)
2024-07-01 06:00:32,609 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-07-01 06:00:32,609 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:32,609 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-07-01 06:00:32,609 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:32,609 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:00:32,609 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-07-01 06:00:32,610 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-07-01 06:00:32,611 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-07-01 06:00:32,621 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-07-01 06:00:32,621 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-07-01 06:00:32,622 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-07-01 06:00:32,623 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-07-01 06:00:32,624 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-07-01 06:00:32,625 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-07-01 06:00:32,626 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-07-01 06:00:32,627 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-07-01 06:00:32,627 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-07-01 06:00:32,627 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-07-01 06:00:32,628 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-07-01 06:00:32,629 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-07-01 06:00:32,630 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15017 (custom)
2024-07-01 06:00:32,635 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:32,635 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-07-01 06:00:32,635 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:32,636 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis] (custom)
2024-07-01 06:00:32,636 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-07-01 06:00:32,636 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-07-01 06:00:32,639 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(266)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/tmp
2024-07-01 06:00:32,639 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(271)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/tmp is not a group directory; ignoring it. 
2024-07-01 06:00:32,641 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-07-01 06:00:32,647 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9854b6ad] REGISTERED
2024-07-01 06:00:32,648 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9854b6ad] BIND: 0.0.0.0/0.0.0.0:15017
2024-07-01 06:00:32,649 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9854b6ad, L:/0.0.0.0:15017] ACTIVE
2024-07-01 06:00:32,665 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-07-01 06:00:32,700 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-07-01 06:00:32,702 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-07-01 06:00:32,741 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15011
2024-07-01 06:00:32,742 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:00:32,743 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:00:32,744 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-07-01 06:00:32,745 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:00:32,746 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-07-01 06:00:32,746 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:00:32,746 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:00:32,747 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/meta/webserver
2024-07-01 06:00:32,747 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15011
2024-07-01 06:00:32,747 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:00:32,750 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:00:32,750 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:00:32,751 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-07-01 06:00:32,751 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@510efcb7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:00:32,752 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@14f5b751{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-07-01 06:00:32,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:32,920 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@25e58cbd{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/meta/webserver/jetty-0_0_0_0-15011-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-16469382279983656759/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:00:32,921 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5fe01354{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-07-01 06:00:32,921 [main] INFO  server.Server (Server.java:doStart(415)) - Started @20940ms
2024-07-01 06:00:32,921 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-07-01 06:00:32,922 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15011
2024-07-01 06:00:32,924 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:32,925 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15012
2024-07-01 06:00:32,925 [Socket Reader #1 for port 15012] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15012
2024-07-01 06:00:32,927 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(321)) - Datanode start with admins: [runner]
2024-07-01 06:00:32,927 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15012
2024-07-01 06:00:32,927 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:32,927 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15012: starting
2024-07-01 06:00:32,928 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(545)) - Ozone container server started.
2024-07-01 06:00:32,929 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:32,929 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:32,929 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-07-01 06:00:32,939 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(237)) - HddsDatanodeService host:fv-az1786-697.10u40dmvycxuldx3oogyczyfqh.bx.internal.cloudapp.net ip:10.1.0.20
2024-07-01 06:00:32,941 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-07-01 06:00:32,942 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(293)) - Datanode State Machine Task Thread Pool size 2
2024-07-01 06:00:32,944 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-07-01 06:00:32,945 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds to VolumeSet
2024-07-01 06:00:32,946 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis to VolumeSet
2024-07-01 06:00:32,948 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-07-01 06:00:32,961 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-07-01 06:00:32,962 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:32,962 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15024 (custom)
2024-07-01 06:00:32,962 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:32,962 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15023 (custom)
2024-07-01 06:00:32,962 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-07-01 06:00:32,963 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15025 (custom)
2024-07-01 06:00:32,963 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-07-01 06:00:32,963 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:32,963 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-07-01 06:00:32,963 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:32,963 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:00:32,963 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-07-01 06:00:32,963 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-07-01 06:00:32,965 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-07-01 06:00:32,965 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-07-01 06:00:32,966 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-07-01 06:00:32,966 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-07-01 06:00:32,966 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-07-01 06:00:32,966 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-07-01 06:00:32,966 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-07-01 06:00:32,966 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-07-01 06:00:32,966 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-07-01 06:00:32,967 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-07-01 06:00:32,967 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-07-01 06:00:32,967 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-07-01 06:00:32,968 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-07-01 06:00:32,968 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15026 (custom)
2024-07-01 06:00:32,968 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:32,968 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-07-01 06:00:32,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:32,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis] (custom)
2024-07-01 06:00:32,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-07-01 06:00:32,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-07-01 06:00:32,969 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x58494ccf] REGISTERED
2024-07-01 06:00:32,970 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x58494ccf] BIND: 0.0.0.0/0.0.0.0:15026
2024-07-01 06:00:32,970 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x58494ccf, L:/0.0.0.0:15026] ACTIVE
2024-07-01 06:00:32,971 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(266)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/tmp
2024-07-01 06:00:32,971 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-07-01 06:00:32,971 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(271)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2024-07-01 06:00:32,972 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-07-01 06:00:32,973 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-07-01 06:00:32,975 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-07-01 06:00:32,976 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-07-01 06:00:32,982 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15020
2024-07-01 06:00:32,982 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:00:32,983 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:00:32,984 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-07-01 06:00:32,986 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:00:32,987 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-07-01 06:00:32,987 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:00:32,987 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:00:32,988 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/meta/webserver
2024-07-01 06:00:32,988 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15020
2024-07-01 06:00:32,988 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:00:33,000 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:00:33,000 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:00:33,000 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-07-01 06:00:33,001 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7eecccfb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:00:33,001 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2aa43b2e{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-07-01 06:00:33,020 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/meta/datanode.id
2024-07-01 06:00:33,154 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@f033ec6{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/meta/webserver/jetty-0_0_0_0-15020-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-1344174515041399368/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:00:33,155 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@27a18e3b{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-07-01 06:00:33,155 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21174ms
2024-07-01 06:00:33,155 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-07-01 06:00:33,156 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15020
2024-07-01 06:00:33,156 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:33,156 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15021
2024-07-01 06:00:33,157 [Socket Reader #1 for port 15021] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15021
2024-07-01 06:00:33,159 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(321)) - Datanode start with admins: [runner]
2024-07-01 06:00:33,159 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15021
2024-07-01 06:00:33,159 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:33,163 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(545)) - Ozone container server started.
2024-07-01 06:00:33,163 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:33,163 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:33,163 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-07-01 06:00:33,166 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15021: starting
2024-07-01 06:00:33,172 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-07-01 06:00:33,173 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(237)) - HddsDatanodeService host:fv-az1786-697.10u40dmvycxuldx3oogyczyfqh.bx.internal.cloudapp.net ip:10.1.0.20
2024-07-01 06:00:33,175 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/meta/datanode.id
2024-07-01 06:00:33,176 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-07-01 06:00:33,177 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(293)) - Datanode State Machine Task Thread Pool size 2
2024-07-01 06:00:33,179 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-07-01 06:00:33,179 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds to VolumeSet
2024-07-01 06:00:33,180 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis to VolumeSet
2024-07-01 06:00:33,181 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-07-01 06:00:33,185 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-07-01 06:00:33,185 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:33,185 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15033 (custom)
2024-07-01 06:00:33,185 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:33,185 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15032 (custom)
2024-07-01 06:00:33,185 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-07-01 06:00:33,185 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15034 (custom)
2024-07-01 06:00:33,185 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-07-01 06:00:33,186 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:33,186 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-07-01 06:00:33,186 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:33,186 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:00:33,186 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-07-01 06:00:33,186 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-07-01 06:00:33,187 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-07-01 06:00:33,188 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-07-01 06:00:33,188 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-07-01 06:00:33,188 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-07-01 06:00:33,188 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-07-01 06:00:33,188 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-07-01 06:00:33,188 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-07-01 06:00:33,189 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-07-01 06:00:33,189 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-07-01 06:00:33,189 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-07-01 06:00:33,189 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-07-01 06:00:33,190 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-07-01 06:00:33,190 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-07-01 06:00:33,190 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15035 (custom)
2024-07-01 06:00:33,191 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:33,191 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-07-01 06:00:33,191 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:33,191 [d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x19100d1b] REGISTERED
2024-07-01 06:00:33,191 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis] (custom)
2024-07-01 06:00:33,191 [d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x19100d1b] BIND: 0.0.0.0/0.0.0.0:15035
2024-07-01 06:00:33,191 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-07-01 06:00:33,191 [d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x19100d1b, L:/0.0.0.0:15035] ACTIVE
2024-07-01 06:00:33,192 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-07-01 06:00:33,192 [d911fb7d-ae06-4770-ac9a-ead30a7876df-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(266)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/tmp
2024-07-01 06:00:33,192 [d911fb7d-ae06-4770-ac9a-ead30a7876df-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(271)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/tmp is not a group directory; ignoring it. 
2024-07-01 06:00:33,192 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-07-01 06:00:33,193 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-07-01 06:00:33,196 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-07-01 06:00:33,196 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-07-01 06:00:33,198 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15029
2024-07-01 06:00:33,198 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:00:33,200 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:00:33,203 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-07-01 06:00:33,204 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:00:33,205 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-07-01 06:00:33,205 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:00:33,205 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:00:33,206 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/meta/webserver
2024-07-01 06:00:33,206 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15029
2024-07-01 06:00:33,207 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:00:33,211 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:00:33,211 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:00:33,211 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-07-01 06:00:33,214 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7967b127{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:00:33,214 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2c507e20{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-07-01 06:00:33,375 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@18547b0b{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/meta/webserver/jetty-0_0_0_0-15029-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-2116948387124532106/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:00:33,376 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@37347be1{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-07-01 06:00:33,376 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21395ms
2024-07-01 06:00:33,376 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-07-01 06:00:33,377 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15029
2024-07-01 06:00:33,377 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:33,378 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15030
2024-07-01 06:00:33,378 [Socket Reader #1 for port 15030] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15030
2024-07-01 06:00:33,380 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(321)) - Datanode start with admins: [runner]
2024-07-01 06:00:33,380 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15030
2024-07-01 06:00:33,380 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:33,380 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15030: starting
2024-07-01 06:00:33,380 [d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(545)) - Ozone container server started.
2024-07-01 06:00:33,381 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:33,381 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:33,381 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-07-01 06:00:33,382 [d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-07-01 06:00:33,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/meta/datanode.id
2024-07-01 06:00:33,392 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(237)) - HddsDatanodeService host:fv-az1786-697.10u40dmvycxuldx3oogyczyfqh.bx.internal.cloudapp.net ip:10.1.0.20
2024-07-01 06:00:33,394 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-07-01 06:00:33,394 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(293)) - Datanode State Machine Task Thread Pool size 2
2024-07-01 06:00:33,397 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-07-01 06:00:33,397 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds to VolumeSet
2024-07-01 06:00:33,398 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis to VolumeSet
2024-07-01 06:00:33,398 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-07-01 06:00:33,402 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-07-01 06:00:33,402 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:33,402 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15042 (custom)
2024-07-01 06:00:33,402 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:33,403 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15041 (custom)
2024-07-01 06:00:33,403 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-07-01 06:00:33,403 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15043 (custom)
2024-07-01 06:00:33,403 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-07-01 06:00:33,403 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:33,403 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-07-01 06:00:33,403 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:33,404 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:00:33,404 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-07-01 06:00:33,404 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-07-01 06:00:33,405 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-07-01 06:00:33,406 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-07-01 06:00:33,406 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-07-01 06:00:33,406 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-07-01 06:00:33,406 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-07-01 06:00:33,406 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-07-01 06:00:33,406 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-07-01 06:00:33,406 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-07-01 06:00:33,407 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-07-01 06:00:33,407 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-07-01 06:00:33,407 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-07-01 06:00:33,408 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-07-01 06:00:33,408 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-07-01 06:00:33,408 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15044 (custom)
2024-07-01 06:00:33,409 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:33,409 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-07-01 06:00:33,409 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:33,409 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaff6a543] REGISTERED
2024-07-01 06:00:33,409 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis] (custom)
2024-07-01 06:00:33,409 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaff6a543] BIND: 0.0.0.0/0.0.0.0:15044
2024-07-01 06:00:33,409 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-07-01 06:00:33,409 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaff6a543, L:/0.0.0.0:15044] ACTIVE
2024-07-01 06:00:33,409 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-07-01 06:00:33,410 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(266)) - 4873639b-1d87-440f-9147-409a0544c1cf: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/tmp
2024-07-01 06:00:33,410 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(271)) - 4873639b-1d87-440f-9147-409a0544c1cf: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/tmp is not a group directory; ignoring it. 
2024-07-01 06:00:33,410 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-07-01 06:00:33,411 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-07-01 06:00:33,414 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-07-01 06:00:33,414 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-07-01 06:00:33,417 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15038
2024-07-01 06:00:33,417 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:00:33,418 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:00:33,420 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-07-01 06:00:33,421 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:00:33,422 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-07-01 06:00:33,422 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:00:33,422 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:00:33,423 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/meta/webserver
2024-07-01 06:00:33,423 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15038
2024-07-01 06:00:33,423 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:00:33,424 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:00:33,424 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:00:33,424 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-07-01 06:00:33,425 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@53568b43{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:00:33,425 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2952a16{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-07-01 06:00:33,429 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:33,588 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3c07d704{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/meta/webserver/jetty-0_0_0_0-15038-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-7419817019285849054/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:00:33,589 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@9f2d904{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-07-01 06:00:33,589 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21608ms
2024-07-01 06:00:33,590 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-07-01 06:00:33,590 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15038
2024-07-01 06:00:33,591 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:33,591 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15039
2024-07-01 06:00:33,592 [Socket Reader #1 for port 15039] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15039
2024-07-01 06:00:33,594 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(321)) - Datanode start with admins: [runner]
2024-07-01 06:00:33,594 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15039
2024-07-01 06:00:33,596 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:33,596 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15039: starting
2024-07-01 06:00:33,597 [4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(545)) - Ozone container server started.
2024-07-01 06:00:33,597 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:33,597 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-07-01 06:00:33,597 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-07-01 06:00:33,598 [4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-07-01 06:00:33,600 [4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/meta/datanode.id
2024-07-01 06:00:33,609 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(237)) - HddsDatanodeService host:fv-az1786-697.10u40dmvycxuldx3oogyczyfqh.bx.internal.cloudapp.net ip:10.1.0.20
2024-07-01 06:00:33,611 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-07-01 06:00:33,612 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(293)) - Datanode State Machine Task Thread Pool size 2
2024-07-01 06:00:33,614 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-07-01 06:00:33,614 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2024-07-01 06:00:33,615 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis to VolumeSet
2024-07-01 06:00:33,616 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-07-01 06:00:33,619 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-07-01 06:00:33,619 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:33,620 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15051 (custom)
2024-07-01 06:00:33,620 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:00:33,620 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15050 (custom)
2024-07-01 06:00:33,620 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-07-01 06:00:33,620 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15052 (custom)
2024-07-01 06:00:33,620 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-07-01 06:00:33,620 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:33,620 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-07-01 06:00:33,620 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:33,621 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:00:33,621 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-07-01 06:00:33,621 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-07-01 06:00:33,622 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-07-01 06:00:33,623 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-07-01 06:00:33,623 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-07-01 06:00:33,623 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-07-01 06:00:33,623 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-07-01 06:00:33,623 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-07-01 06:00:33,623 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-07-01 06:00:33,624 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-07-01 06:00:33,624 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-07-01 06:00:33,624 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-07-01 06:00:33,624 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-07-01 06:00:33,625 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-07-01 06:00:33,625 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-07-01 06:00:33,625 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15053 (custom)
2024-07-01 06:00:33,626 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:33,626 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-07-01 06:00:33,626 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:33,626 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis] (custom)
2024-07-01 06:00:33,626 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-07-01 06:00:33,626 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-07-01 06:00:33,627 [7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0058c1b0] REGISTERED
2024-07-01 06:00:33,627 [7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0058c1b0] BIND: 0.0.0.0/0.0.0.0:15053
2024-07-01 06:00:33,627 [7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0058c1b0, L:/0.0.0.0:15053] ACTIVE
2024-07-01 06:00:33,629 [7c590364-16f9-412e-8d8f-583652a307a8-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(266)) - 7c590364-16f9-412e-8d8f-583652a307a8: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/tmp
2024-07-01 06:00:33,629 [7c590364-16f9-412e-8d8f-583652a307a8-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(271)) - 7c590364-16f9-412e-8d8f-583652a307a8: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2024-07-01 06:00:33,630 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-07-01 06:00:33,631 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-07-01 06:00:33,633 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-07-01 06:00:33,633 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-07-01 06:00:33,635 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15047
2024-07-01 06:00:33,635 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:00:33,637 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:00:33,638 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-07-01 06:00:33,639 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:00:33,640 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-07-01 06:00:33,640 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:00:33,640 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:00:33,641 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/meta/webserver
2024-07-01 06:00:33,641 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15047
2024-07-01 06:00:33,641 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:00:33,642 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:00:33,642 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:00:33,642 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-07-01 06:00:33,643 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3e650f4{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:00:33,643 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@160a5e87{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-07-01 06:00:33,791 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@523e0ffb{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/meta/webserver/jetty-0_0_0_0-15047-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-7828457382669087088/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:00:33,792 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4dccaef5{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-07-01 06:00:33,792 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21811ms
2024-07-01 06:00:33,792 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-07-01 06:00:33,793 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15047
2024-07-01 06:00:33,793 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:00:33,793 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15048
2024-07-01 06:00:33,794 [Socket Reader #1 for port 15048] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15048
2024-07-01 06:00:33,795 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(321)) - Datanode start with admins: [runner]
2024-07-01 06:00:33,795 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15048
2024-07-01 06:00:33,795 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:00:33,796 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15048: starting
2024-07-01 06:00:33,796 [7c590364-16f9-412e-8d8f-583652a307a8-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(545)) - Ozone container server started.
2024-07-01 06:00:33,798 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-07-01 06:00:33,798 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:33,798 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:33,799 [7c590364-16f9-412e-8d8f-583652a307a8-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-07-01 06:00:33,802 [7c590364-16f9-412e-8d8f-583652a307a8-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/meta/datanode.id
2024-07-01 06:00:33,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:34,430 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:34,799 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-07-01 06:00:34,799 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:34,799 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:34,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:35,008 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-205e25c1-5543-4288-a226-6c3910f61994/container.db to cache
2024-07-01 06:00:35,008 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-205e25c1-5543-4288-a226-6c3910f61994/container.db for volume DS-205e25c1-5543-4288-a226-6c3910f61994
2024-07-01 06:00:35,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds
2024-07-01 06:00:35,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds
2024-07-01 06:00:35,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-07-01 06:00:35,015 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds
2024-07-01 06:00:35,019 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds
2024-07-01 06:00:35,021 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis
2024-07-01 06:00:35,021 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis
2024-07-01 06:00:35,023 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-07-01 06:00:35,028 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,030 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15018
2024-07-01 06:00:35,031 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(562)) - Starting XceiverServerRatis bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:35,032 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,032 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(408)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start RPC server
2024-07-01 06:00:35,033 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: GrpcService started, listening on 15014
2024-07-01 06:00:35,033 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: GrpcService started, listening on 15016
2024-07-01 06:00:35,033 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: GrpcService started, listening on 15015
2024-07-01 06:00:35,034 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-bfc6da33-104c-4d07-98ee-1aed7336cdfb: Started
2024-07-01 06:00:35,034 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis bfc6da33-104c-4d07-98ee-1aed7336cdfb is started using port 15014 for RATIS
2024-07-01 06:00:35,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis bfc6da33-104c-4d07-98ee-1aed7336cdfb is started using port 15015 for RATIS_ADMIN
2024-07-01 06:00:35,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis bfc6da33-104c-4d07-98ee-1aed7336cdfb is started using port 15016 for RATIS_SERVER
2024-07-01 06:00:35,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis bfc6da33-104c-4d07-98ee-1aed7336cdfb is started using port 15017 for RATIS_DATASTREAM
2024-07-01 06:00:35,037 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:00:35,186 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-03f05026-6558-4a94-a93b-33a7a73f0436/container.db to cache
2024-07-01 06:00:35,186 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-03f05026-6558-4a94-a93b-33a7a73f0436/container.db for volume DS-03f05026-6558-4a94-a93b-33a7a73f0436
2024-07-01 06:00:35,188 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds
2024-07-01 06:00:35,188 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds
2024-07-01 06:00:35,188 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-07-01 06:00:35,188 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds
2024-07-01 06:00:35,189 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds
2024-07-01 06:00:35,190 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis
2024-07-01 06:00:35,190 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis
2024-07-01 06:00:35,191 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-07-01 06:00:35,191 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-07-01 06:00:35,191 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,192 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,192 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15027
2024-07-01 06:00:35,192 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(562)) - Starting XceiverServerRatis bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:35,193 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(408)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start RPC server
2024-07-01 06:00:35,193 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: GrpcService started, listening on 15023
2024-07-01 06:00:35,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: GrpcService started, listening on 15025
2024-07-01 06:00:35,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: GrpcService started, listening on 15024
2024-07-01 06:00:35,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 is started using port 15023 for RATIS
2024-07-01 06:00:35,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 is started using port 15024 for RATIS_ADMIN
2024-07-01 06:00:35,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 is started using port 15025 for RATIS_SERVER
2024-07-01 06:00:35,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 is started using port 15026 for RATIS_DATASTREAM
2024-07-01 06:00:35,194 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Started
2024-07-01 06:00:35,196 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:00:35,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db to cache
2024-07-01 06:00:35,416 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db for volume DS-e1e9d739-af54-44d8-a0ec-81db78888cd6
2024-07-01 06:00:35,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds
2024-07-01 06:00:35,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds
2024-07-01 06:00:35,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-07-01 06:00:35,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds
2024-07-01 06:00:35,419 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds
2024-07-01 06:00:35,420 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis
2024-07-01 06:00:35,422 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis
2024-07-01 06:00:35,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-07-01 06:00:35,424 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-07-01 06:00:35,424 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,427 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,427 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15036
2024-07-01 06:00:35,427 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(562)) - Starting XceiverServerRatis d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:35,431 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:35,441 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(408)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start RPC server
2024-07-01 06:00:35,442 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: GrpcService started, listening on 15032
2024-07-01 06:00:35,442 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: GrpcService started, listening on 15034
2024-07-01 06:00:35,443 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: GrpcService started, listening on 15033
2024-07-01 06:00:35,445 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis d911fb7d-ae06-4770-ac9a-ead30a7876df is started using port 15032 for RATIS
2024-07-01 06:00:35,445 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis d911fb7d-ae06-4770-ac9a-ead30a7876df is started using port 15033 for RATIS_ADMIN
2024-07-01 06:00:35,445 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis d911fb7d-ae06-4770-ac9a-ead30a7876df is started using port 15034 for RATIS_SERVER
2024-07-01 06:00:35,445 [d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis d911fb7d-ae06-4770-ac9a-ead30a7876df is started using port 15035 for RATIS_DATASTREAM
2024-07-01 06:00:35,448 [d911fb7d-ae06-4770-ac9a-ead30a7876df-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:00:35,453 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-d911fb7d-ae06-4770-ac9a-ead30a7876df: Started
2024-07-01 06:00:35,618 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db to cache
2024-07-01 06:00:35,618 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db for volume DS-afa75c00-b616-444c-8afa-8f1e266a329f
2024-07-01 06:00:35,620 [4873639b-1d87-440f-9147-409a0544c1cf-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds
2024-07-01 06:00:35,620 [4873639b-1d87-440f-9147-409a0544c1cf-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds
2024-07-01 06:00:35,620 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-07-01 06:00:35,620 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds
2024-07-01 06:00:35,621 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds
2024-07-01 06:00:35,622 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis
2024-07-01 06:00:35,622 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis
2024-07-01 06:00:35,623 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-07-01 06:00:35,623 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-07-01 06:00:35,624 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,624 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15045
2024-07-01 06:00:35,624 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(562)) - Starting XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:35,631 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,631 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(408)) - 4873639b-1d87-440f-9147-409a0544c1cf: start RPC server
2024-07-01 06:00:35,632 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 4873639b-1d87-440f-9147-409a0544c1cf: GrpcService started, listening on 15041
2024-07-01 06:00:35,632 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 4873639b-1d87-440f-9147-409a0544c1cf: GrpcService started, listening on 15043
2024-07-01 06:00:35,632 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 4873639b-1d87-440f-9147-409a0544c1cf: GrpcService started, listening on 15042
2024-07-01 06:00:35,634 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf is started using port 15041 for RATIS
2024-07-01 06:00:35,635 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-4873639b-1d87-440f-9147-409a0544c1cf: Started
2024-07-01 06:00:35,635 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf is started using port 15042 for RATIS_ADMIN
2024-07-01 06:00:35,635 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf is started using port 15043 for RATIS_SERVER
2024-07-01 06:00:35,635 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf is started using port 15044 for RATIS_DATASTREAM
2024-07-01 06:00:35,644 [4873639b-1d87-440f-9147-409a0544c1cf-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:00:35,799 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-07-01 06:00:35,799 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:35,799 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:35,818 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-76e85e00-675e-4383-b07b-e58193edac37/container.db to cache
2024-07-01 06:00:35,818 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-76e85e00-675e-4383-b07b-e58193edac37/container.db for volume DS-76e85e00-675e-4383-b07b-e58193edac37
2024-07-01 06:00:35,820 [7c590364-16f9-412e-8d8f-583652a307a8-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds
2024-07-01 06:00:35,820 [7c590364-16f9-412e-8d8f-583652a307a8-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds
2024-07-01 06:00:35,820 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-07-01 06:00:35,820 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds
2024-07-01 06:00:35,821 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds
2024-07-01 06:00:35,822 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis
2024-07-01 06:00:35,822 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis
2024-07-01 06:00:35,822 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-07-01 06:00:35,822 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-07-01 06:00:35,823 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,823 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:00:35,824 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15054
2024-07-01 06:00:35,824 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(562)) - Starting XceiverServerRatis 7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:35,824 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(408)) - 7c590364-16f9-412e-8d8f-583652a307a8: start RPC server
2024-07-01 06:00:35,825 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 7c590364-16f9-412e-8d8f-583652a307a8: GrpcService started, listening on 15050
2024-07-01 06:00:35,825 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 7c590364-16f9-412e-8d8f-583652a307a8: GrpcService started, listening on 15052
2024-07-01 06:00:35,825 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 7c590364-16f9-412e-8d8f-583652a307a8: GrpcService started, listening on 15051
2024-07-01 06:00:35,826 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 7c590364-16f9-412e-8d8f-583652a307a8 is started using port 15050 for RATIS
2024-07-01 06:00:35,826 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 7c590364-16f9-412e-8d8f-583652a307a8 is started using port 15051 for RATIS_ADMIN
2024-07-01 06:00:35,826 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 7c590364-16f9-412e-8d8f-583652a307a8 is started using port 15052 for RATIS_SERVER
2024-07-01 06:00:35,826 [7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 7c590364-16f9-412e-8d8f-583652a307a8 is started using port 15053 for RATIS_DATASTREAM
2024-07-01 06:00:35,826 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-7c590364-16f9-412e-8d8f-583652a307a8: Started
2024-07-01 06:00:35,827 [7c590364-16f9-412e-8d8f-583652a307a8-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:00:35,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:36,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:36,800 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-07-01 06:00:36,800 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:36,800 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:36,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:36,952 [IPC Server handler 1 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:36,952 [IPC Server handler 3 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:36,954 [IPC Server handler 1 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: bfc6da33-104c-4d07-98ee-1aed7336cdfb{ip: 127.0.0.1, host: localhost, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:36,954 [IPC Server handler 3 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: bfc6da33-104c-4d07-98ee-1aed7336cdfb{ip: 127.0.0.1, host: localhost, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:36,956 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:00:36,956 [IPC Server handler 3 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:36,957 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(203)) - ContainerSafeModeRule rule is successfully validated
2024-07-01 06:00:36,958 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(203)) - AtleastOneDatanodeReportedRule rule is successfully validated
2024-07-01 06:00:36,957 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node bfc6da33-104c-4d07-98ee-1aed7336cdfb to Node DB.
2024-07-01 06:00:36,957 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2024-07-01 06:00:36,962 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 to datanode:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:36,970 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 83d0b075-21bf-48bf-ac12-3d02eec07596, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:36.961744792Z[Etc/UTC]]
2024-07-01 06:00:37,168 [IPC Server handler 2 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:37,168 [IPC Server handler 1 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:37,169 [IPC Server handler 2 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91{ip: 127.0.0.1, host: localhost, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:37,169 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2024-07-01 06:00:37,170 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:00:37,169 [IPC Server handler 1 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91{ip: 127.0.0.1, host: localhost, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:37,170 [IPC Server handler 1 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:37,171 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f to datanode:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:37,171 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 to Node DB.
2024-07-01 06:00:37,172 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 5b142fd5-bd6f-4167-9b55-bc378716716f, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:37.171093091Z[Etc/UTC]]
2024-07-01 06:00:37,384 [IPC Server handler 6 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:37,384 [IPC Server handler 6 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: d911fb7d-ae06-4770-ac9a-ead30a7876df{ip: 127.0.0.1, host: localhost, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:37,384 [IPC Server handler 6 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:37,385 [IPC Server handler 3 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:37,385 [IPC Server handler 3 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: d911fb7d-ae06-4770-ac9a-ead30a7876df{ip: 127.0.0.1, host: localhost, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:37,386 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:00:37,386 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node d911fb7d-ae06-4770-ac9a-ead30a7876df to Node DB.
2024-07-01 06:00:37,387 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2024-07-01 06:00:37,387 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(203)) - DataNodeSafeModeRule rule is successfully validated
2024-07-01 06:00:37,387 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(232)) - All SCM safe mode pre check rules have passed
2024-07-01 06:00:37,387 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-07-01 06:00:37,387 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:00:37,387 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f to datanode:d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:37,389 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f, Nodes: d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:37.387952998Z[Etc/UTC]]
2024-07-01 06:00:37,392 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 to datanode:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:37,392 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 to datanode:d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:37,392 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 to datanode:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:37,393 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 6a54b320-18b2-409b-b307-9d3e094e5440, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:37.392315391Z[Etc/UTC]]
2024-07-01 06:00:37,434 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:37,600 [IPC Server handler 0 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:37,600 [IPC Server handler 4 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:37,600 [IPC Server handler 0 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 4873639b-1d87-440f-9147-409a0544c1cf{ip: 127.0.0.1, host: localhost, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:37,600 [IPC Server handler 0 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:37,600 [IPC Server handler 4 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 4873639b-1d87-440f-9147-409a0544c1cf{ip: 127.0.0.1, host: localhost, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:37,601 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node 4873639b-1d87-440f-9147-409a0544c1cf to Node DB.
2024-07-01 06:00:37,601 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:00:37,601 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 to datanode:4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:37,602 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 91926170-46b2-4d66-81ef-084ccd2b28b6, Nodes: 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:37.601672323Z[Etc/UTC]]
2024-07-01 06:00:37,800 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 4 of 5 DN Heartbeats.
2024-07-01 06:00:37,800 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:37,801 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:37,801 [IPC Server handler 2 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:37,801 [IPC Server handler 2 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 7c590364-16f9-412e-8d8f-583652a307a8{ip: 127.0.0.1, host: localhost, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:37,801 [IPC Server handler 2 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:37,801 [IPC Server handler 0 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:37,802 [IPC Server handler 0 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 7c590364-16f9-412e-8d8f-583652a307a8{ip: 127.0.0.1, host: localhost, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-07-01 06:00:37,802 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:00:37,803 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node 7c590364-16f9-412e-8d8f-583652a307a8 to Node DB.
2024-07-01 06:00:37,803 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 to datanode:7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:37,804 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1, Nodes: 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:37.803446458Z[Etc/UTC]]
2024-07-01 06:00:37,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:38,435 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:38,801 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-07-01 06:00:38,801 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:38,801 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:38,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:38,958 [IPC Server handler 3 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-07-01 06:00:39,169 [IPC Server handler 1 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-07-01 06:00:39,384 [IPC Server handler 5 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-07-01 06:00:39,437 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:39,600 [IPC Server handler 0 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-07-01 06:00:39,800 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-07-01 06:00:39,802 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-07-01 06:00:39,802 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:39,802 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:39,803 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:39,803 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:39,803 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:39,803 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:39,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:39,968 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: addNew group-3D02EEC07596:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016] returns group-3D02EEC07596:java.util.concurrent.CompletableFuture@6ff14de6[Not completed]
2024-07-01 06:00:39,971 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  lib.Interns (Interns.java:removeEldestEntry(50)) - Metrics intern cache overflow at 2011 for MetricsSystem={MetricsSystem=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem}, MetricsSystem record=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem record}}
2024-07-01 06:00:39,974 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: new RaftServerImpl for group-3D02EEC07596:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016] with ContainerStateMachine:uninitialized
2024-07-01 06:00:39,974 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:39,974 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:39,974 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:39,974 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:39,974 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:39,974 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:39,974 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:39,975 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: ConfigurationManager, init=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:39,975 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:39,975 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:39,975 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:39,975 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:39,975 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:39,975 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:39,985 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis] (custom)
2024-07-01 06:00:39,986 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/83d0b075-21bf-48bf-ac12-3d02eec07596 does not exist. Creating ...
2024-07-01 06:00:39,987 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/83d0b075-21bf-48bf-ac12-3d02eec07596/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:39,988 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/83d0b075-21bf-48bf-ac12-3d02eec07596 has been successfully formatted.
2024-07-01 06:00:39,989 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-3D02EEC07596: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:39,989 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:39,990 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:39,990 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:39,990 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:39,990 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:39,993 [IPC Server handler 1 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-07-01 06:00:39,993 [IPC Server handler 1 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:39,993 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596. Trying to get from SCM.
2024-07-01 06:00:39,995 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:39,995 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:39,995 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:39,996 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:39,996 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:39,996 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/83d0b075-21bf-48bf-ac12-3d02eec07596
2024-07-01 06:00:39,996 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:39,996 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:39,997 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:39,997 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:39,997 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:39,997 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:39,997 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:39,997 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:39,997 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:39,997 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:39,998 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:40,000 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,000 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596
2024-07-01 06:00:40,000 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:40,000 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:40,001 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:40,001 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:40,001 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,001 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,001 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: start as a follower, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}
2024-07-01 06:00:40,001 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:40,001 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3D02EEC07596,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3D02EEC07596,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:40,002 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:40,010 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(87)) - Pipeline Pipeline[ Id: 83d0b075-21bf-48bf-ac12-3d02eec07596, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:00:36.961Z[Etc/UTC]] verified from SCM and added to Recon pipeline metadata.
2024-07-01 06:00:40,010 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596
2024-07-01 06:00:40,011 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596.
2024-07-01 06:00:40,011 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: addNew group-9D3E094E5440:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-9D3E094E5440:java.util.concurrent.CompletableFuture@c27e03e[Not completed]
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: new RaftServerImpl for group-9D3E094E5440:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:40,013 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: ConfigurationManager, init=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:40,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:40,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:40,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:40,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:40,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:40,014 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:40,022 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis] (custom)
2024-07-01 06:00:40,023 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/6a54b320-18b2-409b-b307-9d3e094e5440 does not exist. Creating ...
2024-07-01 06:00:40,023 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:40,025 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/6a54b320-18b2-409b-b307-9d3e094e5440 has been successfully formatted.
2024-07-01 06:00:40,025 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9D3E094E5440: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:40,025 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:40,025 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:40,025 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,025 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:40,026 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:40,028 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:40,028 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440. Trying to get from SCM.
2024-07-01 06:00:40,030 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,030 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:40,030 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:40,030 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,031 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(87)) - Pipeline Pipeline[ Id: 6a54b320-18b2-409b-b307-9d3e094e5440, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:37.392Z[Etc/UTC]] verified from SCM and added to Recon pipeline metadata.
2024-07-01 06:00:40,032 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:40,035 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:40,036 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:40,036 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:40,038 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,038 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:40,039 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:40,039 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:40,039 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,039 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,043 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: start as a follower, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:40,043 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:40,043 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D3E094E5440,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-9D3E094E5440,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:40,044 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:40,045 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:40,046 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:40,167 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: addNew group-BC378716716F:[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-BC378716716F:java.util.concurrent.CompletableFuture@64d22adb[Not completed]
2024-07-01 06:00:40,169 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: new RaftServerImpl for group-BC378716716F:[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:00:40,169 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:40,169 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:40,169 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:40,169 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:40,169 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: ConfigurationManager, init=conf: {index: -1, cur=peers:[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:40,170 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:40,178 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:40,178 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:40,179 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:40,179 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:40,179 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:40,180 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:40,180 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:40,180 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:40,180 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis] (custom)
2024-07-01 06:00:40,180 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/5b142fd5-bd6f-4167-9b55-bc378716716f does not exist. Creating ...
2024-07-01 06:00:40,181 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/5b142fd5-bd6f-4167-9b55-bc378716716f/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:40,182 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/5b142fd5-bd6f-4167-9b55-bc378716716f has been successfully formatted.
2024-07-01 06:00:40,182 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-BC378716716F: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:40,182 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:40,182 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:40,182 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,183 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:40,183 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:40,185 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,185 [IPC Server handler 7 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-07-01 06:00:40,185 [IPC Server handler 7 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:40,185 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:40,185 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:40,185 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,186 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f. Trying to get from SCM.
2024-07-01 06:00:40,186 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f
2024-07-01 06:00:40,186 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:40,188 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(87)) - Pipeline Pipeline[ Id: 5b142fd5-bd6f-4167-9b55-bc378716716f, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, CreationTimestamp2024-07-01T06:00:37.171Z[Etc/UTC]] verified from SCM and added to Recon pipeline metadata.
2024-07-01 06:00:40,191 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:40,191 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/5b142fd5-bd6f-4167-9b55-bc378716716f
2024-07-01 06:00:40,192 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:40,192 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:40,192 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,193 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:40,193 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:40,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:40,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:40,194 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:40,195 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:40,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:40,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:40,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:40,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: start as a follower, conf=conf: {index: -1, cur=peers:[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:40,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:40,199 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState
2024-07-01 06:00:40,210 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BC378716716F,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:40,210 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-BC378716716F,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:40,210 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:40,210 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:40,210 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:40,210 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:40,210 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:40,211 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:40,211 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:40,212 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:40,212 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f
2024-07-01 06:00:40,212 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f.
2024-07-01 06:00:40,212 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: addNew group-9D3E094E5440:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-9D3E094E5440:java.util.concurrent.CompletableFuture@60eda299[Not completed]
2024-07-01 06:00:40,214 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: new RaftServerImpl for group-9D3E094E5440:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:00:40,214 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:40,214 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:40,214 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:40,214 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: ConfigurationManager, init=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:40,215 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:40,221 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:40,221 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:40,221 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:40,221 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:40,221 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:40,221 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:40,222 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:40,222 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:40,222 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis] (custom)
2024-07-01 06:00:40,222 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/6a54b320-18b2-409b-b307-9d3e094e5440 does not exist. Creating ...
2024-07-01 06:00:40,224 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:40,225 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/6a54b320-18b2-409b-b307-9d3e094e5440 has been successfully formatted.
2024-07-01 06:00:40,226 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9D3E094E5440: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:40,227 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:40,227 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:40,227 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,228 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:40,228 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:40,228 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:00:40,231 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:40,235 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,236 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:40,236 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:40,236 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,242 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:40,243 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:40,244 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:40,245 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,245 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:40,245 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:40,245 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:40,246 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,246 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,251 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: start as a follower, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:40,251 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:40,251 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState
2024-07-01 06:00:40,251 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D3E094E5440,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:40,251 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-9D3E094E5440,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:40,251 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:40,251 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:40,251 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:40,252 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:40,252 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:40,252 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:40,252 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:40,252 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:40,255 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:40,298 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: addNew group-9D3E094E5440:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-9D3E094E5440:java.util.concurrent.CompletableFuture@1eb76841[Not completed]
2024-07-01 06:00:40,299 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: new RaftServerImpl for group-9D3E094E5440:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:00:40,299 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:40,299 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:40,299 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:40,299 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: ConfigurationManager, init=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:40,300 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:40,330 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:40,332 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:40,332 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:40,332 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:40,333 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:40,333 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:40,335 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:40,335 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:40,335 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis] (custom)
2024-07-01 06:00:40,336 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/6a54b320-18b2-409b-b307-9d3e094e5440 does not exist. Creating ...
2024-07-01 06:00:40,338 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:40,342 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/6a54b320-18b2-409b-b307-9d3e094e5440 has been successfully formatted.
2024-07-01 06:00:40,344 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9D3E094E5440: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:40,345 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:40,345 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:40,345 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,345 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:40,346 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:40,348 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,348 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:40,349 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:40,349 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,349 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:40,349 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:40,350 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:40,350 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:40,350 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,350 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:40,351 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:40,351 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:40,351 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:40,351 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:40,351 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:40,353 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,353 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:40,353 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:40,353 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:40,353 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,353 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,355 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: start as a follower, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:40,355 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:40,355 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState
2024-07-01 06:00:40,356 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:40,356 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:40,356 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D3E094E5440,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:40,357 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-9D3E094E5440,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:40,357 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:40,357 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:40,358 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:40,358 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:40,359 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:40,359 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:40,371 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440.
2024-07-01 06:00:40,384 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: new RaftServerImpl for group-3F456FFC0A9F:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034] with ContainerStateMachine:uninitialized
2024-07-01 06:00:40,384 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:40,384 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:40,384 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:40,384 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:40,384 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:40,384 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:40,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:40,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: ConfigurationManager, init=conf: {index: -1, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:40,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:40,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:40,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:40,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:40,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:40,385 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:40,389 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: addNew group-3F456FFC0A9F:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034] returns group-3F456FFC0A9F:java.util.concurrent.CompletableFuture@3e344426[Not completed]
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis] (custom)
2024-07-01 06:00:40,393 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f does not exist. Creating ...
2024-07-01 06:00:40,395 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:40,400 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f has been successfully formatted.
2024-07-01 06:00:40,400 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-3F456FFC0A9F: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:40,401 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:40,401 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:40,401 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,401 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:40,401 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:40,403 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,404 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:40,404 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:40,404 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,404 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f
2024-07-01 06:00:40,405 [IPC Server handler 83 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-07-01 06:00:40,405 [IPC Server handler 83 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:40,405 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f. Trying to get from SCM.
2024-07-01 06:00:40,405 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:40,408 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(87)) - Pipeline Pipeline[ Id: fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f, Nodes: d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:d911fb7d-ae06-4770-ac9a-ead30a7876df, CreationTimestamp2024-07-01T06:00:37.387Z[Etc/UTC]] verified from SCM and added to Recon pipeline metadata.
2024-07-01 06:00:40,408 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1)
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:40,415 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:40,416 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:40,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:40,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:40,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:40,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,418 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,419 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: start as a follower, conf=conf: {index: -1, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}
2024-07-01 06:00:40,419 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:40,420 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3F456FFC0A9F,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3F456FFC0A9F,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:40,423 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:40,427 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f
2024-07-01 06:00:40,427 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f.
2024-07-01 06:00:40,432 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440.
2024-07-01 06:00:40,434 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f, PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440]
2024-07-01 06:00:40,437 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f moved to CLOSED state
2024-07-01 06:00:40,438 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:40,440 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 moved to CLOSED state
2024-07-01 06:00:40,445 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 4 pipelines in house.
2024-07-01 06:00:40,446 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f already exists in Recon pipeline metadata.
2024-07-01 06:00:40,447 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:00:40,448 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,450 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(109)) - Added new pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 from SCM.
2024-07-01 06:00:40,451 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,453 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(109)) - Added new pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 from SCM.
2024-07-01 06:00:40,600 [4873639b-1d87-440f-9147-409a0544c1cf-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - 4873639b-1d87-440f-9147-409a0544c1cf: addNew group-084CCD2B28B6:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043] returns group-084CCD2B28B6:java.util.concurrent.CompletableFuture@2ddcf048[Not completed]
2024-07-01 06:00:40,601 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - 4873639b-1d87-440f-9147-409a0544c1cf: new RaftServerImpl for group-084CCD2B28B6:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-07-01 06:00:40,601 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:40,601 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:40,601 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:40,601 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:40,601 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:40,601 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:40,601 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:40,602 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: ConfigurationManager, init=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:40,602 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:40,602 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:40,602 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:40,602 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:40,602 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:40,602 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:40,607 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:40,607 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:40,607 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:40,607 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:40,607 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:40,607 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:40,607 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:40,608 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:40,608 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis] (custom)
2024-07-01 06:00:40,608 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6 does not exist. Creating ...
2024-07-01 06:00:40,609 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:40,611 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6 has been successfully formatted.
2024-07-01 06:00:40,611 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-084CCD2B28B6: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:40,611 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:40,611 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:40,612 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,612 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:40,612 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:40,614 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-07-01 06:00:40,614 [IPC Server handler 2 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:40,615 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6
2024-07-01 06:00:40,615 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/ONE PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:00:40,615 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,615 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:40,616 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:40,616 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,616 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:40,616 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:40,616 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:40,619 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:40,620 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:40,622 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,622 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:40,622 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:40,622 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:40,622 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,622 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,631 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: start as a follower, conf=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043]|listeners:[], old=null}
2024-07-01 06:00:40,631 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:40,631 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState
2024-07-01 06:00:40,633 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:40,633 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-084CCD2B28B6,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:40,633 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-084CCD2B28B6,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:40,633 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:40,634 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:40,634 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:40,634 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:40,634 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:40,634 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:40,634 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:40,635 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6]
2024-07-01 06:00:40,635 [4873639b-1d87-440f-9147-409a0544c1cf-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6
2024-07-01 06:00:40,635 [4873639b-1d87-440f-9147-409a0544c1cf-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6.
2024-07-01 06:00:40,636 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 moved to CLOSED state
2024-07-01 06:00:40,639 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-07-01 06:00:40,640 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f already exists in Recon pipeline metadata.
2024-07-01 06:00:40,640 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:00:40,641 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,642 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,643 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,644 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,801 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - 7c590364-16f9-412e-8d8f-583652a307a8: addNew group-9AE4F3F9C8F1:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052] returns group-9AE4F3F9C8F1:java.util.concurrent.CompletableFuture@7987f96a[Not completed]
2024-07-01 06:00:40,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - 7c590364-16f9-412e-8d8f-583652a307a8: new RaftServerImpl for group-9AE4F3F9C8F1:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052] with ContainerStateMachine:uninitialized
2024-07-01 06:00:40,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:40,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:40,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:40,802 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-07-01 06:00:40,803 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:40,803 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:40,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: ConfigurationManager, init=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:40,803 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:40,804 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:40,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:40,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:40,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:40,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:40,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:40,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:40,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:40,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:40,808 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis] (custom)
2024-07-01 06:00:40,808 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 does not exist. Creating ...
2024-07-01 06:00:40,809 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:40,810 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 has been successfully formatted.
2024-07-01 06:00:40,810 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9AE4F3F9C8F1: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:40,810 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:40,810 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:40,810 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,810 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:40,811 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:40,812 [IPC Server handler 1 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-07-01 06:00:40,812 [IPC Server handler 1 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:40,812 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/ONE PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 reported by 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)
2024-07-01 06:00:40,813 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,813 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1
2024-07-01 06:00:40,813 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:40,813 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:40,814 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:40,814 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,814 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:40,814 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1
2024-07-01 06:00:40,814 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:40,814 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:40,814 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:40,815 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:40,815 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:40,815 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:40,815 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:40,815 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:40,815 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:40,817 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:40,817 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:40,817 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:40,817 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:40,817 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,817 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: start as a follower, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052]|listeners:[], old=null}
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 7c590364-16f9-412e-8d8f-583652a307a8: start 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9AE4F3F9C8F1,id=7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-9AE4F3F9C8F1,id=7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:40,818 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:40,819 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:40,819 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:40,819 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:40,819 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:40,820 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1
2024-07-01 06:00:40,820 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1.
2024-07-01 06:00:40,835 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1]
2024-07-01 06:00:40,836 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 moved to CLOSED state
2024-07-01 06:00:40,838 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-07-01 06:00:40,838 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f already exists in Recon pipeline metadata.
2024-07-01 06:00:40,839 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:00:40,839 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,840 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,841 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,841 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 already exists in Recon pipeline metadata.
2024-07-01 06:00:40,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:41,228 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:41,228 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:00:41,403 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:41,403 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1)
2024-07-01 06:00:41,439 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:41,613 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:41,803 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-07-01 06:00:41,803 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:41,803 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:41,812 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:41,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:42,027 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:42,028 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:00:42,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:42,803 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-07-01 06:00:42,804 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:42,804 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:42,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:43,027 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:00:43,027 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:43,228 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:43,228 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:00:43,402 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:43,403 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1)
2024-07-01 06:00:43,442 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:43,613 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:43,804 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-07-01 06:00:43,804 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:43,804 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:43,812 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:43,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:44,229 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:00:44,229 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:44,403 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1)
2024-07-01 06:00:44,403 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:44,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:44,804 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-07-01 06:00:44,805 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-07-01 06:00:44,805 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:44,813 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:44,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:45,027 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:45,027 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:00:45,162 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5160550169ns, electionTimeout:5160ms
2024-07-01 06:00:45,162 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState
2024-07-01 06:00:45,162 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:00:45,162 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:00:45,163 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2
2024-07-01 06:00:45,163 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}
2024-07-01 06:00:45,163 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2 PRE_VOTE round 0: result PASSED (term=0)
2024-07-01 06:00:45,164 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}
2024-07-01 06:00:45,164 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2 ELECTION round 0: result PASSED (term=1)
2024-07-01 06:00:45,164 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2
2024-07-01 06:00:45,165 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:00:45,165 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:00:45,165 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,165 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:00:45,166 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:00:45,166 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:00:45,166 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:00:45,166 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:00:45,166 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:00:45,167 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:45,167 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:00:45,167 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,167 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:00:45,167 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderStateImpl
2024-07-01 06:00:45,167 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:00:45,167 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-3D02EEC07596 with new leaderId: bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:45,168 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: change Leader from null to bfc6da33-104c-4d07-98ee-1aed7336cdfb at term 1 for becomeLeader, leader elected after 5192ms
2024-07-01 06:00:45,168 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:45,169 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:45,169 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: set configuration conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}
2024-07-01 06:00:45,172 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:00:45,173 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:45,176 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/83d0b075-21bf-48bf-ac12-3d02eec07596/current/log_inprogress_0
2024-07-01 06:00:45,178 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:00:45,198 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5155492994ns, electionTimeout:5153ms
2024-07-01 06:00:45,198 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState
2024-07-01 06:00:45,198 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:00:45,199 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:00:45,199 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3
2024-07-01 06:00:45,199 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,202 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:45,202 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:45,202 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034
2024-07-01 06:00:45,203 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025
2024-07-01 06:00:45,210 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: receive requestVote(PRE_VOTE, bfc6da33-104c-4d07-98ee-1aed7336cdfb, group-9D3E094E5440, 0, (t:0, i:0))
2024-07-01 06:00:45,211 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: receive requestVote(PRE_VOTE, bfc6da33-104c-4d07-98ee-1aed7336cdfb, group-9D3E094E5440, 0, (t:0, i:0))
2024-07-01 06:00:45,212 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FOLLOWER: accept PRE_VOTE from bfc6da33-104c-4d07-98ee-1aed7336cdfb: our priority 0 <= candidate's priority 1
2024-07-01 06:00:45,212 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FOLLOWER: accept PRE_VOTE from bfc6da33-104c-4d07-98ee-1aed7336cdfb: our priority 0 <= candidate's priority 1
2024-07-01 06:00:45,214 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440 replies to PRE_VOTE vote request: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-d911fb7d-ae06-4770-ac9a-ead30a7876df#0:OK-t0. Peer's state: d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440:t0, leader=null, voted=, raftlog=Memoized:d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,214 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440 replies to PRE_VOTE vote request: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#0:OK-t0. Peer's state: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440:t0, leader=null, voted=, raftlog=Memoized:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,219 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-07-01 06:00:45,219 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#0:OK-t0
2024-07-01 06:00:45,219 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3 PRE_VOTE round 0: result PASSED
2024-07-01 06:00:45,221 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,222 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:45,222 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:45,224 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: receive requestVote(ELECTION, bfc6da33-104c-4d07-98ee-1aed7336cdfb, group-9D3E094E5440, 1, (t:0, i:0))
2024-07-01 06:00:45,224 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: receive requestVote(ELECTION, bfc6da33-104c-4d07-98ee-1aed7336cdfb, group-9D3E094E5440, 1, (t:0, i:0))
2024-07-01 06:00:45,224 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FOLLOWER: accept ELECTION from bfc6da33-104c-4d07-98ee-1aed7336cdfb: our priority 0 <= candidate's priority 1
2024-07-01 06:00:45,224 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:45,224 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState
2024-07-01 06:00:45,224 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState
2024-07-01 06:00:45,224 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FOLLOWER: accept ELECTION from bfc6da33-104c-4d07-98ee-1aed7336cdfb: our priority 0 <= candidate's priority 1
2024-07-01 06:00:45,224 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState was interrupted
2024-07-01 06:00:45,225 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: set firstElectionSinceStartup to false for candidate:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:45,224 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:45,225 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState
2024-07-01 06:00:45,225 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState
2024-07-01 06:00:45,225 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState was interrupted
2024-07-01 06:00:45,226 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440 replies to ELECTION vote request: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-d911fb7d-ae06-4770-ac9a-ead30a7876df#0:OK-t1. Peer's state: d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440:t1, leader=null, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,227 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-07-01 06:00:45,227 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-d911fb7d-ae06-4770-ac9a-ead30a7876df#0:OK-t1
2024-07-01 06:00:45,227 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3 ELECTION round 0: result PASSED
2024-07-01 06:00:45,227 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3
2024-07-01 06:00:45,227 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:00:45,227 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:00:45,228 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,228 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:00:45,228 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:00:45,228 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:00:45,228 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:00:45,229 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:00:45,229 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:00:45,229 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:45,229 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:00:45,229 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,229 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:00:45,230 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: set firstElectionSinceStartup to false for candidate:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:45,232 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440 replies to ELECTION vote request: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#0:OK-t1. Peer's state: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440:t1, leader=null, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,236 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-07-01 06:00:45,236 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:45,236 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-07-01 06:00:45,238 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-07-01 06:00:45,239 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-07-01 06:00:45,239 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:45,240 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-07-01 06:00:45,240 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-07-01 06:00:45,240 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-07-01 06:00:45,242 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:45,242 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:00:45,248 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-07-01 06:00:45,248 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:45,248 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-07-01 06:00:45,248 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-07-01 06:00:45,249 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-07-01 06:00:45,249 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:45,249 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-07-01 06:00:45,249 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-07-01 06:00:45,250 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-07-01 06:00:45,250 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:45,250 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:00:45,251 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderStateImpl
2024-07-01 06:00:45,251 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:00:45,254 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-9D3E094E5440 with new leaderId: bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:45,254 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: change Leader from null to bfc6da33-104c-4d07-98ee-1aed7336cdfb at term 1 for becomeLeader, leader elected after 5237ms
2024-07-01 06:00:45,255 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:45,255 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderElection3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: set configuration conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,256 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-07-01 06:00:45,256 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:00:45,255 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:45,256 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:45,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-07-01 06:00:45,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(203)) - HealthyPipelineSafeModeRule rule is successfully validated
2024-07-01 06:00:45,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(218)) - ScmSafeModeManager, all rules are successfully validated
2024-07-01 06:00:45,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2024-07-01 06:00:45,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-07-01 06:00:45,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(258)) - Service BackgroundPipelineCreator transitions to RUNNING.
2024-07-01 06:00:45,261 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2024-07-01 06:00:45,261 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-07-01 06:00:45,261 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(247)) - notifyStatusChanged:RUNNING
2024-07-01 06:00:45,261 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1406)) - Service ReplicationManager transitions to RUNNING.
2024-07-01 06:00:45,264 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/current/log_inprogress_0
2024-07-01 06:00:45,264 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(134)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-07-01 06:00:45,295 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-9D3E094E5440 with new leaderId: bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:45,296 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: change Leader from null to bfc6da33-104c-4d07-98ee-1aed7336cdfb at term 1 for appendEntries, leader elected after 5080ms
2024-07-01 06:00:45,299 [d911fb7d-ae06-4770-ac9a-ead30a7876df-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-9D3E094E5440 with new leaderId: bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:45,299 [d911fb7d-ae06-4770-ac9a-ead30a7876df-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: change Leader from null to bfc6da33-104c-4d07-98ee-1aed7336cdfb at term 1 for appendEntries, leader elected after 4999ms
2024-07-01 06:00:45,303 [d911fb7d-ae06-4770-ac9a-ead30a7876df-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: set configuration conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,305 [d911fb7d-ae06-4770-ac9a-ead30a7876df-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:45,306 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:45,315 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/current/log_inprogress_0
2024-07-01 06:00:45,321 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: set configuration conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,322 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:45,322 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:45,325 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:00:45,331 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/current/log_inprogress_0
2024-07-01 06:00:45,363 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5164237690ns, electionTimeout:5151ms
2024-07-01 06:00:45,363 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState
2024-07-01 06:00:45,363 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:00:45,363 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:00:45,363 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4
2024-07-01 06:00:45,364 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,364 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4 PRE_VOTE round 0: result PASSED (term=0)
2024-07-01 06:00:45,366 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,366 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4 ELECTION round 0: result PASSED (term=1)
2024-07-01 06:00:45,366 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4
2024-07-01 06:00:45,366 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:00:45,366 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:00:45,366 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,366 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:00:45,367 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:00:45,367 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:00:45,367 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderStateImpl
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:00:45,368 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-BC378716716F with new leaderId: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:45,369 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: change Leader from null to bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 at term 1 for becomeLeader, leader elected after 5198ms
2024-07-01 06:00:45,369 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:45,369 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:45,371 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderElection4] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: set configuration conf: {index: 0, cur=peers:[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:45,377 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/5b142fd5-bd6f-4167-9b55-bc378716716f/current/log_inprogress_0
2024-07-01 06:00:45,379 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:00:45,445 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:45,514 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5094517700ns, electionTimeout:5091ms
2024-07-01 06:00:45,514 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState
2024-07-01 06:00:45,515 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:00:45,515 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:00:45,515 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5
2024-07-01 06:00:45,515 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}
2024-07-01 06:00:45,515 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5 PRE_VOTE round 0: result PASSED (term=0)
2024-07-01 06:00:45,517 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}
2024-07-01 06:00:45,517 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5 ELECTION round 0: result PASSED (term=1)
2024-07-01 06:00:45,517 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5
2024-07-01 06:00:45,517 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:00:45,517 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:00:45,518 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,518 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:00:45,519 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:00:45,519 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:00:45,519 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderStateImpl
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:00:45,520 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-3F456FFC0A9F with new leaderId: d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:45,521 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: change Leader from null to d911fb7d-ae06-4770-ac9a-ead30a7876df at term 1 for becomeLeader, leader elected after 5135ms
2024-07-01 06:00:45,521 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:45,522 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:45,527 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: set configuration conf: {index: 0, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}
2024-07-01 06:00:45,530 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f/current/log_inprogress_0
2024-07-01 06:00:45,536 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:00:45,709 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5077784239ns, electionTimeout:5075ms
2024-07-01 06:00:45,709 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState
2024-07-01 06:00:45,709 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:00:45,709 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:00:45,709 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6
2024-07-01 06:00:45,710 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043]|listeners:[], old=null}
2024-07-01 06:00:45,710 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6 PRE_VOTE round 0: result PASSED (term=0)
2024-07-01 06:00:45,711 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043]|listeners:[], old=null}
2024-07-01 06:00:45,711 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6 ELECTION round 0: result PASSED (term=1)
2024-07-01 06:00:45,711 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6
2024-07-01 06:00:45,711 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:00:45,711 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:00:45,712 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,712 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:00:45,712 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:00:45,712 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:00:45,712 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderStateImpl
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:00:45,713 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-084CCD2B28B6 with new leaderId: 4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:45,714 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: change Leader from null to 4873639b-1d87-440f-9147-409a0544c1cf at term 1 for becomeLeader, leader elected after 5111ms
2024-07-01 06:00:45,714 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:45,714 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: set configuration conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043]|listeners:[], old=null}
2024-07-01 06:00:45,715 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:45,722 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6/current/log_inprogress_0
2024-07-01 06:00:45,724 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:00:45,805 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-07-01 06:00:45,805 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Cluster exits safe mode
2024-07-01 06:00:45,805 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-07-01 06:00:45,806 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-07-01 06:00:45,806 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-07-01 06:00:45,808 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-07-01 06:00:45,809 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-07-01 06:00:45,840 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5022514919ns, electionTimeout:5022ms
2024-07-01 06:00:45,841 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState
2024-07-01 06:00:45,841 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:00:45,841 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:00:45,841 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 7c590364-16f9-412e-8d8f-583652a307a8: start 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7
2024-07-01 06:00:45,841 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052]|listeners:[], old=null}
2024-07-01 06:00:45,841 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7 PRE_VOTE round 0: result PASSED (term=0)
2024-07-01 06:00:45,843 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052]|listeners:[], old=null}
2024-07-01 06:00:45,843 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7 ELECTION round 0: result PASSED (term=1)
2024-07-01 06:00:45,843 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7
2024-07-01 06:00:45,843 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:00:45,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:45,843 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:00:45,844 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,844 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:00:45,844 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:00:45,844 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:00:45,844 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:00:45,845 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:00:45,845 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:00:45,845 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:45,845 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:00:45,845 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:00:45,846 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:00:45,846 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 7c590364-16f9-412e-8d8f-583652a307a8: start 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderStateImpl
2024-07-01 06:00:45,846 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:00:45,846 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-9AE4F3F9C8F1 with new leaderId: 7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:45,846 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: change Leader from null to 7c590364-16f9-412e-8d8f-583652a307a8 at term 1 for becomeLeader, leader elected after 5042ms
2024-07-01 06:00:45,846 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:00:45,847 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:00:45,851 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: set configuration conf: {index: 0, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052]|listeners:[], old=null}
2024-07-01 06:00:45,855 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1/current/log_inprogress_0
2024-07-01 06:00:45,859 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:00:46,071 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(473)) - Creating Volume: vol1, with user15275 as owner and space quota set to -1 bytes, counts quota set to -1
2024-07-01 06:00:46,107 [om1-OMStateMachineApplyTransactionThread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(198)) - created volume:vol1 for user:user15275
2024-07-01 06:00:46,119 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-07-01 06:00:46,119 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-07-01 06:00:46,120 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-07-01 06:00:46,120 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-07-01 06:00:46,120 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-07-01 06:00:46,120 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(699)) - Creating Bucket: vol1/bucket1, with bucket layout FILE_SYSTEM_OPTIMIZED, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2024-07-01 06:00:46,131 [om1-OMStateMachineApplyTransactionThread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(293)) - created bucket: bucket1 of layout FILE_SYSTEM_OPTIMIZED in volume: vol1
2024-07-01 06:00:46,168 [IPC Server handler 0 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(144)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2024-07-01 06:00:46,175 [IPC Server handler 0 on default port 15001] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(257)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-07-01 06:00:46,175 [IPC Server handler 0 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(144)) - Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-07-01 06:00:46,239 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2024-07-01 06:00:46,264 [main] INFO  scm.XceiverClientRatis (XceiverClientRatis.java:<init>(139)) - WatchType ALL_COMMITTED. Majority 2, 
2024-07-01 06:00:46,417 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:46,417 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:46,417 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:46,417 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:46,418 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:46,418 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:46,422 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(244)) - Successfully added container #1 to Recon.
2024-07-01 06:00:46,427 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(244)) - Successfully added container #1 to Recon.
2024-07-01 06:00:46,427 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(244)) - Successfully added container #1 to Recon.
2024-07-01 06:00:46,430 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 17 millisec, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:46,431 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 14 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:46,431 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 17 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:46,455 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:46,455 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:46,455 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:46,455 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:46,455 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:46,455 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:46,455 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-07-01 06:00:46,574 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 0
2024-07-01 06:00:46,574 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:46,574 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(581)) - Obtaining full snapshot from Ozone Manager
2024-07-01 06:00:46,575 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:checkAndValidateReconDbPermissions(646)) - Permissions for Recon DB directory '/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/recon' meet the minimum required permissions '750'
2024-07-01 06:00:46,587 [qtp193743819-412] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:doGet(301)) - Received GET request to obtain DB checkpoint snapshot
2024-07-01 06:00:46,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:47,459 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:47,459 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:47,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:47,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:47,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:47,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:47,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:47,523 [qtp193743819-412] INFO  db.RDBCheckpointManager (RDBCheckpointManager.java:createCheckpoint(89)) - Created checkpoint in rocksDB at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/db.checkpoints/om.db_checkpoint_1719813647500 in 23 milliseconds
2024-07-01 06:00:47,546 [qtp193743819-412] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(225)) - Time taken to write the checkpoint to response output stream: 16 milliseconds
2024-07-01 06:00:47,547 [qtp193743819-412] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(228)) - Excluded SST [] from the latest checkpoint.
2024-07-01 06:00:47,556 [qtp193743819-412] INFO  db.RocksDBCheckpoint (RocksDBCheckpoint.java:cleanupCheckpoint(78)) - Cleaning up RocksDB checkpoint at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/db.checkpoints/om.db_checkpoint_1719813647500
2024-07-01 06:00:47,564 [Recon-SyncOM-1] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:47,564 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(437)) - Attempting to update Recon OM DB with new snapshot located at: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/recon/om.snapshot.db_1719813646575
2024-07-01 06:00:47,565 [Recon-SyncOM-1] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-07-01 06:00:47,613 [Recon-SyncOM-1] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:initializeNewRdbStore(107)) - Created OM DB handle from snapshot at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/recon/om.snapshot.db_1719813646575.
2024-07-01 06:00:47,618 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(441)) - Successfully updated Recon OM DB with new snapshot.
2024-07-01 06:00:47,621 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(594)) - Calling reprocess on Recon tasks.
2024-07-01 06:00:47,755 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-07-01 06:00:47,756 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-07-01 06:00:47,791 [Recon-SyncOM-1] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:00:47,791 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:47,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-07-01 06:00:48,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:48,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:48,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:48,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:48,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:48,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:48,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:48,706 [IPC Server handler 2 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenanceNodes(496)) - Force flag = true. Skip checking if maintenance is possible for dns: [bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)]
2024-07-01 06:00:48,707 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) moved to HEALTHY state.
2024-07-01 06:00:48,707 [IPC Server handler 2 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(532)) - Starting Maintenance for node bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:00:48,707 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:00:48,718 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:48,718 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: FCR, size: 0}
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-07-01 06:00:48,739 [qtp260382211-461] INFO  impl.Tools (JooqLogger.java:info(338)) - Kotlin is available, but not kotlin-reflect. Add the kotlin-reflect dependency to better use Kotlin features like data classes
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-07-01 06:00:48,792 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:48,792 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:48,793 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:48,793 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:48,798 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:48,798 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:48,800 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:48,845 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:00:48,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@44524022. There are 2 pipelines
2024-07-01 06:00:48,858 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1). Finalizing its pipelines [PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596, PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440]
2024-07-01 06:00:48,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:48,860 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 moved to CLOSED state
2024-07-01 06:00:48,862 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #1 closed for pipeline=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:48,862 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2024-07-01 06:00:48,862 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 moved to CLOSED state
2024-07-01 06:00:49,413 [IPC Server handler 11 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-07-01 06:00:49,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:49,468 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:49,468 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:49,468 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:49,468 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:49,468 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:49,468 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:49,800 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:49,801 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:49,801 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:49,801 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:49,803 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:49,803 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:49,805 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:49,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) with datanode deadline 1719814219846 and scm deadline 1719814249846
2024-07-01 06:00:49,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) with datanode deadline 1719814219846 and scm deadline 1719814249846
2024-07-01 06:00:49,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) with datanode deadline 1719814219846 and scm deadline 1719814249846
2024-07-01 06:00:49,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:00:49,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@44524022. There are 2 pipelines
2024-07-01 06:00:49,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:50,414 [IPC Server handler 12 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-07-01 06:00:50,414 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-07-01 06:00:50,471 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:50,472 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:50,472 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:50,472 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:50,472 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:50,472 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:50,472 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:50,805 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:50,805 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:50,805 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:50,805 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:50,807 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:50,808 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:50,809 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:50,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) with datanode deadline 1719814220847 and scm deadline 1719814250847
2024-07-01 06:00:50,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) with datanode deadline 1719814220847 and scm deadline 1719814250847
2024-07-01 06:00:50,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) with datanode deadline 1719814220847 and scm deadline 1719814250847
2024-07-01 06:00:50,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:00:50,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@44524022. There are 2 pipelines
2024-07-01 06:00:50,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:51,412 [IPC Server handler 3 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-07-01 06:00:51,414 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:00:51,415 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:00:51,476 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:51,477 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:51,477 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:51,477 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:51,477 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:51,477 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:51,477 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:51,810 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:51,810 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:51,810 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:51,810 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:51,812 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:51,812 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:51,814 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:51,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) with datanode deadline 1719814221848 and scm deadline 1719814251848
2024-07-01 06:00:51,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) with datanode deadline 1719814221848 and scm deadline 1719814251848
2024-07-01 06:00:51,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-07-01T06:00:48.861706220Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) with datanode deadline 1719814221848 and scm deadline 1719814251848
2024-07-01 06:00:51,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:00:51,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@44524022. There are 2 pipelines
2024-07-01 06:00:51,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:52,420 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:checkContainerStateAndUpdate(199)) - Container #1 has state OPEN, but given state is CLOSING.
2024-07-01 06:00:52,420 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:checkContainerStateAndUpdate(199)) - Container #1 has state OPEN, but given state is CLOSING.
2024-07-01 06:00:52,425 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:52,426 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:52,433 [d911fb7d-ae06-4770-ac9a-ead30a7876df-CloseContainerThread-2] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-07-01 06:00:52,434 [d911fb7d-ae06-4770-ac9a-ead30a7876df-CloseContainerThread-2] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-07-01 06:00:52,434 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-CloseContainerThread-1] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-07-01 06:00:52,435 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-07-01 06:00:52,437 [d911fb7d-ae06-4770-ac9a-ead30a7876df-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-07-01 06:00:52,437 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-CloseContainerThread-2] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-07-01 06:00:52,439 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-07-01 06:00:52,439 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-07-01 06:00:52,440 [d911fb7d-ae06-4770-ac9a-ead30a7876df-CloseContainerThread-1] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-07-01 06:00:52,446 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-07-01 06:00:52,447 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-07-01 06:00:52,447 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-07-01 06:00:52,449 [d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-07-01 06:00:52,450 [d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-07-01 06:00:52,451 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) reported CLOSED replica with index 0.
2024-07-01 06:00:52,451 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) reported CLOSED replica with index 0.
2024-07-01 06:00:52,452 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:00:52,453 [d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-07-01 06:00:52,454 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ContainerOp-6a54b320-18b2-409b-b307-9d3e094e5440-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-07-01 06:00:52,480 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:52,481 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:52,481 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:52,481 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:52,481 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:52,481 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:52,481 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:52,814 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:52,814 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:52,814 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:52,814 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:52,816 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:52,816 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:52,818 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:52,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 2 milliseconds for processing 1 containers.
2024-07-01 06:00:52,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@44524022. There are 2 pipelines
2024-07-01 06:00:52,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:53,484 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:53,484 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:53,484 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:53,484 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:53,484 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:53,484 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:53,484 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:53,818 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:53,818 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:53,818 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:53,819 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:53,821 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:53,821 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:53,823 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:53,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:00:53,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@44524022. There are 2 pipelines
2024-07-01 06:00:53,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:54,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:54,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:54,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:54,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:54,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:54,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:54,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:54,689 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 since it stays at CLOSED stage.
2024-07-01 06:00:54,690 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 close command to datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:54,691 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 83d0b075-21bf-48bf-ac12-3d02eec07596, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:00:36.961Z[Etc/UTC]] removed.
2024-07-01 06:00:54,691 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 since it stays at CLOSED stage.
2024-07-01 06:00:54,691 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 close command to datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:54,691 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 close command to datanode d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:54,691 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 close command to datanode bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:54,691 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 6a54b320-18b2-409b-b307-9d3e094e5440, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:00:37.392Z[Etc/UTC]] removed.
2024-07-01 06:00:54,823 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:54,823 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:54,823 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:54,823 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:54,825 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:54,826 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:54,827 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:54,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:00:54,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@44524022 has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-07-01 06:00:54,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) has entered maintenance
2024-07-01 06:00:54,860 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:54,860 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) moved to HEALTHY state.
2024-07-01 06:00:54,860 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:00:54,861 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 to datanode:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:54,861 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 to datanode:4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:54,861 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 to datanode:7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:54,862 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 021f4cea-3012-4c29-83fe-bdbb6172c2d0, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 07c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:54.860973558Z[Etc/UTC]]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-07-01 06:00:55,003 [IPC Server handler 5 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenanceNodes(496)) - Force flag = true. Skip checking if maintenance is possible for dns: [d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1)]
2024-07-01 06:00:55,004 [IPC Server handler 5 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(532)) - Starting Maintenance for node d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1)
2024-07-01 06:00:55,004 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) moved to HEALTHY state.
2024-07-01 06:00:55,004 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-07-01 06:00:55,452 [IPC Server handler 45 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-07-01 06:00:55,455 [IPC Server handler 47 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-07-01 06:00:55,456 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 is not found
2024-07-01 06:00:55,457 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:00:55,491 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:55,491 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:55,491 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:55,491 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:55,491 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:55,491 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:55,491 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:55,828 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:55,828 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:55,828 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:55,828 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:55,830 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:55,830 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:55,832 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:55,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:00:55,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001. There are 1 pipelines
2024-07-01 06:00:55,858 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1). Finalizing its pipelines [PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f]
2024-07-01 06:00:55,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:55,859 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f moved to CLOSED state
2024-07-01 06:00:56,451 [IPC Server handler 45 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-07-01 06:00:56,452 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 is not found
2024-07-01 06:00:56,452 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 is not found
2024-07-01 06:00:56,453 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:00:56,453 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:00:56,454 [IPC Server handler 47 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-07-01 06:00:56,455 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 is not found
2024-07-01 06:00:56,469 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: remove    LEADER bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440:t1, leader=bfc6da33-104c-4d07-98ee-1aed7336cdfb, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLog:OPENED:c8:last(t:1, i:8), conf=conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null} RUNNING
2024-07-01 06:00:56,470 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: shutdown
2024-07-01 06:00:56,471 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D3E094E5440,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:56,471 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-LeaderStateImpl
2024-07-01 06:00:56,471 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-07-01 06:00:56,472 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440->d911fb7d-ae06-4770-ac9a-ead30a7876df-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440->d911fb7d-ae06-4770-ac9a-ead30a7876df-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-07-01 06:00:56,472 [grpc-default-executor-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-PendingRequests: sendNotLeaderResponses
2024-07-01 06:00:56,473 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Completed APPEND_ENTRIES, lastRequest: null
2024-07-01 06:00:56,480 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Completed APPEND_ENTRIES, lastRequest: bfc6da33-104c-4d07-98ee-1aed7336cdfb->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#24-t1,previous=(t:1, i:7),leaderCommit=7,initializing? false,entries: size=1, first=(t:1, i:8), METADATAENTRY(c:7)
2024-07-01 06:00:56,480 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: Completed APPEND_ENTRIES, lastRequest: null
2024-07-01 06:00:56,481 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Completed APPEND_ENTRIES, lastReply: null
2024-07-01 06:00:56,481 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: Completed APPEND_ENTRIES, lastRequest: bfc6da33-104c-4d07-98ee-1aed7336cdfb->d911fb7d-ae06-4770-ac9a-ead30a7876df#25-t1,previous=(t:1, i:7),leaderCommit=7,initializing? false,entries: size=1, first=(t:1, i:8), METADATAENTRY(c:7)
2024-07-01 06:00:56,482 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: Completed APPEND_ENTRIES, lastReply: null
2024-07-01 06:00:56,482 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "bfc6da33-104c-4d07-98ee-1aed7336cdfb"
  replyId: "bd7a4aed-4c16-4f29-bb4e-36cd0e487b91"
  raftGroupId {
    id: "jT\263 \030\262@\233\263\a\235>\tNT@"
  }
  callId: 27
  success: true
}
term: 1
nextIndex: 9
followerCommit: 8
matchIndex: 18446744073709551615
isHearbeat: true

2024-07-01 06:00:56,483 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "bfc6da33-104c-4d07-98ee-1aed7336cdfb"
  replyId: "d911fb7d-ae06-4770-ac9a-ead30a7876df"
  raftGroupId {
    id: "jT\263 \030\262@\233\263\a\235>\tNT@"
  }
  callId: 28
  success: true
}
term: 1
nextIndex: 9
followerCommit: 8
matchIndex: 18446744073709551615
isHearbeat: true

2024-07-01 06:00:56,484 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-9D3E094E5440: Taking a snapshot at:(t:1, i:8) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/sm/snapshot.1_8
2024-07-01 06:00:56,486 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440->d911fb7d-ae06-4770-ac9a-ead30a7876df-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:00:56,487 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440->d911fb7d-ae06-4770-ac9a-ead30a7876df-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:00:56,489 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:00:56,490 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:00:56,490 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater: set stopIndex = 8
2024-07-01 06:00:56,495 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:56,495 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:56,495 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:56,495 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:56,495 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:56,495 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:56,495 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:56,515 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-9D3E094E5440: Finished taking a snapshot at:(t:1, i:8) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/sm/snapshot.1_8 took: 31 ms
2024-07-01 06:00:56,516 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater: Took a snapshot at index 8
2024-07-01 06:00:56,516 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 8
2024-07-01 06:00:56,520 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:8)
2024-07-01 06:00:56,521 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:00:56,717 [4873639b-1d87-440f-9147-409a0544c1cf-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - 4873639b-1d87-440f-9147-409a0544c1cf: addNew group-BDBB6172C2D0:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-BDBB6172C2D0:java.util.concurrent.CompletableFuture@29e3712b[Not completed]
2024-07-01 06:00:56,718 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - 4873639b-1d87-440f-9147-409a0544c1cf: new RaftServerImpl for group-BDBB6172C2D0:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: ConfigurationManager, init=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:56,719 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:56,720 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:56,720 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:56,724 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis] (custom)
2024-07-01 06:00:56,725 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0 does not exist. Creating ...
2024-07-01 06:00:56,726 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:56,727 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0 has been successfully formatted.
2024-07-01 06:00:56,727 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-BDBB6172C2D0: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:56,727 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:56,727 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:56,728 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,728 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:56,728 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:56,728 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0. Trying to get from SCM.
2024-07-01 06:00:56,730 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:56,730 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:56,730 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:56,730 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,735 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:56,735 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0
2024-07-01 06:00:56,735 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:56,735 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:56,735 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:56,735 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:56,735 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:56,735 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:56,736 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:56,736 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:56,736 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:56,738 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,738 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:56,738 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:56,738 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:56,738 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:56,738 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:56,740 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(87)) - Pipeline Pipeline[ Id: 021f4cea-3012-4c29-83fe-bdbb6172c2d0, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 07c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:00:54.860Z[Etc/UTC]] verified from SCM and added to Recon pipeline metadata.
2024-07-01 06:00:56,741 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:00:56,741 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: start as a follower, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:56,741 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:56,741 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState
2024-07-01 06:00:56,741 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:56,741 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:56,741 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:56,741 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:00:56,742 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:56,742 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:56,742 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:56,742 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:56,742 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:56,742 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:56,743 [4873639b-1d87-440f-9147-409a0544c1cf-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0
2024-07-01 06:00:56,749 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: addNew group-BDBB6172C2D0:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-BDBB6172C2D0:java.util.concurrent.CompletableFuture@69ea050f[Not completed]
2024-07-01 06:00:56,750 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: new RaftServerImpl for group-BDBB6172C2D0:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: ConfigurationManager, init=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:56,751 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:56,755 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:56,755 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:56,755 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:56,756 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:56,756 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:56,756 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:56,756 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:56,756 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:56,756 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis] (custom)
2024-07-01 06:00:56,756 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0 does not exist. Creating ...
2024-07-01 06:00:56,757 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:56,758 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0 has been successfully formatted.
2024-07-01 06:00:56,759 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-BDBB6172C2D0: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:56,759 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:56,759 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:56,760 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 is not found
2024-07-01 06:00:56,760 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,761 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:00:56,761 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:56,762 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:56,765 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:56,766 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:56,767 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:56,767 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,768 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:56,768 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0
2024-07-01 06:00:56,768 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:56,768 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:56,769 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:56,769 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:56,769 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:56,769 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:56,769 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:56,769 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:56,770 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:56,772 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,772 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:56,772 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:56,772 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:56,772 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:56,772 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:56,775 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: start as a follower, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:56,775 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:56,775 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState
2024-07-01 06:00:56,776 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:56,776 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:56,777 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:56,777 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:56,777 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:56,777 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:56,777 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:56,777 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:56,777 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:56,777 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:56,788 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - 7c590364-16f9-412e-8d8f-583652a307a8: addNew group-BDBB6172C2D0:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-BDBB6172C2D0:java.util.concurrent.CompletableFuture@6c394088[Not completed]
2024-07-01 06:00:56,789 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - 7c590364-16f9-412e-8d8f-583652a307a8: new RaftServerImpl for group-BDBB6172C2D0:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:00:56,789 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:00:56,789 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:00:56,789 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:00:56,789 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:00:56,789 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:00:56,789 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:00:56,790 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:00:56,790 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: ConfigurationManager, init=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:00:56,790 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:00:56,790 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:00:56,790 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:00:56,790 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:00:56,790 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:00:56,790 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:00:56,794 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:00:56,794 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:00:56,794 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:00:56,794 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:00:56,794 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:00:56,795 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:00:56,795 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:00:56,795 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:00:56,795 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis] (custom)
2024-07-01 06:00:56,795 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0 does not exist. Creating ...
2024-07-01 06:00:56,796 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:00:56,797 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0 has been successfully formatted.
2024-07-01 06:00:56,797 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-BDBB6172C2D0: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:00:56,797 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:00:56,797 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:00:56,798 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,798 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:00:56,798 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:00:56,799 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)
2024-07-01 06:00:56,801 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:56,801 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:00:56,801 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:00:56,801 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,801 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:00:56,801 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0
2024-07-01 06:00:56,801 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:00:56,801 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:00:56,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:00:56,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:00:56,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:00:56,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:00:56,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:00:56,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:00:56,802 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:00:56,804 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:00:56,805 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:00:56,805 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:00:56,805 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:00:56,806 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:56,806 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:00:56,806 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: start as a follower, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:00:56,806 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 7c590364-16f9-412e-8d8f-583652a307a8: start 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:00:56,807 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:00:56,808 [7c590364-16f9-412e-8d8f-583652a307a8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:00:56,811 [4873639b-1d87-440f-9147-409a0544c1cf-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0.
2024-07-01 06:00:56,832 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:56,832 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:56,832 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:56,832 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:56,834 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:56,834 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:56,836 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:56,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:00:56,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001. There are 1 pipelines
2024-07-01 06:00:56,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:57,442 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440-SegmentedRaftLogWorker close()
2024-07-01 06:00:57,444 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-9D3E094E5440: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:57,451 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: remove    LEADER bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596:t1, leader=bfc6da33-104c-4d07-98ee-1aed7336cdfb, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLog:OPENED:c0:last(t:1, i:0), conf=conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null} RUNNING
2024-07-01 06:00:57,451 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: shutdown
2024-07-01 06:00:57,451 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3D02EEC07596,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:00:57,451 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-LeaderStateImpl
2024-07-01 06:00:57,451 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-PendingRequests: sendNotLeaderResponses
2024-07-01 06:00:57,452 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:00:57,453 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-3D02EEC07596: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/83d0b075-21bf-48bf-ac12-3d02eec07596/sm/snapshot.1_0
2024-07-01 06:00:57,453 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-3D02EEC07596: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/83d0b075-21bf-48bf-ac12-3d02eec07596/sm/snapshot.1_0 took: 0 ms
2024-07-01 06:00:57,453 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:00:57,454 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:00:57,454 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:00:57,454 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:00:57,455 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 is not found
2024-07-01 06:00:57,456 [IPC Server handler 43 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-07-01 06:00:57,456 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-07-01 06:00:57,457 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 is not found
2024-07-01 06:00:57,457 [d911fb7d-ae06-4770-ac9a-ead30a7876df-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-07-01 06:00:57,458 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:00:57,458 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:00:57,461 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: remove  FOLLOWER d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440:t1, leader=bfc6da33-104c-4d07-98ee-1aed7336cdfb, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLog:OPENED:c8:last(t:1, i:8), conf=conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null} RUNNING
2024-07-01 06:00:57,461 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: shutdown
2024-07-01 06:00:57,461 [grpc-default-executor-4] WARN  server.RaftServer (RaftServerProxy.java:remove(107)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: does not contain group: group-9D3E094E5440
2024-07-01 06:00:57,462 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D3E094E5440,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:00:57,463 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState
2024-07-01 06:00:57,463 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-FollowerState was interrupted
2024-07-01 06:00:57,463 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater: set stopIndex = 8
2024-07-01 06:00:57,463 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-9D3E094E5440: Taking a snapshot at:(t:1, i:8) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/sm/snapshot.1_8
2024-07-01 06:00:57,464 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-9D3E094E5440: Finished taking a snapshot at:(t:1, i:8) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/sm/snapshot.1_8 took: 1 ms
2024-07-01 06:00:57,464 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater: Took a snapshot at index 8
2024-07-01 06:00:57,464 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 8
2024-07-01 06:00:57,464 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:8)
2024-07-01 06:00:57,465 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:00:57,478 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: remove  FOLLOWER bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440:t1, leader=bfc6da33-104c-4d07-98ee-1aed7336cdfb, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLog:OPENED:c8:last(t:1, i:8), conf=conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null} RUNNING
2024-07-01 06:00:57,478 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: shutdown
2024-07-01 06:00:57,478 [grpc-default-executor-4] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D3E094E5440,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:00:57,478 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState
2024-07-01 06:00:57,478 [grpc-default-executor-4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater: set stopIndex = 8
2024-07-01 06:00:57,478 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-FollowerState was interrupted
2024-07-01 06:00:57,478 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-9D3E094E5440: Taking a snapshot at:(t:1, i:8) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/sm/snapshot.1_8
2024-07-01 06:00:57,479 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-9D3E094E5440: Finished taking a snapshot at:(t:1, i:8) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/6a54b320-18b2-409b-b307-9d3e094e5440/sm/snapshot.1_8 took: 1 ms
2024-07-01 06:00:57,479 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater: Took a snapshot at index 8
2024-07-01 06:00:57,479 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 8
2024-07-01 06:00:57,480 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:8)
2024-07-01 06:00:57,480 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:00:57,498 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:57,499 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:57,499 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:57,499 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:57,499 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:57,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:57,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:57,729 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:00:57,799 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)
2024-07-01 06:00:57,837 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:57,837 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:57,837 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:57,837 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:57,839 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:57,839 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:57,841 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:57,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:00:57,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001. There are 1 pipelines
2024-07-01 06:00:57,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:58,178 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596-SegmentedRaftLogWorker close()
2024-07-01 06:00:58,179 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-3D02EEC07596: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/83d0b075-21bf-48bf-ac12-3d02eec07596
2024-07-01 06:00:58,179 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 command on datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb.
2024-07-01 06:00:58,444 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440-SegmentedRaftLogWorker close()
2024-07-01 06:00:58,444 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440-SegmentedRaftLogWorker close()
2024-07-01 06:00:58,445 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-9D3E094E5440: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:58,445 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-9D3E094E5440: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/6a54b320-18b2-409b-b307-9d3e094e5440
2024-07-01 06:00:58,449 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] WARN  server.RaftServer (RaftServerProxy.java:remove(107)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: does not contain group: group-9D3E094E5440
2024-07-01 06:00:58,449 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] WARN  server.RaftServer (RaftServerProxy.java:remove(107)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: does not contain group: group-9D3E094E5440
2024-07-01 06:00:58,452 [IPC Server handler 10 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-07-01 06:00:58,454 [IPC Server handler 12 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-07-01 06:00:58,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:58,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:58,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:58,513 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:58,513 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:58,513 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-07-01 06:00:58,513 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:58,761 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:00:58,841 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:58,841 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:58,841 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:58,841 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:58,843 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:58,843 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:58,845 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:58,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:00:58,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001. There are 1 pipelines
2024-07-01 06:00:58,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:00:59,517 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:59,517 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:00:59,517 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:59,517 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:00:59,517 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:00:59,517 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:00:59,517 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:00:59,729 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:00:59,760 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:00:59,800 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:59,800 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:00:59,804 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)
2024-07-01 06:00:59,840 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/d911fb7d-ae06-4770-ac9a-ead30a7876df, /default-rack/bfc6da33-104c-4d07-98ee-1aed7336cdfb, /default-rack/bd7a4aed-4c16-4f29-bb4e-36cd0e487b91]" excludedNodes="[d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)]"  ancestorGen="1").
2024-07-01 06:00:59,840 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)], affinityNode:
2024-07-01 06:00:59,841 [UnderReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), priority=NORMAL] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-07-01T06:00:52.452114282Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) with datanode deadline 1719814229841 and scm deadline 1719814259841
2024-07-01 06:00:59,842 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-07-01 06:00:59,845 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:00:59,845 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:00:59,845 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:00:59,845 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:00:59,847 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:00:59,847 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:00:59,849 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:00:59,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:00:59,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001. There are 1 pipelines
2024-07-01 06:00:59,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:00,521 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:00,521 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:00,521 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:00,521 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:00,521 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:00,521 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:00,521 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:00,799 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)
2024-07-01 06:01:00,849 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:00,850 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:00,850 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:00,850 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:00,852 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:00,852 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:00,853 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:00,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:00,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001. There are 1 pipelines
2024-07-01 06:01:00,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:01,458 [d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerReplicationThread-0] INFO  replication.PushReplicator (PushReplicator.java:replicate(58)) - Starting replication of container 1 to 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) using NO_COMPRESSION
2024-07-01 06:01:01,458 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:01,459 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:01,474 [d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerReplicationThread-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(116)) - Sent 16384 bytes for container 1
2024-07-01 06:01:01,478 [7c590364-16f9-412e-8d8f-583652a307a8-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onNext(96)) - Accepting container 1
2024-07-01 06:01:01,478 [7c590364-16f9-412e-8d8f-583652a307a8-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(131)) - Container 1 is downloaded with size 16384, starting to import.
2024-07-01 06:01:01,509 [7c590364-16f9-412e-8d8f-583652a307a8-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(137)) - Container 1 is replicated successfully
2024-07-01 06:01:01,511 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)
2024-07-01 06:01:01,512 [grpc-default-executor-4] INFO  replication.GrpcContainerUploader (GrpcContainerUploader.java:onCompleted(132)) - Finished uploading container 1 to 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)
2024-07-01 06:01:01,513 [d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(369)) - Successful DONE replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), priority=NORMAL, transferred 16384 bytes
2024-07-01 06:01:01,514 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: ICR, size: 1}
2024-07-01 06:01:01,523 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-07-01 06:01:01,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:01,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:01,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:01,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:01,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:01,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:01,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:01,729 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:01,760 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:01:01,788 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5047489266ns, electionTimeout:5047ms
2024-07-01 06:01:01,789 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:01,789 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:01:01,789 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:01:01,789 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8
2024-07-01 06:01:01,789 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,790 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052
2024-07-01 06:01:01,790 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025
2024-07-01 06:01:01,790 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:01,790 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:01,794 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: receive requestVote(PRE_VOTE, 4873639b-1d87-440f-9147-409a0544c1cf, group-BDBB6172C2D0, 0, (t:0, i:0))
2024-07-01 06:01:01,795 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FOLLOWER: reject PRE_VOTE from 4873639b-1d87-440f-9147-409a0544c1cf: our priority 1 > candidate's priority 0
2024-07-01 06:01:01,795 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0 replies to PRE_VOTE vote request: 4873639b-1d87-440f-9147-409a0544c1cf<-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#0:FAIL-t0. Peer's state: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0:t0, leader=null, voted=, raftlog=Memoized:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,796 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2024-07-01 06:01:01,796 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 4873639b-1d87-440f-9147-409a0544c1cf<-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#0:FAIL-t0
2024-07-01 06:01:01,796 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8 PRE_VOTE round 0: result REJECTED
2024-07-01 06:01:01,796 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-07-01 06:01:01,796 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8
2024-07-01 06:01:01,796 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:01,796 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: set firstElectionSinceStartup to false for REJECTED
2024-07-01 06:01:01,844 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5068878203ns, electionTimeout:5066ms
2024-07-01 06:01:01,844 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:01,844 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:01:01,844 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:01:01,844 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9
2024-07-01 06:01:01,845 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,845 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052
2024-07-01 06:01:01,846 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043
2024-07-01 06:01:01,846 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:01,846 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:01,853 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: receive requestVote(PRE_VOTE, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, group-BDBB6172C2D0, 0, (t:0, i:0))
2024-07-01 06:01:01,854 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FOLLOWER: accept PRE_VOTE from bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: our priority 0 <= candidate's priority 1
2024-07-01 06:01:01,854 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:01,854 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:01,854 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:01,854 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:01,854 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0 replies to PRE_VOTE vote request: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91<-7c590364-16f9-412e-8d8f-583652a307a8#0:OK-t0. Peer's state: 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0:t0, leader=null, voted=, raftlog=Memoized:7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,855 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: receive requestVote(PRE_VOTE, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, group-BDBB6172C2D0, 0, (t:0, i:0))
2024-07-01 06:01:01,855 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FOLLOWER: accept PRE_VOTE from bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: our priority 0 <= candidate's priority 1
2024-07-01 06:01:01,856 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0 replies to PRE_VOTE vote request: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91<-4873639b-1d87-440f-9147-409a0544c1cf#0:OK-t0. Peer's state: 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0:t0, leader=null, voted=, raftlog=Memoized:4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,856 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-07-01 06:01:01,856 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91<-7c590364-16f9-412e-8d8f-583652a307a8#0:OK-t0
2024-07-01 06:01:01,856 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9 PRE_VOTE round 0: result PASSED
2024-07-01 06:01:01,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:01,856 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:01,856 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:01,858 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001. There are 1 pipelines
2024-07-01 06:01:01,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:01,859 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:01,859 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: receive requestVote(ELECTION, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, group-BDBB6172C2D0, 1, (t:0, i:0))
2024-07-01 06:01:01,860 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FOLLOWER: accept ELECTION from bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: our priority 0 <= candidate's priority 1
2024-07-01 06:01:01,860 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:01,860 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:01,860 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 7c590364-16f9-412e-8d8f-583652a307a8: start 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:01,860 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState was interrupted
2024-07-01 06:01:01,861 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:01,861 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:01,862 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: set firstElectionSinceStartup to false for candidate:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:01,863 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: receive requestVote(ELECTION, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, group-BDBB6172C2D0, 1, (t:0, i:0))
2024-07-01 06:01:01,863 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FOLLOWER: accept ELECTION from bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: our priority 0 <= candidate's priority 1
2024-07-01 06:01:01,863 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:01,863 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:01,863 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:01,863 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState was interrupted
2024-07-01 06:01:01,863 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0 replies to ELECTION vote request: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91<-7c590364-16f9-412e-8d8f-583652a307a8#0:OK-t1. Peer's state: 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0:t1, leader=null, voted=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, raftlog=Memoized:7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,864 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0 replies to ELECTION vote request: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91<-4873639b-1d87-440f-9147-409a0544c1cf#0:OK-t1. Peer's state: 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0:t1, leader=null, voted=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, raftlog=Memoized:4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,865 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-07-01 06:01:01,865 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91<-4873639b-1d87-440f-9147-409a0544c1cf#0:OK-t1
2024-07-01 06:01:01,866 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9 ELECTION round 0: result PASSED
2024-07-01 06:01:01,866 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9
2024-07-01 06:01:01,867 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:01:01,867 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:01:01,868 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:01:01,868 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:01:01,869 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:01:01,869 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:01:01,869 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:01:01,870 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:01:01,870 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:01:01,871 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:01,871 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:01:01,871 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:01:01,871 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:01:01,872 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-07-01 06:01:01,872 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:01,872 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-07-01 06:01:01,872 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-07-01 06:01:01,873 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-07-01 06:01:01,873 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:01,873 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-07-01 06:01:01,873 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-07-01 06:01:01,873 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-07-01 06:01:01,873 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:01,873 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:01:01,875 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-07-01 06:01:01,875 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:01,875 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-07-01 06:01:01,875 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-07-01 06:01:01,876 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-07-01 06:01:01,876 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:01,876 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-07-01 06:01:01,876 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-07-01 06:01:01,876 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-07-01 06:01:01,876 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:01,876 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:01:01,877 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderStateImpl
2024-07-01 06:01:01,877 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:01:01,877 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-BDBB6172C2D0 with new leaderId: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:01,877 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: change Leader from null to bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 at term 1 for becomeLeader, leader elected after 5125ms
2024-07-01 06:01:01,877 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:01:01,878 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:01:01,882 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderElection9] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: set configuration conf: {index: 0, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,882 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:01:01,883 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0
2024-07-01 06:01:01,886 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/current/log_inprogress_0
2024-07-01 06:01:01,888 [7c590364-16f9-412e-8d8f-583652a307a8-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-BDBB6172C2D0 with new leaderId: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:01,888 [7c590364-16f9-412e-8d8f-583652a307a8-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: change Leader from null to bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 at term 1 for appendEntries, leader elected after 5097ms
2024-07-01 06:01:01,889 [7c590364-16f9-412e-8d8f-583652a307a8-server-thread3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: set configuration conf: {index: 0, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,889 [7c590364-16f9-412e-8d8f-583652a307a8-server-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:01:01,889 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:01:01,895 [4873639b-1d87-440f-9147-409a0544c1cf-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-BDBB6172C2D0 with new leaderId: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:01,896 [4873639b-1d87-440f-9147-409a0544c1cf-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: change Leader from null to bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 at term 1 for appendEntries, leader elected after 5176ms
2024-07-01 06:01:01,897 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/current/log_inprogress_0
2024-07-01 06:01:01,899 [4873639b-1d87-440f-9147-409a0544c1cf-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: set configuration conf: {index: 0, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:01,899 [4873639b-1d87-440f-9147-409a0544c1cf-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:01:01,900 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:01:01,902 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:01:01,909 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/current/log_inprogress_0
2024-07-01 06:01:02,534 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:02,534 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:02,534 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:02,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:02,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:02,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:02,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:02,692 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f since it stays at CLOSED stage.
2024-07-01 06:01:02,692 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f close command to datanode d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:01:02,693 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f, Nodes: d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d911fb7d-ae06-4770-ac9a-ead30a7876df, CreationTimestamp2024-07-01T06:00:37.387Z[Etc/UTC]] removed.
2024-07-01 06:01:02,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:02,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001 has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-07-01 06:01:02,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) has entered maintenance
2024-07-01 06:01:02,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:02,859 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) moved to HEALTHY state.
2024-07-01 06:01:02,859 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:01:02,859 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:02,859 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:02,859 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:02,860 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:02,861 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:02,861 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:02,863 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:03,031 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [7c590364-16f9-412e-8d8f-583652a307a8, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-07-01 06:01:03,055 [IPC Server handler 13 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(476)) - Queued node bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) for recommission
2024-07-01 06:01:03,055 [IPC Server handler 13 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(476)) - Queued node d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) for recommission
2024-07-01 06:01:03,456 [IPC Server handler 43 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-07-01 06:01:03,457 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f is not found
2024-07-01 06:01:03,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:03,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:03,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:03,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:03,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:03,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:03,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:03,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:03,858 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) moved to HEALTHY state.
2024-07-01 06:01:03,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@44524022
2024-07-01 06:01:03,858 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:01:03,859 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) moved to HEALTHY state.
2024-07-01 06:01:03,859 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:01:03,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d1f52001
2024-07-01 06:01:03,859 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a to datanode:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:03,860 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 3861e760-4c8e-4a89-95b5-888f41e9de4a, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:01:03.859496383Z[Etc/UTC]]
2024-07-01 06:01:03,860 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd to datanode:d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:01:03,861 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 5c411626-cbe8-45ee-a8fc-730640d1aadd, Nodes: d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:01:03.860888281Z[Etc/UTC]]
2024-07-01 06:01:03,863 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:03,863 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:03,863 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:03,863 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:03,865 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:03,865 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:03,867 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-07-01 06:01:04,090 [IPC Server handler 16 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:decommissionNodes(321)) - Force flag = false. Checking if decommission is possible for dns: [7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)]
2024-07-01 06:01:04,090 [IPC Server handler 16 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startDecommission(376)) - Starting Decommission for node 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1)
2024-07-01 06:01:04,090 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) moved to HEALTHY state.
2024-07-01 06:01:04,091 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-07-01 06:01:04,454 [IPC Server handler 47 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-07-01 06:01:04,456 [IPC Server handler 43 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-07-01 06:01:04,457 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f is not found
2024-07-01 06:01:04,510 [IPC Server handler 46 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-07-01 06:01:04,541 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:04,541 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:04,541 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:04,541 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:04,541 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:04,541 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:04,541 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:04,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:04,858 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1). Finalizing its pipelines [PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0, PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1]
2024-07-01 06:01:04,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@b58c1dd4. There are 2 pipelines
2024-07-01 06:01:04,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:04,859 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 moved to CLOSED state
2024-07-01 06:01:04,859 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 moved to CLOSED state
2024-07-01 06:01:04,867 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:04,867 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:04,867 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:04,867 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:04,869 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:04,870 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:04,871 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:05,453 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: addNew group-888F41E9DE4A:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016] returns group-888F41E9DE4A:java.util.concurrent.CompletableFuture@2d8f4642[Not completed]
2024-07-01 06:01:05,454 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: new RaftServerImpl for group-888F41E9DE4A:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016] with ContainerStateMachine:uninitialized
2024-07-01 06:01:05,455 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:05,455 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:01:05,455 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:01:05,455 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:01:05,455 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:01:05,455 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:01:05,455 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:01:05,455 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: remove    LEADER d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F:t1, leader=d911fb7d-ae06-4770-ac9a-ead30a7876df, voted=d911fb7d-ae06-4770-ac9a-ead30a7876df, raftlog=Memoized:d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLog:OPENED:c0:last(t:1, i:0), conf=conf: {index: 0, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null} RUNNING
2024-07-01 06:01:05,455 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: shutdown
2024-07-01 06:01:05,455 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3F456FFC0A9F,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:01:05,455 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-LeaderStateImpl
2024-07-01 06:01:05,455 [IPC Server handler 45 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-07-01 06:01:05,455 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: ConfigurationManager, init=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:01:05,456 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:01:05,456 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:01:05,456 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:01:05,456 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:01:05,456 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:01:05,456 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:01:05,457 [IPC Server handler 43 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-07-01 06:01:05,458 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f is not found
2024-07-01 06:01:05,455 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:05,459 [IPC Server handler 9 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-07-01 06:01:05,460 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:05,460 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-07-01 06:01:05,462 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-3F456FFC0A9F: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f/sm/snapshot.1_0
2024-07-01 06:01:05,462 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-3F456FFC0A9F: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f/sm/snapshot.1_0 took: 0 ms
2024-07-01 06:01:05,462 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:05,462 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:05,459 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:05,463 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:05,463 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 7 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:05,463 [d911fb7d-ae06-4770-ac9a-ead30a7876df-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-07-01 06:01:05,464 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:05,464 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:05,465 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:05,462 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:05,466 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:05,466 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:01:05,467 [d911fb7d-ae06-4770-ac9a-ead30a7876df-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-07-01 06:01:05,467 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:01:05,467 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:01:05,468 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:01:05,468 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:01:05,468 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:01:05,468 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis] (custom)
2024-07-01 06:01:05,469 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/3861e760-4c8e-4a89-95b5-888f41e9de4a does not exist. Creating ...
2024-07-01 06:01:05,469 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/3861e760-4c8e-4a89-95b5-888f41e9de4a/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:01:05,470 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/3861e760-4c8e-4a89-95b5-888f41e9de4a has been successfully formatted.
2024-07-01 06:01:05,472 [IPC Server handler 13 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-07-01 06:01:05,472 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a. Trying to get from SCM.
2024-07-01 06:01:05,473 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a
2024-07-01 06:01:05,474 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-888F41E9DE4A: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:01:05,474 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:01:05,474 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(87)) - Pipeline Pipeline[ Id: 3861e760-4c8e-4a89-95b5-888f41e9de4a, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:01:03.859Z[Etc/UTC]] verified from SCM and added to Recon pipeline metadata.
2024-07-01 06:01:05,475 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:01:05,475 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:05,475 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:01:05,475 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:01:05,476 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:05,477 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:01:05,477 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:01:05,477 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:05,486 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:01:05,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/3861e760-4c8e-4a89-95b5-888f41e9de4a
2024-07-01 06:01:05,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:01:05,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:01:05,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:05,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:01:05,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:01:05,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:01:05,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:01:05,488 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:01:05,488 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:01:05,491 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:05,491 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:01:05,491 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:01:05,491 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:01:05,491 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:05,491 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:05,495 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: start as a follower, conf=conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}
2024-07-01 06:01:05,495 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:01:05,495 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-888F41E9DE4A,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-888F41E9DE4A,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:01:05,499 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:01:05,500 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:01:05,500 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a
2024-07-01 06:01:05,501 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a.
2024-07-01 06:01:05,510 [IPC Server handler 33 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-07-01 06:01:05,533 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F-SegmentedRaftLogWorker close()
2024-07-01 06:01:05,533 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-3F456FFC0A9F: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f
2024-07-01 06:01:05,534 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f command on datanode d911fb7d-ae06-4770-ac9a-ead30a7876df.
2024-07-01 06:01:05,534 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: addNew group-730640D1AADD:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034] returns group-730640D1AADD:java.util.concurrent.CompletableFuture@406c9b3e[Not completed]
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: new RaftServerImpl for group-730640D1AADD:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034] with ContainerStateMachine:uninitialized
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: ConfigurationManager, init=conf: {index: -1, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:01:05,535 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:01:05,536 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:01:05,536 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:01:05,536 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:01:05,536 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:01:05,538 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:05,538 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:05,538 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:01:05,538 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:01:05,538 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:01:05,538 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:01:05,538 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:01:05,539 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:01:05,539 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis] (custom)
2024-07-01 06:01:05,539 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/5c411626-cbe8-45ee-a8fc-730640d1aadd does not exist. Creating ...
2024-07-01 06:01:05,540 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/5c411626-cbe8-45ee-a8fc-730640d1aadd/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:01:05,544 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:05,544 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:05,544 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:05,544 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:05,544 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:05,544 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:05,544 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:05,545 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/5c411626-cbe8-45ee-a8fc-730640d1aadd has been successfully formatted.
2024-07-01 06:01:05,545 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-730640D1AADD: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:01:05,545 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:01:05,545 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:01:05,546 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:05,546 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:01:05,546 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:01:05,546 [IPC Server handler 18 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-07-01 06:01:05,547 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd. Trying to get from SCM.
2024-07-01 06:01:05,547 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd
2024-07-01 06:01:05,549 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(87)) - Pipeline Pipeline[ Id: 5c411626-cbe8-45ee-a8fc-730640d1aadd, Nodes: d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:d911fb7d-ae06-4770-ac9a-ead30a7876df, CreationTimestamp2024-07-01T06:01:03.860Z[Etc/UTC]] verified from SCM and added to Recon pipeline metadata.
2024-07-01 06:01:05,551 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:05,551 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:01:05,551 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:01:05,551 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:05,553 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:01:05,553 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/5c411626-cbe8-45ee-a8fc-730640d1aadd
2024-07-01 06:01:05,553 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:01:05,553 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:01:05,553 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:05,553 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:01:05,553 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:01:05,553 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:01:05,554 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:01:05,554 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:01:05,554 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:01:05,556 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:05,556 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:01:05,556 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:01:05,557 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:01:05,557 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:05,557 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:05,567 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: start as a follower, conf=conf: {index: -1, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}
2024-07-01 06:01:05,567 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:01:05,567 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState
2024-07-01 06:01:05,571 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-730640D1AADD,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:01:05,571 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-730640D1AADD,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:01:05,571 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:01:05,571 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:01:05,571 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:01:05,571 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:01:05,571 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:01:05,571 [d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:01:05,572 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:05,572 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:05,579 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd
2024-07-01 06:01:05,579 [d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd.
2024-07-01 06:01:05,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@b58c1dd4. There are 2 pipelines
2024-07-01 06:01:05,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:05,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:05,872 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:05,872 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:05,872 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:05,872 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:05,873 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:05,874 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:05,875 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:06,510 [IPC Server handler 33 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-07-01 06:01:06,511 [7c590364-16f9-412e-8d8f-583652a307a8-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONING, scaling executor pool size to 20
2024-07-01 06:01:06,514 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:06,514 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:06,549 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-07-01 06:01:06,549 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:06,549 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:06,549 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:06,550 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:06,550 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:06,550 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:06,837 [OverReplicatedProcessor] INFO  replication.RatisOverReplicationHandler (RatisOverReplicationHandler.java:processAndSendCommands(115)) - Container #1 is over replicated. Actual replica count is 4, with 0 pending delete(s). Expected replica count is 3.
2024-07-01 06:01:06,838 [OverReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [deleteContainerCommand: containerID: 1, replicaIndex: 0, force: true] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-07-01T06:00:52.452114282Z, pipelineID=PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440, owner=omServiceIdDefault} to 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) with datanode deadline 1719814236838 and scm deadline 1719814266838
2024-07-01 06:01:06,838 [OverReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {OVER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-07-01 06:01:06,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@b58c1dd4. There are 2 pipelines
2024-07-01 06:01:06,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:06,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:06,875 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:06,876 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:06,876 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:06,876 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:06,877 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:06,878 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:06,879 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:07,511 [IPC Server handler 18 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-07-01 06:01:07,551 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-07-01 06:01:07,553 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:07,554 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:07,554 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:07,554 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:07,554 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:07,554 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:07,554 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:07,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@b58c1dd4. There are 2 pipelines
2024-07-01 06:01:07,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:07,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:07,880 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:07,880 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:07,880 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:07,880 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:07,881 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:07,882 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:07,883 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:08,514 [7c590364-16f9-412e-8d8f-583652a307a8-DeleteContainerThread-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerForDelete(424)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/current/containerDir0/1 to state DELETED from state:CLOSED
2024-07-01 06:01:08,557 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:08,557 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:08,557 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:08,557 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:08,557 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:08,557 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:08,557 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:08,844 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:verifyUnderReplication(314)) - The container #1 state changed and it's not under replicated any more.
2024-07-01 06:01:08,844 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-07-01 06:01:08,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@b58c1dd4. There are 2 pipelines
2024-07-01 06:01:08,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:08,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:08,883 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:08,884 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:08,884 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:08,884 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:08,885 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:08,886 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:08,887 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:09,560 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:09,560 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:09,560 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:09,560 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:09,560 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:09,560 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:09,560 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:09,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@b58c1dd4. There are 2 pipelines
2024-07-01 06:01:09,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-07-01 06:01:09,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:09,887 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:09,887 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:09,888 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:09,888 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:09,889 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:09,889 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:09,891 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:10,564 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:10,564 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:10,564 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:10,564 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:10,564 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:10,564 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:10,564 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:10,592 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5097489601ns, electionTimeout:5093ms
2024-07-01 06:01:10,592 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState
2024-07-01 06:01:10,593 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:01:10,593 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:01:10,593 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10
2024-07-01 06:01:10,593 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}
2024-07-01 06:01:10,593 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10 PRE_VOTE round 0: result PASSED (term=0)
2024-07-01 06:01:10,594 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}
2024-07-01 06:01:10,595 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10 ELECTION round 0: result PASSED (term=1)
2024-07-01 06:01:10,595 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10
2024-07-01 06:01:10,595 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:01:10,595 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:01:10,595 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:01:10,595 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:01:10,596 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:01:10,596 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:01:10,596 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:01:10,596 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:01:10,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:01:10,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:10,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:01:10,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:01:10,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:01:10,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderStateImpl
2024-07-01 06:01:10,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:01:10,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-888F41E9DE4A with new leaderId: bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:10,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: change Leader from null to bfc6da33-104c-4d07-98ee-1aed7336cdfb at term 1 for becomeLeader, leader elected after 5141ms
2024-07-01 06:01:10,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:01:10,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: set configuration conf: {index: 0, cur=peers:[bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016]|listeners:[], old=null}
2024-07-01 06:01:10,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:01:10,605 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/3861e760-4c8e-4a89-95b5-888f41e9de4a/current/log_inprogress_0
2024-07-01 06:01:10,607 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:01:10,693 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 since it stays at CLOSED stage.
2024-07-01 06:01:10,694 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 close command to datanode bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:10,694 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 close command to datanode 4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:10,694 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 close command to datanode 7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:01:10,694 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 021f4cea-3012-4c29-83fe-bdbb6172c2d0, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 07c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, CreationTimestamp2024-07-01T06:00:54.860Z[Etc/UTC]] removed.
2024-07-01 06:01:10,694 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 since it stays at CLOSED stage.
2024-07-01 06:01:10,694 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 close command to datanode 7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:01:10,695 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1, Nodes: 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:7c590364-16f9-412e-8d8f-583652a307a8, CreationTimestamp2024-07-01T06:00:37.803Z[Etc/UTC]] removed.
2024-07-01 06:01:10,729 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 is not found
2024-07-01 06:01:10,752 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5185379346ns, electionTimeout:5180ms
2024-07-01 06:01:10,752 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState
2024-07-01 06:01:10,753 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:01:10,753 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:01:10,753 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11
2024-07-01 06:01:10,753 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}
2024-07-01 06:01:10,753 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11 PRE_VOTE round 0: result PASSED (term=0)
2024-07-01 06:01:10,754 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}
2024-07-01 06:01:10,754 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11 ELECTION round 0: result PASSED (term=1)
2024-07-01 06:01:10,755 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11
2024-07-01 06:01:10,755 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:01:10,755 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:01:10,755 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:01:10,755 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:01:10,755 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:01:10,755 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:01:10,755 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:01:10,756 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:01:10,756 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:01:10,756 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:10,756 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:01:10,756 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:01:10,756 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:01:10,756 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: start d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderStateImpl
2024-07-01 06:01:10,756 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:01:10,757 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-730640D1AADD with new leaderId: d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:01:10,757 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: change Leader from null to d911fb7d-ae06-4770-ac9a-ead30a7876df at term 1 for becomeLeader, leader elected after 5221ms
2024-07-01 06:01:10,757 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:01:10,757 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderElection11] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: set configuration conf: {index: 0, cur=peers:[d911fb7d-ae06-4770-ac9a-ead30a7876df|127.0.0.1:15034]|listeners:[], old=null}
2024-07-01 06:01:10,758 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:01:10,765 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/5c411626-cbe8-45ee-a8fc-730640d1aadd/current/log_inprogress_0
2024-07-01 06:01:10,767 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:01:10,858 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@b58c1dd4 has 0 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-07-01 06:01:10,859 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:completeDecommission(522)) - Datanode 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) has completed the admin workflow. The operational state has been set to DECOMMISSIONED
2024-07-01 06:01:10,859 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) moved to HEALTHY state.
2024-07-01 06:01:10,859 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-07-01 06:01:10,860 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 to datanode:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:10,860 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 to datanode:4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:10,860 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 to datanode:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:10,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:10,861 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: ee6424f6-b724-4afc-aa46-f848eaf35609, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:01:10.860155694Z[Etc/UTC]]
2024-07-01 06:01:10,881 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 is not found
2024-07-01 06:01:10,882 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:10,891 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:10,891 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:10,891 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:10,891 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:10,893 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:10,893 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:10,895 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:10,911 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:11,112 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:11,312 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:11,513 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:11,517 [IPC Server handler 18 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-07-01 06:01:11,518 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 is not found
2024-07-01 06:01:11,518 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 is not found
2024-07-01 06:01:11,567 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:11,567 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:11,567 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:11,567 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:11,567 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:11,567 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:11,567 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:11,600 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:11,713 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:11,731 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:01:11,731 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:01:11,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:11,881 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 is not found
2024-07-01 06:01:11,895 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:11,895 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:11,896 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:11,896 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:11,897 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:11,897 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:11,899 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:11,913 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:12,114 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:12,314 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:12,472 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: addNew group-F848EAF35609:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-F848EAF35609:java.util.concurrent.CompletableFuture@ac67b2f[Not completed]
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: new RaftServerImpl for group-F848EAF35609:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: ConfigurationManager, init=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:01:12,473 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:01:12,474 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:01:12,474 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:01:12,474 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:01:12,474 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:01:12,474 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:01:12,476 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:12,476 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:12,476 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:01:12,476 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:01:12,476 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:01:12,476 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:01:12,476 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:01:12,477 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:01:12,477 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis] (custom)
2024-07-01 06:01:12,477 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609 does not exist. Creating ...
2024-07-01 06:01:12,478 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:01:12,479 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609 has been successfully formatted.
2024-07-01 06:01:12,479 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-F848EAF35609: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:01:12,479 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:01:12,479 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:01:12,479 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,480 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:01:12,480 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:01:12,481 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:12,481 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:01:12,481 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:01:12,482 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:01:12,483 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:01:12,483 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:01:12,484 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609. Trying to get from SCM.
2024-07-01 06:01:12,485 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,485 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:01:12,485 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:01:12,485 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:01:12,485 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:12,486 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:12,486 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: start as a follower, conf=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:12,486 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(87)) - Pipeline Pipeline[ Id: ee6424f6-b724-4afc-aa46-f848eaf35609, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-07-01T06:01:10.860Z[Etc/UTC]] verified from SCM and added to Recon pipeline metadata.
2024-07-01 06:01:12,486 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:01:12,486 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState
2024-07-01 06:01:12,486 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:01:12,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F848EAF35609,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:12,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-F848EAF35609,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:12,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:01:12,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:01:12,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:01:12,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:01:12,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:01:12,487 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:01:12,488 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:12,488 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:12,491 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(849)) - Created group PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:12,498 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: addNew group-F848EAF35609:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-F848EAF35609:java.util.concurrent.CompletableFuture@45a72678[Not completed]
2024-07-01 06:01:12,499 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: new RaftServerImpl for group-F848EAF35609:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:01:12,499 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:12,499 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:01:12,499 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:01:12,499 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:01:12,499 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:01:12,499 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:01:12,499 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:01:12,500 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: ConfigurationManager, init=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:01:12,500 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:01:12,500 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:01:12,500 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:01:12,500 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:01:12,500 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:01:12,500 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:01:12,502 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:12,502 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:12,502 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:01:12,502 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:01:12,502 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:01:12,502 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:01:12,503 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:01:12,503 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:01:12,503 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis] (custom)
2024-07-01 06:01:12,503 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609 does not exist. Creating ...
2024-07-01 06:01:12,504 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:01:12,505 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609 has been successfully formatted.
2024-07-01 06:01:12,505 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-F848EAF35609: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:01:12,505 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:01:12,505 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:01:12,505 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,505 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:01:12,506 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:01:12,506 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 is not found
2024-07-01 06:01:12,507 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:01:12,507 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:12,507 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:01:12,507 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:01:12,507 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,510 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:01:12,511 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:01:12,513 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,513 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:01:12,513 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:01:12,514 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:01:12,514 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:12,514 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:12,515 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:12,518 [7c590364-16f9-412e-8d8f-583652a307a8-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONED, scaling executor pool size to 20
2024-07-01 06:01:12,518 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: start as a follower, conf=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:12,518 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:01:12,518 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState
2024-07-01 06:01:12,520 [IPC Server handler 27 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) as the reported value (DECOMMISSIONED, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-07-01 06:01:12,521 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 is not found
2024-07-01 06:01:12,521 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 is not found
2024-07-01 06:01:12,525 [grpc-default-executor-0] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - 4873639b-1d87-440f-9147-409a0544c1cf: remove  FOLLOWER 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0:t1, leader=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, voted=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, raftlog=Memoized:4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLog:OPENED:c0:last(t:1, i:0), conf=conf: {index: 0, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null} RUNNING
2024-07-01 06:01:12,525 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: shutdown
2024-07-01 06:01:12,525 [grpc-default-executor-0] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:12,525 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:12,525 [grpc-default-executor-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:12,525 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-BDBB6172C2D0: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/sm/snapshot.1_0
2024-07-01 06:01:12,525 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-FollowerState was interrupted
2024-07-01 06:01:12,526 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-BDBB6172C2D0: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/sm/snapshot.1_0 took: 1 ms
2024-07-01 06:01:12,526 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:12,526 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:12,527 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:12,527 [4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F848EAF35609,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-F848EAF35609,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:01:12,528 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:12,559 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - 4873639b-1d87-440f-9147-409a0544c1cf: addNew group-F848EAF35609:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] returns group-F848EAF35609:java.util.concurrent.CompletableFuture@2c41966f[Not completed]
2024-07-01 06:01:12,560 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - 4873639b-1d87-440f-9147-409a0544c1cf: new RaftServerImpl for group-F848EAF35609:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: ConfigurationManager, init=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:01:12,561 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:01:12,564 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:12,564 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:12,565 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:01:12,565 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:01:12,565 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:01:12,565 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:01:12,565 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:01:12,565 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:01:12,565 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis] (custom)
2024-07-01 06:01:12,565 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609 does not exist. Creating ...
2024-07-01 06:01:12,566 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:01:12,568 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609 has been successfully formatted.
2024-07-01 06:01:12,568 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-F848EAF35609: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-07-01 06:01:12,570 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:01:12,570 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:01:12,570 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,570 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:12,571 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:12,571 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:12,571 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:12,571 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:12,571 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:12,571 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:12,571 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:12,571 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:01:12,571 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:01:12,574 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:12,575 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:01:12,575 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:01:12,575 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,578 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:01:12,579 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:01:12,582 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:12,582 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:01:12,582 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:01:12,582 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:01:12,582 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:12,582 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:12,591 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: start as a follower, conf=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:12,591 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-07-01 06:01:12,591 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState
2024-07-01 06:01:12,597 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F848EAF35609,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:12,597 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-F848EAF35609,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:12,597 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:01:12,598 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:01:12,598 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:01:12,598 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:01:12,598 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:01:12,598 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:01:12,599 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:12,599 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:12,603 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609.
2024-07-01 06:01:12,715 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:12,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:12,885 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - 7c590364-16f9-412e-8d8f-583652a307a8: remove  FOLLOWER 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0:t1, leader=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, voted=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, raftlog=Memoized:7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLog:OPENED:c0:last(t:1, i:0), conf=conf: {index: 0, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null} RUNNING
2024-07-01 06:01:12,885 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: shutdown
2024-07-01 06:01:12,885 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:01:12,885 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState
2024-07-01 06:01:12,885 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:12,885 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-FollowerState was interrupted
2024-07-01 06:01:12,885 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-BDBB6172C2D0: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/sm/snapshot.1_0
2024-07-01 06:01:12,886 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-BDBB6172C2D0: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/sm/snapshot.1_0 took: 1 ms
2024-07-01 06:01:12,886 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:12,886 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:12,887 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:12,887 [7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:12,899 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:12,899 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:12,900 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:12,900 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:12,900 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0-SegmentedRaftLogWorker close()
2024-07-01 06:01:12,901 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-BDBB6172C2D0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0
2024-07-01 06:01:12,902 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:12,902 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:12,904 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:12,909 [grpc-default-executor-3] WARN  server.RaftServer (RaftServerProxy.java:remove(107)) - 4873639b-1d87-440f-9147-409a0544c1cf: does not contain group: group-BDBB6172C2D0
2024-07-01 06:01:12,911 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0-SegmentedRaftLogWorker close()
2024-07-01 06:01:12,913 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-BDBB6172C2D0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0
2024-07-01 06:01:12,915 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:12,920 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: remove    LEADER bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0:t1, leader=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, voted=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, raftlog=Memoized:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLog:OPENED:c0:last(t:1, i:0), conf=conf: {index: 0, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052, 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null} RUNNING
2024-07-01 06:01:12,920 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: shutdown
2024-07-01 06:01:12,920 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BDBB6172C2D0,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:12,921 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-LeaderStateImpl
2024-07-01 06:01:12,921 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0->7c590364-16f9-412e-8d8f-583652a307a8-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0->7c590364-16f9-412e-8d8f-583652a307a8-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-07-01 06:01:12,921 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:12,921 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-07-01 06:01:12,922 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 4873639b-1d87-440f-9147-409a0544c1cf: Completed APPEND_ENTRIES, lastRequest: null
2024-07-01 06:01:12,922 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-BDBB6172C2D0: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/sm/snapshot.1_0
2024-07-01 06:01:12,922 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 4873639b-1d87-440f-9147-409a0544c1cf: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "bd7a4aed-4c16-4f29-bb4e-36cd0e487b91"
  replyId: "4873639b-1d87-440f-9147-409a0544c1cf"
  raftGroupId {
    id: "\002\037L\3520\022L)\203\376\275\273ar\302\320"
  }
  callId: 8
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-07-01 06:01:12,922 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 7c590364-16f9-412e-8d8f-583652a307a8: Completed APPEND_ENTRIES, lastRequest: null
2024-07-01 06:01:12,922 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-BDBB6172C2D0: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0/sm/snapshot.1_0 took: 1 ms
2024-07-01 06:01:12,923 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:12,923 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:12,923 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:12,923 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 7c590364-16f9-412e-8d8f-583652a307a8: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "bd7a4aed-4c16-4f29-bb4e-36cd0e487b91"
  replyId: "7c590364-16f9-412e-8d8f-583652a307a8"
  raftGroupId {
    id: "\002\037L\3520\022L)\203\376\275\273ar\302\320"
  }
  callId: 6
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-07-01 06:01:12,924 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0->4873639b-1d87-440f-9147-409a0544c1cf-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:01:12,924 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 4873639b-1d87-440f-9147-409a0544c1cf: Completed APPEND_ENTRIES, lastRequest: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91->4873639b-1d87-440f-9147-409a0544c1cf#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id:"7c590364-16f9-412e-8d8f-583652a307a8"address:"127.0.0.1:15052"dataStreamAddress:"127.0.0.1:15053"clientAddress:"127.0.0.1:15050"adminAddress:"127.0.0.1:15051"startupRole:FOLLOWER, id:"4873639b-1d87-440f-9147-409a0544c1cf"address:"127.0.0.1:15043"dataStreamAddress:"127.0.0.1:15044"clientAddress:"127.0.0.1:15041"adminAddress:"127.0.0.1:15042"startupRole:FOLLOWER, id:"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91"address:"127.0.0.1:15025"priority:1dataStreamAddress:"127.0.0.1:15026"clientAddress:"127.0.0.1:15023"adminAddress:"127.0.0.1:15024"startupRole:FOLLOWER, old:)
2024-07-01 06:01:12,924 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 4873639b-1d87-440f-9147-409a0544c1cf: Completed APPEND_ENTRIES, lastReply: null
2024-07-01 06:01:12,924 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0->4873639b-1d87-440f-9147-409a0544c1cf-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:01:12,925 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 7c590364-16f9-412e-8d8f-583652a307a8: Completed APPEND_ENTRIES, lastRequest: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91->7c590364-16f9-412e-8d8f-583652a307a8#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id:"7c590364-16f9-412e-8d8f-583652a307a8"address:"127.0.0.1:15052"dataStreamAddress:"127.0.0.1:15053"clientAddress:"127.0.0.1:15050"adminAddress:"127.0.0.1:15051"startupRole:FOLLOWER, id:"4873639b-1d87-440f-9147-409a0544c1cf"address:"127.0.0.1:15043"dataStreamAddress:"127.0.0.1:15044"clientAddress:"127.0.0.1:15041"adminAddress:"127.0.0.1:15042"startupRole:FOLLOWER, id:"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91"address:"127.0.0.1:15025"priority:1dataStreamAddress:"127.0.0.1:15026"clientAddress:"127.0.0.1:15023"adminAddress:"127.0.0.1:15024"startupRole:FOLLOWER, old:)
2024-07-01 06:01:12,925 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 7c590364-16f9-412e-8d8f-583652a307a8: Completed APPEND_ENTRIES, lastReply: null
2024-07-01 06:01:12,925 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0->7c590364-16f9-412e-8d8f-583652a307a8-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:01:12,925 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0->7c590364-16f9-412e-8d8f-583652a307a8-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:01:12,926 [grpc-default-executor-3] WARN  server.RaftServer (RaftServerProxy.java:remove(107)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: does not contain group: group-BDBB6172C2D0
2024-07-01 06:01:12,927 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:12,928 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:12,930 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] WARN  server.RaftServer (RaftServerProxy.java:remove(107)) - 7c590364-16f9-412e-8d8f-583652a307a8: does not contain group: group-BDBB6172C2D0
2024-07-01 06:01:12,931 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - 7c590364-16f9-412e-8d8f-583652a307a8: remove    LEADER 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1:t1, leader=7c590364-16f9-412e-8d8f-583652a307a8, voted=7c590364-16f9-412e-8d8f-583652a307a8, raftlog=Memoized:7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLog:OPENED:c0:last(t:1, i:0), conf=conf: {index: 0, cur=peers:[7c590364-16f9-412e-8d8f-583652a307a8|127.0.0.1:15052]|listeners:[], old=null} RUNNING
2024-07-01 06:01:12,931 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: shutdown
2024-07-01 06:01:12,931 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9AE4F3F9C8F1,id=7c590364-16f9-412e-8d8f-583652a307a8
2024-07-01 06:01:12,931 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-LeaderStateImpl
2024-07-01 06:01:12,931 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:12,932 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:12,932 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-9AE4F3F9C8F1: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1/sm/snapshot.1_0
2024-07-01 06:01:12,932 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-9AE4F3F9C8F1: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1/sm/snapshot.1_0 took: 0 ms
2024-07-01 06:01:12,932 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:12,932 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:12,933 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:12,933 [7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:13,116 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:13,316 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:13,482 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:01:13,506 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:01:13,517 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:13,574 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:13,574 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:13,574 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:13,574 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:13,574 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:13,574 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:13,574 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:13,717 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:13,858 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1-SegmentedRaftLogWorker close()
2024-07-01 06:01:13,859 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - 7c590364-16f9-412e-8d8f-583652a307a8@group-9AE4F3F9C8F1: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/ratis/90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1
2024-07-01 06:01:13,859 [7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 command on datanode 7c590364-16f9-412e-8d8f-583652a307a8.
2024-07-01 06:01:13,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:13,888 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0-SegmentedRaftLogWorker close()
2024-07-01 06:01:13,888 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BDBB6172C2D0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/021f4cea-3012-4c29-83fe-bdbb6172c2d0
2024-07-01 06:01:13,888 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 command on datanode bd7a4aed-4c16-4f29-bb4e-36cd0e487b91.
2024-07-01 06:01:13,904 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:13,904 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:13,904 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:13,904 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:13,906 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:13,906 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:13,908 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:13,917 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:14,118 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:14,318 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:14,518 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:14,569 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:14,577 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:14,577 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:14,577 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:14,577 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:14,577 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:14,578 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:14,578 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:14,719 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:14,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:14,908 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:14,908 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:14,908 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:14,908 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:14,910 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:14,910 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:14,912 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:14,919 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:15,119 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:15,320 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:15,482 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:01:15,506 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:01:15,520 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:15,569 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:15,580 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:15,580 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:15,580 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:15,580 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:15,581 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:15,581 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:15,581 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:15,720 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:15,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:15,912 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:15,912 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:15,912 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:15,913 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:15,914 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:15,914 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:15,916 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:15,921 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:16,121 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:16,322 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:16,482 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:01:16,507 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1)
2024-07-01 06:01:16,522 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:16,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:16,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:16,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:16,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:16,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:16,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:16,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:16,722 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:16,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:16,916 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:16,916 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:16,917 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:16,917 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:16,918 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:16,918 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:16,920 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:16,923 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:17,123 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:17,323 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:17,524 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:17,569 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:17,581 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5094846648ns, electionTimeout:5093ms
2024-07-01 06:01:17,581 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState
2024-07-01 06:01:17,581 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:01:17,581 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:01:17,581 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12
2024-07-01 06:01:17,582 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(144)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5063271701ns, electionTimeout:5051ms
2024-07-01 06:01:17,582 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState
2024-07-01 06:01:17,582 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-07-01 06:01:17,582 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-07-01 06:01:17,582 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13
2024-07-01 06:01:17,582 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,582 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,583 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043
2024-07-01 06:01:17,584 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:17,584 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:17,584 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:17,584 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:17,584 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016
2024-07-01 06:01:17,586 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: receive requestVote(PRE_VOTE, bfc6da33-104c-4d07-98ee-1aed7336cdfb, group-F848EAF35609, 0, (t:0, i:0))
2024-07-01 06:01:17,586 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-CANDIDATE: accept PRE_VOTE from bfc6da33-104c-4d07-98ee-1aed7336cdfb: our priority 0 <= candidate's priority 1
2024-07-01 06:01:17,586 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609 replies to PRE_VOTE vote request: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#0:OK-t0. Peer's state: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609:t0, leader=null, voted=, raftlog=Memoized:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,588 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-07-01 06:01:17,588 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#0:OK-t0
2024-07-01 06:01:17,588 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12 PRE_VOTE round 0: result PASSED
2024-07-01 06:01:17,588 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:17,588 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:17,588 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:17,588 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:17,589 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:17,589 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:17,589 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:17,589 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,591 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: receive requestVote(PRE_VOTE, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, group-F848EAF35609, 0, (t:0, i:0))
2024-07-01 06:01:17,591 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-CANDIDATE: reject PRE_VOTE from bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: our priority 1 > candidate's priority 0
2024-07-01 06:01:17,591 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609 replies to PRE_VOTE vote request: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91<-bfc6da33-104c-4d07-98ee-1aed7336cdfb#0:FAIL-t1. Peer's state: bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609:t1, leader=null, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,592 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13: PRE_VOTE DISCOVERED_A_NEW_TERM (term=1) received 1 response(s) and 0 exception(s):
2024-07-01 06:01:17,592 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91<-bfc6da33-104c-4d07-98ee-1aed7336cdfb#0:FAIL-t1
2024-07-01 06:01:17,592 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13 PRE_VOTE round 0: result DISCOVERED_A_NEW_TERM (term=1)
2024-07-01 06:01:17,592 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM (term=1)
2024-07-01 06:01:17,592 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13
2024-07-01 06:01:17,592 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState
2024-07-01 06:01:17,592 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:17,592 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:17,593 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: receive requestVote(ELECTION, bfc6da33-104c-4d07-98ee-1aed7336cdfb, group-F848EAF35609, 1, (t:0, i:0))
2024-07-01 06:01:17,593 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FOLLOWER: accept ELECTION from bfc6da33-104c-4d07-98ee-1aed7336cdfb: our priority 0 <= candidate's priority 1
2024-07-01 06:01:17,593 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-LeaderElection13] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: set firstElectionSinceStartup to false for DISCOVERED_A_NEW_TERM (term=1)
2024-07-01 06:01:17,593 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:17,593 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState
2024-07-01 06:01:17,593 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState
2024-07-01 06:01:17,594 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: set firstElectionSinceStartup to false for candidate:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:17,595 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1416)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: receive requestVote(ELECTION, bfc6da33-104c-4d07-98ee-1aed7336cdfb, group-F848EAF35609, 1, (t:0, i:0))
2024-07-01 06:01:17,595 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FOLLOWER: accept ELECTION from bfc6da33-104c-4d07-98ee-1aed7336cdfb: our priority 0 <= candidate's priority 1
2024-07-01 06:01:17,595 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:17,595 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState
2024-07-01 06:01:17,595 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: start bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState
2024-07-01 06:01:17,594 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState was interrupted
2024-07-01 06:01:17,595 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609 replies to ELECTION vote request: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-4873639b-1d87-440f-9147-409a0544c1cf#0:OK-t1. Peer's state: 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609:t1, leader=null, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-4873639b-1d87-440f-9147-409a0544c1cf#0:OK-t1
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12 ELECTION round 0: result PASSED
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(139)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2024-07-01 06:01:17,597 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-07-01 06:01:17,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-07-01 06:01:17,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-07-01 06:01:17,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-07-01 06:01:17,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:17,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2024-07-01 06:01:17,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-07-01 06:01:17,598 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:17,599 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:01:17,600 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-07-01 06:01:17,600 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:17,600 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-07-01 06:01:17,600 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: start bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderStateImpl
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(549)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: set firstElectionSinceStartup to false for becomeLeader
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-F848EAF35609 with new leaderId: bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:17,601 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: change Leader from null to bfc6da33-104c-4d07-98ee-1aed7336cdfb at term 1 for becomeLeader, leader elected after 5127ms
2024-07-01 06:01:17,602 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:01:17,602 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:01:17,602 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState was interrupted
2024-07-01 06:01:17,604 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(104)) - Pipeline RATIS/THREE PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 reported by bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1)
2024-07-01 06:01:17,606 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: set configuration conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,607 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:17,608 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1449)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609 replies to ELECTION vote request: bfc6da33-104c-4d07-98ee-1aed7336cdfb<-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#0:OK-t1. Peer's state: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609:t1, leader=null, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,612 [4873639b-1d87-440f-9147-409a0544c1cf-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-F848EAF35609 with new leaderId: bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:17,613 [4873639b-1d87-440f-9147-409a0544c1cf-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: change Leader from null to bfc6da33-104c-4d07-98ee-1aed7336cdfb at term 1 for appendEntries, leader elected after 5051ms
2024-07-01 06:01:17,613 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/current/log_inprogress_0
2024-07-01 06:01:17,614 [4873639b-1d87-440f-9147-409a0544c1cf-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: set configuration conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,615 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(950)) - Leader change notification received for group: group-F848EAF35609 with new leaderId: bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:17,615 [4873639b-1d87-440f-9147-409a0544c1cf-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:01:17,615 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: change Leader from null to bfc6da33-104c-4d07-98ee-1aed7336cdfb at term 1 for appendEntries, leader elected after 5114ms
2024-07-01 06:01:17,615 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:01:17,616 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: set configuration conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:17,616 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(433)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker: Starting segment from index:0
2024-07-01 06:01:17,619 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2024-07-01 06:01:17,625 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/current/log_inprogress_0
2024-07-01 06:01:17,625 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(637)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/current/log_inprogress_0
2024-07-01 06:01:17,629 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(316)) - Leader bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2024-07-01 06:01:17,724 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:17,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:17,920 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:17,920 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:17,920 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:17,921 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:17,922 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:17,922 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:17,924 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:17,924 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:18,125 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:18,325 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:18,525 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:18,592 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:18,592 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:18,592 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:18,592 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:18,592 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:18,592 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:18,592 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:18,726 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:18,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:18,924 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:18,924 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:18,924 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:18,924 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:18,926 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:18,926 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:18,926 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:18,928 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:19,127 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:19,327 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:19,527 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:19,595 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:19,595 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:19,595 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:19,595 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:19,595 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:19,595 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:19,595 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:19,728 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:19,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:19,928 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:19,928 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:19,928 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:19,929 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:19,929 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:19,931 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:19,931 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:19,932 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:20,128 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:20,329 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:20,529 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:20,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:20,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:20,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:20,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:20,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:20,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:20,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:20,730 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:20,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:20,930 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:20,932 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:20,933 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:20,933 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:20,933 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:20,934 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:20,934 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:20,936 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:21,130 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:21,331 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:21,363 [Recon-SyncSCMContainerInfo-0] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:syncWithSCMContainerInfo(564)) - Got list of containers from SCM : 1
2024-07-01 06:01:21,531 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:21,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:21,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:21,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:21,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:21,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:21,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:21,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:21,731 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:21,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:21,932 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:21,936 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:21,936 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:21,937 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:21,937 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:21,938 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:21,938 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:21,940 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:22,132 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:22,332 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:22,533 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:22,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:22,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:22,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:22,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:22,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:22,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:22,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:22,733 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:22,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:22,933 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:22,940 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:22,940 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:22,940 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:22,940 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:22,942 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:22,942 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:22,944 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:23,134 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:23,334 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:23,535 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:23,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:23,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:23,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:23,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:23,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:23,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:23,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:23,735 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:23,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:23,935 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:23,944 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:23,944 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:23,944 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:23,944 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:23,946 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:23,946 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:23,948 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:24,136 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:24,336 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:24,536 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:24,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:24,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:24,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:24,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:24,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:24,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:24,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:24,737 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:24,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:24,937 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:24,948 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:24,948 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:24,948 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:24,948 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:24,950 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:24,950 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:24,952 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:25,138 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:25,338 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:25,538 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:25,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:25,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:25,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:25,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:25,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:25,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:25,615 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:25,739 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:25,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:25,939 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:25,952 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:25,952 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:25,952 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:25,952 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:25,954 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:25,954 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:25,955 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:26,139 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:26,340 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:26,540 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:26,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:26,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:26,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:26,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:26,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:26,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:26,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:26,741 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:26,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:26,941 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:26,955 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:26,955 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:26,955 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:26,956 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:26,957 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:26,957 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:26,959 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:27,141 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:27,342 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:27,542 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:27,570 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:01:27,571 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: FCR, size: 0}
2024-07-01 06:01:27,620 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:27,620 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:27,620 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:27,620 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:27,620 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:27,620 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:27,620 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:27,743 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:27,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:27,943 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:27,959 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:27,959 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:27,959 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:27,959 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:27,961 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:27,961 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:27,962 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:28,143 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:28,344 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:28,544 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:28,623 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:28,623 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:28,623 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:28,624 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:28,624 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:28,624 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:28,624 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:28,744 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:28,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:28,945 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:28,962 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:28,963 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:28,963 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:28,963 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:28,964 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:28,964 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:28,966 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:29,145 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:29,346 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:29,546 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:29,627 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:29,627 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:29,627 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:29,627 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:29,627 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:29,627 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:29,627 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:29,746 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:29,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:29,947 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:29,966 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:29,966 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:29,967 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:29,967 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:29,968 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:29,968 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:29,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:30,147 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:30,347 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:30,510 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:30,511 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:30,548 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:30,630 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:30,630 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:30,630 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:30,630 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:30,630 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:30,630 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:30,630 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:30,748 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:30,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:30,949 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:30,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:30,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:30,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:30,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:30,972 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:30,972 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:30,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:31,149 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:31,349 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:31,550 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:31,633 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:31,633 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:31,633 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:31,633 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:31,633 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:31,633 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:31,633 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:31,750 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:31,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:31,950 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:31,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:31,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:31,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:31,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:31,976 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:31,976 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:31,978 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:32,151 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:32,351 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:32,551 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:32,636 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:32,636 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:32,636 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:32,636 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:32,636 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:32,637 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:32,637 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:32,752 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:32,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:32,952 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:32,978 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:32,978 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:32,978 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:32,978 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:32,979 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:32,979 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:32,981 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:33,153 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:33,353 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:33,553 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:33,639 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:33,639 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:33,639 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:33,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:33,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:33,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:33,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:33,754 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:33,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:33,954 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:33,981 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:33,981 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:33,982 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:33,982 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:33,983 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:33,983 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:33,985 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:34,154 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:34,355 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:34,555 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:34,642 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:34,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:34,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:34,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:34,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:34,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:34,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:34,755 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:34,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:34,956 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:34,985 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:34,985 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:34,985 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:34,985 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:34,987 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:34,987 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:34,989 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:35,038 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:01:35,156 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:35,197 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:01:35,356 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:35,449 [d911fb7d-ae06-4770-ac9a-ead30a7876df-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:01:35,557 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:35,644 [4873639b-1d87-440f-9147-409a0544c1cf-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:01:35,645 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:35,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:35,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:35,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:35,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:35,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:35,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:35,757 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:35,827 [7c590364-16f9-412e-8d8f-583652a307a8-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:01:35,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:35,958 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:35,989 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:35,989 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:35,989 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:35,989 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:35,991 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:35,991 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:35,992 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:36,158 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:36,358 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:36,509 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:36,559 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:36,649 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:36,649 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:36,649 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:36,649 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:36,649 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:36,649 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:36,649 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:36,759 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:36,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:36,959 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:36,993 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:36,993 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:36,993 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:36,993 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:36,994 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:36,994 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:36,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:37,160 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:37,360 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:37,560 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:37,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:37,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:37,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:37,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:37,652 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:37,652 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:37,652 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:37,761 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:37,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-07-01 06:01:37,961 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:37,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:37,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:37,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:37,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:37,998 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:37,998 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:38,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:38,161 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:38,362 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:38,562 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:38,654 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:38,654 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:38,654 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:38,654 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:38,655 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:38,655 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:38,655 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:38,763 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:38,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:38,963 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:39,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:39,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:39,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:39,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:39,002 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:39,002 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:39,004 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:39,163 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:39,364 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:39,564 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:39,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:39,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:39,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:39,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:39,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:39,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:39,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:39,764 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:39,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:39,965 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:40,004 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:40,004 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:40,004 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:40,004 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:40,006 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:40,006 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:40,007 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
2024-07-01 06:01:40,165 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:40,365 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:40,566 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:40,660 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:40,660 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:40,660 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:40,660 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:40,660 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:40,660 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:40,660 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:40,766 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:40,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-07-01 06:01:40,966 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, bfc6da33-104c-4d07-98ee-1aed7336cdfb, d911fb7d-ae06-4770-ac9a-ead30a7876df]
2024-07-01 06:01:41,007 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:41,008 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:41,008 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:41,008 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:41,011 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:41,011 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:41,012 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 15
====> [2] DECOMMISSIONING, DECOMMISSIONED, false TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2024-07-01 06:01:41,052

"IPC Server handler 91 on default port 15002" daemon prio=5 tid=351 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:766)
"IPC Server handler 19 on default port 15001" daemon prio=5 tid=179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 55 on default port 15009" daemon prio=5 tid=528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-1" daemon prio=5 tid=852 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 50 on default port 15000" daemon prio=5 tid=110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15009" daemon prio=5 tid=500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor7" daemon prio=5 tid=809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$739/0x00007fe9404e0b78.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 15 on default port 15002" daemon prio=5 tid=275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15000" daemon prio=5 tid=113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=42 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"om1-groupManagement"  prio=5 tid=382 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 15 on default port 15000" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"prometheus" daemon prio=5 tid=373 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.Object.wait(Object.java:338)
        at app//org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at app//org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at app//org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at app//org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeReportManager-3" daemon prio=5 tid=604 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 73 on default port 15009" daemon prio=5 tid=546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15002" daemon prio=5 tid=341 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15000" daemon prio=5 tid=141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15009" daemon prio=5 tid=496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15002" daemon prio=5 tid=353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1940959701-694" daemon prio=5 tid=694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 7 on default port 15000" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15009" daemon prio=5 tid=519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15012" daemon prio=5 tid=594 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"7c590364-16f9-412e-8d8f-583652a307a8-ReplicationContainerReader-0" daemon prio=5 tid=1090 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 18 on default port 15004" daemon prio=5 tid=434 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15001" daemon prio=5 tid=190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15001" daemon prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-CommandProcessorThread" daemon prio=5 tid=606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:674)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1636/0x00007fe940c21538.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=778 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 52 on default port 15001" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 74 on default port 15009" daemon prio=5 tid=547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15009" daemon prio=5 tid=529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 70 on default port 15001" daemon prio=5 tid=230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-BlockDeletingService#2" daemon prio=5 tid=1174 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 4 on default port 15000" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15000" daemon prio=5 tid=156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15000" daemon prio=5 tid=153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp111768855-365" daemon prio=5 tid=365 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 3 on default port 15001" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15000" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15001" daemon prio=5 tid=229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15002" daemon prio=5 tid=325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater" daemon prio=5 tid=881 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:219)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1@group-C5BA1605619E-cacheEviction-AwaitToRun" daemon prio=5 tid=389 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-164-thread-1" daemon prio=5 tid=783 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"RatisPipelineUtilsThread-0"  prio=5 tid=26 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:179)
        at app//org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$654/0x00007fe9403a7af8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15004" daemon prio=5 tid=385 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"Recon-FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15012" daemon prio=5 tid=599 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-60-thread-1"  prio=5 tid=406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 45 on default port 15009" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15009" daemon prio=5 tid=485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15009" daemon prio=5 tid=507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-cacheEviction-AwaitToRun" daemon prio=5 tid=1119 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 73 on default port 15000" daemon prio=5 tid=133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-3b5811d3-1"  prio=5 tid=468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 79 on default port 15009" daemon prio=5 tid=552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Common-Cleaner" daemon prio=8 tid=11 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
        at java.base@17.0.11/jdk.internal.ref.CleanerImpl.run(CleanerImpl.java:140)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
        at java.base@17.0.11/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:162)
"IPC Server handler 57 on default port 15009" daemon prio=5 tid=530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=47 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server Responder" daemon prio=5 tid=448 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"om1-OpenKeyCleanupService#0" daemon prio=5 tid=401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4608876e" daemon prio=5 tid=637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 10 on default port 15002" daemon prio=5 tid=270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-ChunkWriter-1-0" daemon prio=5 tid=787 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater" daemon prio=5 tid=1146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:219)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-client-thread1" daemon prio=5 tid=922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 88 on default port 15000" daemon prio=5 tid=148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp111768855-369" daemon prio=5 tid=369 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"PipelineSyncTask" daemon prio=5 tid=573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1544/0x00007fe940bcf498.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 11 on default port 15001" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor4" daemon prio=5 tid=751 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$739/0x00007fe9404e0b78.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 71 on default port 15002" daemon prio=5 tid=331 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1881254670-615" daemon prio=5 tid=615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-PeriodicHDDSVolumeChecker" daemon prio=5 tid=781 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15000" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15002" daemon prio=5 tid=721 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:704)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 13 on default port 15000" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15002" daemon prio=5 tid=316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15002" daemon prio=5 tid=273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 83 on default port 15001" daemon prio=5 tid=243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-ChunkWriter-2-0" daemon prio=5 tid=769 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15048" daemon prio=5 tid=707 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-ChunkWriter-0-0" daemon prio=5 tid=767 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1846446971-672" daemon prio=5 tid=672 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 28 on default port 15000" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1940959701-693" daemon prio=5 tid=693 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"BackgroundPipelineScrubber" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at app//org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$656/0x00007fe9403a2480.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 42 on default port 15001" daemon prio=5 tid=202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15002" daemon prio=5 tid=320 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-ChunkReader-ELG-0" daemon prio=5 tid=791 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 35 on default port 15001" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15000" daemon prio=5 tid=150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-ChunkWriter-2-0" daemon prio=5 tid=807 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 50 on default port 15002" daemon prio=5 tid=310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"CompactionDagPruningService" daemon prio=5 tid=376 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 37 on default port 15001" daemon prio=5 tid=197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15001" daemon prio=5 tid=232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15009" daemon prio=5 tid=535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=679 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 48 on default port 15000" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp193743819-410" daemon prio=5 tid=410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeStateMachineTaskThread-0"  prio=5 tid=633 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1846446971-673" daemon prio=5 tid=673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"JvmPauseMonitor0" daemon prio=5 tid=362 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$739/0x00007fe9404e0b78.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"JvmPauseMonitor5" daemon prio=5 tid=771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$739/0x00007fe9404e0b78.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:290)
        at app//org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:258)
        at app//org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at app//org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1871/0x00007fe940d6eb20.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-BlockDeletingService#1" daemon prio=5 tid=737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 39 on default port 15000" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15001" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-BlockDeletingService#1" daemon prio=5 tid=755 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 54 on default port 15001" daemon prio=5 tid=214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"LeaseManager#LeaseMonitor" daemon prio=5 tid=361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:717)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1074)
        at java.base@17.0.11/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
        at app//org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:284)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Session-HouseKeeper-591b9518-1"  prio=5 tid=620 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 86 on default port 15001" daemon prio=5 tid=246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=43 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Socket Reader #1 for port 15012"  prio=5 tid=595 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker"  prio=5 tid=844 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:302)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1119/0x00007fe940714488.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Session-HouseKeeper-6f82dbc9-1"  prio=5 tid=674 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 1 on default port 15002" daemon prio=5 tid=261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=608 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 13 on default port 15004" daemon prio=5 tid=429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15000" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeReportManager-0" daemon prio=5 tid=628 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1940959701-695" daemon prio=5 tid=695 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 93 on default port 15009" daemon prio=5 tid=566 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15001" daemon prio=5 tid=200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15000" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 41 on default port 15001" daemon prio=5 tid=201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Timer-1" daemon prio=5 tid=437 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.Object.wait(Object.java:338)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:537)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server idle connection scanner for port 15001" daemon prio=5 tid=41 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"qtp111768855-364" daemon prio=5 tid=364 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 19 on default port 15009" daemon prio=5 tid=492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=765 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=38 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Socket Reader #1 for port 15001"  prio=5 tid=40 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 47 on default port 15000" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15000" daemon prio=5 tid=159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15002" daemon prio=5 tid=327 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15009" daemon prio=5 tid=570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-BlockDeletingService#0" daemon prio=5 tid=773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 92 on default port 15002" daemon prio=5 tid=352 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15009" daemon prio=5 tid=517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15001" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15002" daemon prio=5 tid=340 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 30 on default port 15002" daemon prio=5 tid=290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=756 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 49 on default port 15001" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ForkJoinPool.commonPool-worker-3" daemon prio=5 tid=23 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1724)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1623)
        at java.base@17.0.11/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
"IPC Server handler 55 on default port 15001" daemon prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15009" daemon prio=5 tid=525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"null-request--thread1" daemon prio=5 tid=932 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-CloseContainerThread-0"  prio=5 tid=1041 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-SstFilteringService#0" daemon prio=5 tid=402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp896212135-592" daemon prio=5 tid=592 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 46 on default port 15001" daemon prio=5 tid=206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15001" daemon prio=5 tid=239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-worker-ELG-3-4" daemon prio=5 tid=847 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:193)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:304)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:368)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 46 on default port 15000" daemon prio=5 tid=106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15009" daemon prio=5 tid=524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker" daemon prio=5 tid=1124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:302)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1119/0x00007fe940714488.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 71 on default port 15000" daemon prio=5 tid=131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15002" daemon prio=5 tid=344 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15009" daemon prio=5 tid=516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=597 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=776 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-ChunkWriter-1-0" daemon prio=5 tid=768 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 49 on default port 15000" daemon prio=5 tid=109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15002" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 26 on default port 15009" daemon prio=5 tid=499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15001" daemon prio=5 tid=253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"gradle-enterprise-test-client-gradle-enterprise-test-listener"  prio=5 tid=18 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:420)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.a(SourceFile:130)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.b(SourceFile:93)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a$$Lambda$309/0x00007fe940105000.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 56 on default port 15000" daemon prio=5 tid=116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15000" daemon prio=5 tid=112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"OverReplicatedProcessor" daemon prio=5 tid=31 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 99 on default port 15001" daemon prio=5 tid=259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15009" daemon prio=5 tid=490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15004" daemon prio=5 tid=433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15001" daemon prio=5 tid=257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15009" daemon prio=5 tid=495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp896212135-585" daemon prio=5 tid=585 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 40 on default port 15000" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-237c078c-1"  prio=5 tid=593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 19 on default port 15000" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15021" daemon prio=5 tid=626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-PipelineCommandHandlerThread-0"  prio=5 tid=882 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 76 on default port 15000" daemon prio=5 tid=136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15002" daemon prio=5 tid=358 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 78 on default port 15009" daemon prio=5 tid=551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp597906593-641-acceptor-0@3d7f92aa-ServerConnector@37347be1{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}" daemon prio=3 tid=641 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 91 on default port 15001" daemon prio=5 tid=251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15001" daemon prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15009" daemon prio=5 tid=473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-DatanodeReportManager-2" daemon prio=5 tid=711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 87 on default port 15000" daemon prio=5 tid=147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-CommandProcessorThread" daemon prio=5 tid=686 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:674)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1636/0x00007fe940c21538.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 21 on default port 15001" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15000" daemon prio=5 tid=121 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15000" daemon prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerSizeCountTask" daemon prio=5 tid=577 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ozone.recon.tasks.ContainerSizeCountTask.run(ContainerSizeCountTask.java:94)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1544/0x00007fe940bcf498.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-cacheEviction-AwaitToRun" daemon prio=5 tid=843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 5 on default port 15002" daemon prio=5 tid=265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@47a782a1" daemon prio=5 tid=664 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 64 on default port 15009" daemon prio=5 tid=537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=779 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-groupManagement"  prio=5 tid=883 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 61 on default port 15001" daemon prio=5 tid=221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15004" daemon prio=5 tid=432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-DatanodeReportManager-0" daemon prio=5 tid=682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/java.lang.Thread.dumpThreads(Native Method)
        at java.base@17.0.11/java.lang.Thread.getAllStackTraces(Thread.java:1671)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:83)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:69)
        at app//org.apache.ozone.test.TimedOutTestsListener.lambda$executionFinished$0(TimedOutTestsListener.java:55)
        at app//org.apache.ozone.test.TimedOutTestsListener$$Lambda$2621/0x00007fe940f7f340.accept(Unknown Source)
        at java.base@17.0.11/java.util.Optional.ifPresent(Optional.java:178)
        at app//org.apache.ozone.test.TimedOutTestsListener.executionFinished(TimedOutTestsListener.java:51)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$executionFinished$10(CompositeTestExecutionListener.java:73)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$2583/0x00007fe940f68d40.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$notifyEach$19(CompositeTestExecutionListener.java:102)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$299/0x00007fe9400b88a8.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.notifyEach(CompositeTestExecutionListener.java:100)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.executionFinished(CompositeTestExecutionListener.java:72)
        at app//org.junit.platform.launcher.core.ExecutionListenerAdapter.executionFinished(ExecutionListenerAdapter.java:56)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$executionFinished$6(CompositeEngineExecutionListener.java:59)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$2574/0x00007fe940f63a98.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$notifyEach$11(CompositeEngineExecutionListener.java:74)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$351/0x00007fe940115d20.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.notifyEach(CompositeEngineExecutionListener.java:72)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.executionFinished(CompositeEngineExecutionListener.java:58)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.StackTracePruningEngineExecutionListener.executionFinished(StackTracePruningEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.OutcomeDelayingEngineExecutionListener.executionFinished(OutcomeDelayingEngineExecutionListener.java:63)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion(NodeTestTask.java:195)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:142)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:110)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor$$Lambda$2310/0x00007fe940eed858.accept(Unknown Source)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:992)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:992)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@17.0.11/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@17.0.11/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@17.0.11/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@17.0.11/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:110)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:44)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$375/0x00007fe94011b760.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$374/0x00007fe94011b538.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$373/0x00007fe94011b110.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$379/0x00007fe94011f488.accept(Unknown Source)
        at java.base@17.0.11/java.util.ArrayList.forEach(ArrayList.java:1511)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$375/0x00007fe94011b760.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$374/0x00007fe94011b538.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$373/0x00007fe94011b110.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$379/0x00007fe94011f488.accept(Unknown Source)
        at java.base@17.0.11/java.util.ArrayList.forEach(ArrayList.java:1511)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$375/0x00007fe94011b760.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$374/0x00007fe94011b538.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$373/0x00007fe94011b110.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$287/0x00007fe9400b6480.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
        at app//org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at app//org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
        at app//org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
        at app//org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
        at app//org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
        at app//org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=58 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 45 on default port 15001" daemon prio=5 tid=205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 22 on default port 15001" daemon prio=5 tid=182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15002" daemon prio=5 tid=291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp193743819-408" daemon prio=5 tid=408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-DatanodeStateMachineTaskThread-1"  prio=5 tid=796 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 81 on default port 15001" daemon prio=5 tid=241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15002" daemon prio=5 tid=262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 25 on default port 15002" daemon prio=5 tid=285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 28 on default port 15002" daemon prio=5 tid=288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeReportManager-2" daemon prio=5 tid=657 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15009" daemon prio=5 tid=447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 67 on default port 15000" daemon prio=5 tid=127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=393 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 66 on default port 15009" daemon prio=5 tid=539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=819 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 63 on default port 15001" daemon prio=5 tid=223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 71 on default port 15009" daemon prio=5 tid=544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15002" daemon prio=5 tid=289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15009" daemon prio=5 tid=560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1178 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 33 on default port 15002" daemon prio=5 tid=293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 75 on default port 15000" daemon prio=5 tid=135 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15001" daemon prio=5 tid=218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15001" daemon prio=5 tid=220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 85 on default port 15002" daemon prio=5 tid=345 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15000" daemon prio=5 tid=118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=754 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15030" daemon prio=5 tid=648 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"grpc-default-executor-0" daemon prio=5 tid=838 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 75 on default port 15002" daemon prio=5 tid=335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-6b57b1c7-1"  prio=5 tid=415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=689 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 16 on default port 15000" daemon prio=5 tid=76 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ChunkWriter-1-0" daemon prio=5 tid=748 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 55 on default port 15000" daemon prio=5 tid=115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15000" daemon prio=5 tid=98 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15000" daemon prio=5 tid=128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15001" daemon prio=5 tid=180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-ChunkReader-ELG-0" daemon prio=5 tid=733 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 77 on default port 15000" daemon prio=5 tid=137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1940959701-700" daemon prio=5 tid=700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FullTableCache-Cleanup-0" daemon prio=5 tid=925 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@73d3b3fe" daemon prio=5 tid=691 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 57 on default port 15002" daemon prio=5 tid=317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15002" daemon prio=5 tid=326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 94 on default port 15009" daemon prio=5 tid=567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 86 on default port 15009" daemon prio=5 tid=559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15009" daemon prio=5 tid=498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1173 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-ChunkReader-ELG-0" daemon prio=5 tid=810 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 8 on default port 15004" daemon prio=5 tid=424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeStateMachineTaskThread-0"  prio=5 tid=660 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 91 on default port 15009" daemon prio=5 tid=564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15004" daemon prio=5 tid=425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15001" daemon prio=5 tid=247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15000" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15002"  prio=5 tid=35 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 98 on default port 15000" daemon prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15002" daemon prio=5 tid=332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15009" daemon prio=5 tid=484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater" daemon prio=5 tid=1135 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:219)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 24 on default port 15000" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15001" daemon prio=5 tid=228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-DirectoryDeletingService#0" daemon prio=5 tid=400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=812 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 96 on default port 15001" daemon prio=5 tid=256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15009" daemon prio=5 tid=538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15000" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-4cbf61e4-1"  prio=5 tid=647 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-cacheEviction-AwaitToRun" daemon prio=5 tid=1143 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ExpiredContainerReplicaOpScrubber" daemon prio=5 tid=28 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at app//org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$656/0x00007fe9403a2480.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 6 on default port 15002" daemon prio=5 tid=266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15000" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15002" daemon prio=5 tid=304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeReportManager-0" daemon prio=5 tid=601 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FullTableCache-Cleanup-0" daemon prio=5 tid=924 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp111768855-367" daemon prio=5 tid=367 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 7 on default port 15004" daemon prio=5 tid=423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-cacheEviction-AwaitToRun" daemon prio=5 tid=878 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"MutableQuantiles-0" daemon prio=5 tid=582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeStateMachineTaskThread-0"  prio=5 tid=607 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 66 on default port 15001" daemon prio=5 tid=226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp597906593-642" daemon prio=5 tid=642 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 53 on default port 15002" daemon prio=5 tid=313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15002" daemon prio=5 tid=321 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=816 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 7 on default port 15002" daemon prio=5 tid=267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-CommandProcessorThread" daemon prio=5 tid=659 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:674)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1636/0x00007fe940c21538.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread1" daemon prio=5 tid=1170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 10 on default port 15009" daemon prio=5 tid=483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15002" daemon prio=5 tid=287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1881254670-617" daemon prio=5 tid=617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderStateImpl" daemon prio=5 tid=1165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:766)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=444 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 58 on default port 15009" daemon prio=5 tid=531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-4a9412c4-1"  prio=5 tid=372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 80 on default port 15009" daemon prio=5 tid=553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15001" daemon prio=5 tid=225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeStateMachineDaemonThread" daemon prio=5 tid=600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:359)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:546)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1634/0x00007fe940c20ee8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 86 on default port 15000" daemon prio=5 tid=146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds)" daemon prio=5 tid=785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"grpc-default-executor-4" daemon prio=5 tid=1063 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 24 on default port 15009" daemon prio=5 tid=497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15039"  prio=5 tid=676 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"qtp597906593-639" daemon prio=5 tid=639 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1846446971-667" daemon prio=5 tid=667 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 75 on default port 15009" daemon prio=5 tid=548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-BlockDeletingService#1" daemon prio=5 tid=814 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1940959701-696-acceptor-0@60c18357-ServerConnector@4dccaef5{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}" daemon prio=3 tid=696 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 14 on default port 15009" daemon prio=5 tid=487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15000" daemon prio=5 tid=96 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 85 on default port 15001" daemon prio=5 tid=245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15001" daemon prio=5 tid=244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15000" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-DeleteContainerThread-0"  prio=5 tid=1127 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 45 on default port 15000" daemon prio=5 tid=105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMBlockDeletingService#0" daemon prio=5 tid=360 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 88 on default port 15001" daemon prio=5 tid=248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15009" daemon prio=5 tid=489 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=736 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp193743819-407" daemon prio=5 tid=407 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 10 on default port 15004" daemon prio=5 tid=426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15000" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp260382211-466" daemon prio=5 tid=466 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-181-thread-1"  prio=5 tid=665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"timer0" daemon prio=5 tid=935 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 22 on default port 15000" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDiffCleanupService#0" daemon prio=5 tid=378 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15004" daemon prio=5 tid=416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-BlockDeletingService#2" daemon prio=5 tid=1175 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1846446971-668-acceptor-0@276c823e-ServerConnector@9f2d904{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}" daemon prio=3 tid=668 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-groupManagement"  prio=5 tid=877 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-PipelineCommandHandlerThread-0"  prio=5 tid=864 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-cacheEviction-AwaitToRun" daemon prio=5 tid=1123 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 91 on default port 15000" daemon prio=5 tid=151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15000" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp260382211-465" daemon prio=5 tid=465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"timer2" daemon prio=5 tid=902 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"Reference Handler" daemon prio=10 tid=2 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/java.lang.ref.Reference.waitForReferencePendingList(Native Method)
        at java.base@17.0.11/java.lang.ref.Reference.processPendingReferences(Reference.java:253)
        at java.base@17.0.11/java.lang.ref.Reference$ReferenceHandler.run(Reference.java:215)
"qtp1940959701-697" daemon prio=5 tid=697 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 35 on default port 15000" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 94 on default port 15000" daemon prio=5 tid=154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15009" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=818 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"derby.rawStoreDaemon" daemon prio=5 tid=438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-SyncOM-1"  prio=5 tid=949 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-CloseContainerThread-2"  prio=5 tid=1048 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 88 on default port 15002" daemon prio=5 tid=348 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeReportManager-3" daemon prio=5 tid=658 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-ChunkWriter-1-0" daemon prio=5 tid=806 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Socket Reader #1 for port 15048"  prio=5 tid=703 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 47 on default port 15009" daemon prio=5 tid=520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15001" daemon prio=5 tid=198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 55 on default port 15002" daemon prio=5 tid=315 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15001" daemon prio=5 tid=249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15002" daemon prio=5 tid=260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15002" daemon prio=5 tid=342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=944 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderStateImpl" daemon prio=5 tid=1131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:766)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=817 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 9 on default port 15000" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer4" daemon prio=5 tid=907 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"Socket Reader #1 for port 15021"  prio=5 tid=622 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Client (1953044087) connection to 0.0.0.0/0.0.0.0:15002 from runner" daemon prio=5 tid=720 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Server handler 33 on default port 15000" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15002" daemon prio=5 tid=311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-ChunkWriter-0-0" daemon prio=5 tid=728 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp896212135-591" daemon prio=5 tid=591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=739 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 57 on default port 15000" daemon prio=5 tid=117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15009" daemon prio=5 tid=545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderStateImpl" daemon prio=5 tid=1129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:766)
"IPC Server handler 57 on default port 15001" daemon prio=5 tid=217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDeletingService#0" daemon prio=5 tid=403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 27 on default port 15001" daemon prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15000" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-ReplicationContainerReader-1" daemon prio=5 tid=1091 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 79 on default port 15002" daemon prio=5 tid=339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 80 on default port 15001" daemon prio=5 tid=240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15009" daemon prio=5 tid=445 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 1 on default port 15004" daemon prio=5 tid=417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15001" daemon prio=5 tid=211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15001" daemon prio=5 tid=160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 28 on default port 15001" daemon prio=5 tid=188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PeriodicHDDSVolumeChecker" daemon prio=5 tid=742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 2 on default port 15004" daemon prio=5 tid=418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15009" daemon prio=5 tid=563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"client-write-TID-0" daemon prio=5 tid=940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack$SNode.block(SynchronousQueue.java:288)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:397)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:886)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1881254670-618" daemon prio=5 tid=618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler" daemon prio=5 tid=1035 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-CloseContainerThread-0"  prio=5 tid=1038 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 16 on default port 15002" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15009" daemon prio=5 tid=522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15000" daemon prio=5 tid=124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 39 on default port 15009" daemon prio=5 tid=512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1881254670-612" daemon prio=5 tid=612 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ContainerHealthTask" daemon prio=5 tid=576 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.recon.fsck.ContainerHealthTask.run(ContainerHealthTask.java:111)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1544/0x00007fe940bcf498.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-EventQueue-NewNodeForReconNewNodeHandler" daemon prio=5 tid=815 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds)" daemon prio=5 tid=727 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 6 on default port 15004" daemon prio=5 tid=422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread3" daemon prio=5 tid=1172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 12 on default port 15002" daemon prio=5 tid=272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp111768855-368" daemon prio=5 tid=368 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 86 on default port 15002" daemon prio=5 tid=346 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15004" daemon prio=5 tid=431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15009" daemon prio=5 tid=554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15001" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15009" daemon prio=5 tid=557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-BlockDeletingService#1" daemon prio=5 tid=775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1846446971-671" daemon prio=5 tid=671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-EventQueue-StaleNodeForReconStaleNodeHandler" daemon prio=5 tid=875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp597906593-645" daemon prio=5 tid=645 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"SnapshotCacheCleanupService" daemon prio=5 tid=377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 3 on default port 15004" daemon prio=5 tid=419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15009" daemon prio=5 tid=513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15009" daemon prio=5 tid=542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 78 on default port 15000" daemon prio=5 tid=138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15000" daemon prio=5 tid=149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-ChunkWriter-3-0" daemon prio=5 tid=770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-PeriodicHDDSVolumeChecker" daemon prio=5 tid=800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"UnderReplicatedProcessor" daemon prio=5 tid=30 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-67-thread-1"  prio=5 tid=441 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 64 on default port 15001" daemon prio=5 tid=224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15030" daemon prio=5 tid=650 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:302)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1119/0x00007fe940714488.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds)" daemon prio=5 tid=746 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-BlockDeletingService#0" daemon prio=5 tid=753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15039" daemon prio=5 tid=677 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"qtp896212135-587-acceptor-0@728ac187-ServerConnector@5fe01354{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}" daemon prio=3 tid=587 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 95 on default port 15009" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-CloseContainerThread-1"  prio=5 tid=1043 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1181 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-cacheEviction-AwaitToRun" daemon prio=5 tid=1136 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp193743819-411" daemon prio=5 tid=411 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
        at java.base@17.0.11/java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:172)
"Timer-0"  prio=5 tid=395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 64 on default port 15002" daemon prio=5 tid=324 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 37 on default port 15009" daemon prio=5 tid=510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-DatanodeReportManager-3" daemon prio=5 tid=712 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 24 on default port 15002" daemon prio=5 tid=284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 73 on default port 15001" daemon prio=5 tid=233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeReportManager-2" daemon prio=5 tid=630 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker"  prio=5 tid=1120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:302)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1119/0x00007fe940714488.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-groupManagement"  prio=5 tid=842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 60 on default port 15009" daemon prio=5 tid=533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15001" daemon prio=5 tid=213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15009" daemon prio=5 tid=491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 39 on default port 15001" daemon prio=5 tid=199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15002" daemon prio=5 tid=306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp260382211-461" daemon prio=5 tid=461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-ContainerReplicationThread-0" daemon prio=5 tid=1089 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:535)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0"  prio=5 tid=841 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"timer5" daemon prio=5 tid=930 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 89 on default port 15002" daemon prio=5 tid=349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Parameter Sending Thread for localhost/127.0.0.1:15004" daemon prio=5 tid=951 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:704)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-CloseContainerThread-1"  prio=5 tid=1040 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ForkJoinPool.commonPool-worker-1" daemon prio=5 tid=21 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1724)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1623)
        at java.base@17.0.11/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
"IPC Server handler 65 on default port 15000" daemon prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15009" daemon prio=5 tid=523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15001" daemon prio=5 tid=222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor6" daemon prio=5 tid=790 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$739/0x00007fe9404e0b78.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-MultipartUploadCleanupService#0" daemon prio=5 tid=405 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server Responder" daemon prio=5 tid=705 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"pool-188-thread-1" daemon prio=5 tid=802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 42 on default port 15002" daemon prio=5 tid=302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 28 on default port 15009" daemon prio=5 tid=501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 54 on default port 15002" daemon prio=5 tid=314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1881254670-614-acceptor-0@5b318f16-ServerConnector@27a18e3b{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}" daemon prio=3 tid=614 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-BlockDeletingService#0" daemon prio=5 tid=811 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 60 on default port 15000" daemon prio=5 tid=120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-30-thread-1"  prio=5 tid=363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"JvmPauseMonitor2" daemon prio=5 tid=578 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$739/0x00007fe9404e0b78.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-executor-2" daemon prio=5 tid=900 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 43 on default port 15000" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15030"  prio=5 tid=649 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"qtp1846446971-669" daemon prio=5 tid=669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15012" daemon prio=5 tid=596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"timer1" daemon prio=5 tid=901 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 59 on default port 15001" daemon prio=5 tid=219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-140-thread-1" daemon prio=5 tid=763 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 14 on default port 15001" daemon prio=5 tid=174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-DatanodeReportManager-0" daemon prio=5 tid=709 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 17 on default port 15002" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15000" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 39 on default port 15002" daemon prio=5 tid=299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Connector-Scheduler-157e14f2-1"  prio=5 tid=952 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderStateImpl" daemon prio=5 tid=916 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:766)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-groupManagement" daemon prio=5 tid=853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 9 on default port 15001" daemon prio=5 tid=169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeReportManager-3" daemon prio=5 tid=631 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 31 on default port 15001" daemon prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1846446971-670" daemon prio=5 tid=670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 67 on default port 15001" daemon prio=5 tid=227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15002" daemon prio=5 tid=312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15001" daemon prio=5 tid=237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15001" daemon prio=5 tid=170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=822 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-executor-5" daemon prio=5 tid=1064 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15000" daemon prio=5 tid=1066 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:704)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"Socket Reader #1 for port 15004"  prio=5 tid=384 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 90 on default port 15002" daemon prio=5 tid=350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 99 on default port 15002" daemon prio=5 tid=359 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15009" daemon prio=5 tid=572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15009" daemon prio=5 tid=719 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:704)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 42 on default port 15009" daemon prio=5 tid=515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 88 on default port 15009" daemon prio=5 tid=561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-worker-ELG-3-3" daemon prio=5 tid=840 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:193)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:304)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:368)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 12 on default port 15000" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15009" daemon prio=5 tid=502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-BlockDeletingService#2" daemon prio=5 tid=1177 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 5 on default port 15001" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeReportManager-0" daemon prio=5 tid=655 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 84 on default port 15000" daemon prio=5 tid=144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15000"  prio=5 tid=45 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 18 on default port 15000" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15000" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15004" daemon prio=5 tid=428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds)" daemon prio=5 tid=804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 82 on default port 15009" daemon prio=5 tid=555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15000" daemon prio=5 tid=139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15001" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-ChunkWriter-3-0" daemon prio=5 tid=808 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1179 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 98 on default port 15009" daemon prio=5 tid=571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"qtp597906593-644" daemon prio=5 tid=644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-ReplicationContainerReader-2" daemon prio=5 tid=1092 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15030" daemon prio=5 tid=653 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-CloseContainerThread-1"  prio=5 tid=1047 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp597906593-643" daemon prio=5 tid=643 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-ChunkWriter-2-0" daemon prio=5 tid=788 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 82 on default port 15000" daemon prio=5 tid=142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=442 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.Object.wait(Object.java:338)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:537)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server Responder" daemon prio=5 tid=386 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-CommandProcessorThread" daemon prio=5 tid=632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:674)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1636/0x00007fe940c21538.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=813 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1881254670-619" daemon prio=5 tid=619 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp193743819-409-acceptor-0@6df950e2-ServerConnector@157e14f2{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}" daemon prio=3 tid=409 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 83 on default port 15000" daemon prio=5 tid=143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 35 on default port 15002" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15009" daemon prio=5 tid=505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderStateImpl" daemon prio=5 tid=912 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:766)
"IPC Server handler 9 on default port 15002" daemon prio=5 tid=269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15002" daemon prio=5 tid=307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15002" daemon prio=5 tid=328 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-91-thread-1" daemon prio=5 tid=725 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeStateMachineDaemonThread" daemon prio=5 tid=654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:359)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:546)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1634/0x00007fe940c20ee8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=839 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:193)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:304)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:368)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp193743819-412" daemon prio=5 tid=412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15039" daemon prio=5 tid=680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15002" daemon prio=5 tid=280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 63 on default port 15009" daemon prio=5 tid=536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15000" daemon prio=5 tid=129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler" daemon prio=5 tid=1032 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 37 on default port 15002" daemon prio=5 tid=297 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"NetworkTopologyPoller" daemon prio=5 tid=398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15002" daemon prio=5 tid=34 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"4873639b-1d87-440f-9147-409a0544c1cf-BlockDeletingService#2" daemon prio=5 tid=1180 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp193743819-413" daemon prio=5 tid=413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-CloseContainerForCloseContainerEventHandler" daemon prio=5 tid=1036 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeReportManager-1" daemon prio=5 tid=629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp896212135-589" daemon prio=5 tid=589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineTaskThread-1"  prio=5 tid=777 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 96 on default port 15002" daemon prio=5 tid=356 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=717 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-157-thread-1"  prio=5 tid=638 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 22 on default port 15002" daemon prio=5 tid=282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15001" daemon prio=5 tid=255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=929 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1846446971-666" daemon prio=5 tid=666 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 42 on default port 15000" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ReplicationMonitor" daemon prio=5 tid=29 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:934)
        at app//org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$670/0x00007fe9403bc308.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 37 on default port 15000" daemon prio=5 tid=97 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15001" daemon prio=5 tid=194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=387 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-BlockDeletingService#0" daemon prio=5 tid=734 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 24 on default port 15001" daemon prio=5 tid=184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-114-thread-1" daemon prio=5 tid=744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-133-thread-1"  prio=5 tid=611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 26 on default port 15000" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=793 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"process reaper" daemon prio=10 tid=16 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 13 on default port 15001" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Notification Thread" daemon prio=9 tid=13 runnable
java.lang.Thread.State: RUNNABLE
"4873639b-1d87-440f-9147-409a0544c1cf-DatanodeReportManager-3" daemon prio=5 tid=685 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 14 on default port 15002" daemon prio=5 tid=274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15009" daemon prio=5 tid=506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15009" daemon prio=5 tid=478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState" daemon prio=5 tid=1163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:129)
"IPC Server handler 90 on default port 15001" daemon prio=5 tid=250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"DatanodeAdminManager-0" daemon prio=5 tid=32 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"LeakDetector-ManagedRocksObject0" daemon prio=5 tid=24 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
        at app//org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:80)
        at app//org.apache.hadoop.hdds.utils.LeakDetector$$Lambda$573/0x00007fe94028de60.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 3 on default port 15002" daemon prio=5 tid=263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=635 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 1 on default port 15009" daemon prio=5 tid=474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15009" daemon prio=5 tid=521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15009" daemon prio=5 tid=550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15002" daemon prio=5 tid=329 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15002" daemon prio=5 tid=283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=758 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 2 on default port 15001" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15002" daemon prio=5 tid=300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 26 on default port 15002" daemon prio=5 tid=286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=943 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 36 on default port 15002" daemon prio=5 tid=296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15000" daemon prio=5 tid=152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15009" daemon prio=5 tid=504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 73 on default port 15002" daemon prio=5 tid=333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"junit-jupiter-timeout-watcher"  prio=10 tid=1029 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeStateMachineTaskThread-1"  prio=5 tid=757 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 4 on default port 15002" daemon prio=5 tid=264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Connector-Scheduler-74e37ad3-1"  prio=5 tid=948 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 14 on default port 15000" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15001" daemon prio=5 tid=193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15009" daemon prio=5 tid=480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDirectoryCleaningService#0" daemon prio=5 tid=404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 96 on default port 15009" daemon prio=5 tid=569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater" daemon prio=5 tid=1139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:219)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-DatanodeReportManager-1" daemon prio=5 tid=710 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 19 on default port 15002" daemon prio=5 tid=279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15002" daemon prio=5 tid=337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 26 on default port 15001" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15009" daemon prio=5 tid=503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-CloseContainerThread-2"  prio=5 tid=1055 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-DatanodeReportManager-2" daemon prio=5 tid=684 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater" daemon prio=5 tid=1126 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:219)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 66 on default port 15000" daemon prio=5 tid=126 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15000" daemon prio=5 tid=94 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15004" daemon prio=5 tid=427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineTaskThread-0"  prio=5 tid=687 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-ChunkWriter-1-0" daemon prio=5 tid=729 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-DatanodeStateMachineTaskThread-0"  prio=5 tid=714 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 70 on default port 15002" daemon prio=5 tid=330 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15009" daemon prio=5 tid=486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-ChunkWriter-2-0" daemon prio=5 tid=730 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-BlockDeletingService#0" daemon prio=5 tid=792 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 75 on default port 15001" daemon prio=5 tid=235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15000" daemon prio=5 tid=119 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15004" daemon prio=5 tid=435 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15001" daemon prio=5 tid=176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-BlockDeletingService#1" daemon prio=5 tid=795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=798 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 56 on default port 15001" daemon prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-DatanodeReportManager-1" daemon prio=5 tid=683 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 1 on default port 15000" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15000" daemon prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 71 on default port 15001" daemon prio=5 tid=231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=829 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 43 on default port 15002" daemon prio=5 tid=303 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15001" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=25 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 76 on default port 15002" daemon prio=5 tid=336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp260382211-460" daemon prio=5 tid=460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeStateMachineTaskThread-1"  prio=5 tid=738 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 8 on default port 15002" daemon prio=5 tid=268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 14 on default port 15004" daemon prio=5 tid=430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-ChunkWriter-0-0" daemon prio=5 tid=786 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"timer3" daemon prio=5 tid=904 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 47 on default port 15001" daemon prio=5 tid=207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15002" daemon prio=5 tid=271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15000" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 62 on default port 15000" daemon prio=5 tid=122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15001" daemon prio=5 tid=189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15002" daemon prio=5 tid=292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1176 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15001" daemon prio=5 tid=39 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 7 on default port 15001" daemon prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeStateMachineTaskThread-1"  prio=5 tid=715 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-29-thread-1"  prio=5 tid=1037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp111768855-370" daemon prio=5 tid=370 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 94 on default port 15002" daemon prio=5 tid=354 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15009"  prio=5 tid=446 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"Session-HouseKeeper-42583cc1-1"  prio=5 tid=701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-OMStateMachineApplyTransactionThread - 0" daemon prio=5 tid=923 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-ChunkWriter-3-0" daemon prio=5 tid=731 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=824 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp260382211-467" daemon prio=5 tid=467 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15048" daemon prio=5 tid=702 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"qtp260382211-462" daemon prio=5 tid=462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 83 on default port 15002" daemon prio=5 tid=343 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer6" daemon prio=5 tid=933 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 95 on default port 15002" daemon prio=5 tid=355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15009" daemon prio=5 tid=479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp896212135-588" daemon prio=5 tid=588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 70 on default port 15000" daemon prio=5 tid=130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-ChunkReader-ELG-0" daemon prio=5 tid=772 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 62 on default port 15002" daemon prio=5 tid=322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ChunkReader-ELG-0" daemon prio=5 tid=752 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-BlockDeletingService#2" daemon prio=5 tid=1182 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-CommandProcessorThread" daemon prio=5 tid=713 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:674)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1636/0x00007fe940c21538.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"7c590364-16f9-412e-8d8f-583652a307a8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=797 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp193743819-414" daemon prio=5 tid=414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server Responder" daemon prio=5 tid=651 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 30 on default port 15000" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp260382211-464" daemon prio=5 tid=464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 38 on default port 15002" daemon prio=5 tid=298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15002" daemon prio=5 tid=308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15009" daemon prio=5 tid=541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 70 on default port 15009" daemon prio=5 tid=543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15009" daemon prio=5 tid=534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15002" daemon prio=5 tid=278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ChunkWriter-3-0" daemon prio=5 tid=750 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 35 on default port 15009" daemon prio=5 tid=508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15009" daemon prio=5 tid=509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15009" daemon prio=5 tid=476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1881254670-613" daemon prio=5 tid=613 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-KeyDeletingService#0" daemon prio=5 tid=399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=837 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:193)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:304)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:368)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp111768855-366-acceptor-0@21927c58-ServerConnector@46ff1aad{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}" daemon prio=3 tid=366 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 76 on default port 15009" daemon prio=5 tid=549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7dd66054" daemon prio=5 tid=583 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineDaemonThread" daemon prio=5 tid=681 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:359)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:546)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1634/0x00007fe940c20ee8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 41 on default port 15000" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-PipelineCommandHandlerThread-0"  prio=5 tid=876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 48 on default port 15001" daemon prio=5 tid=208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp260382211-463-acceptor-0@3c57ff7c-ServerConnector@74e37ad3{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}" daemon prio=3 tid=463 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker"  prio=5 tid=1137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:302)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1119/0x00007fe940714488.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 32 on default port 15000" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 74 on default port 15000" daemon prio=5 tid=134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15009" daemon prio=5 tid=562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds)" daemon prio=5 tid=766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 63 on default port 15000" daemon prio=5 tid=123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15002" daemon prio=5 tid=347 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:290)
        at app//org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:258)
        at app//org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at app//org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1871/0x00007fe940d6eb20.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 18 on default port 15001" daemon prio=5 tid=178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15000" daemon prio=5 tid=157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15009" daemon prio=5 tid=565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=706 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp896212135-590" daemon prio=5 tid=590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 83 on default port 15009" daemon prio=5 tid=556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=37 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 45 on default port 15002" daemon prio=5 tid=305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=928 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 20 on default port 15009" daemon prio=5 tid=493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15009" daemon prio=5 tid=526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15000" daemon prio=5 tid=44 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ChunkWriter-2-0" daemon prio=5 tid=749 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 21 on default port 15009" daemon prio=5 tid=494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15021" daemon prio=5 tid=623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 17 on default port 15001" daemon prio=5 tid=177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15009" daemon prio=5 tid=475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15001" daemon prio=5 tid=175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15039" daemon prio=5 tid=675 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker"  prio=5 tid=879 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:302)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1119/0x00007fe940714488.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 92 on default port 15001" daemon prio=5 tid=252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 63 on default port 15002" daemon prio=5 tid=323 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-server-thread1" daemon prio=5 tid=1168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 78 on default port 15001" daemon prio=5 tid=238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1940959701-699" daemon prio=5 tid=699 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 78 on default port 15002" daemon prio=5 tid=338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=774 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7fed08c6" daemon prio=5 tid=610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 15 on default port 15009" daemon prio=5 tid=488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-PeriodicHDDSVolumeChecker" daemon prio=5 tid=723 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=716 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-CloseContainerThread-0"  prio=5 tid=1039 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 76 on default port 15001" daemon prio=5 tid=236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15002" daemon prio=5 tid=294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-ChunkWriter-0-0" daemon prio=5 tid=747 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 72 on default port 15000" daemon prio=5 tid=132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 54 on default port 15009" daemon prio=5 tid=527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15001" daemon prio=5 tid=242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-server-thread2" daemon prio=5 tid=1171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 12 on default port 15001" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-OMDoubleBufferFlushThread" daemon prio=5 tid=380 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:570)
        at app//org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:294)
        at app//org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$897/0x00007fe94062d4a8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 25 on default port 15001" daemon prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp111768855-371" daemon prio=5 tid=371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=662 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 17 on default port 15000" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15004" daemon prio=5 tid=383 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"pool-109-thread-1"  prio=5 tid=584 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server Responder" daemon prio=5 tid=624 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-DatanodeStateMachineDaemonThread" daemon prio=5 tid=627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:359)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:546)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1634/0x00007fe940c20ee8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp597906593-640" daemon prio=5 tid=640 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ContainerMetadataScanner" daemon prio=5 tid=803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 6 on default port 15000" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15048" daemon prio=5 tid=704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater" daemon prio=5 tid=1122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:219)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server Responder" daemon prio=5 tid=678 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"qtp1881254670-616" daemon prio=5 tid=616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 59 on default port 15002" daemon prio=5 tid=319 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-ChunkWriter-0-0" daemon prio=5 tid=805 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 8 on default port 15009" daemon prio=5 tid=481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-cacheEviction-AwaitToRun" daemon prio=5 tid=1132 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 21 on default port 15002" daemon prio=5 tid=281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15009" daemon prio=5 tid=477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-DatanodeReportManager-1" daemon prio=5 tid=656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState" daemon prio=5 tid=1164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:129)
"Recon-EventQueue-PipelineReportForReconPipelineReportHandler" daemon prio=5 tid=821 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker"  prio=5 tid=1133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:302)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1119/0x00007fe940714488.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"4873639b-1d87-440f-9147-409a0544c1cf-ChunkWriter-3-0" daemon prio=5 tid=789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-PipelineCommandHandlerThread-0"  prio=5 tid=826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:219)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=735 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 74 on default port 15002" daemon prio=5 tid=334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15009" daemon prio=5 tid=511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15021" daemon prio=5 tid=621 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 21 on default port 15000" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 74 on default port 15001" daemon prio=5 tid=234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15009" daemon prio=5 tid=482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15004" daemon prio=5 tid=420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-205-thread-1"  prio=5 tid=692 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"SSL Certificates Store Monitor" daemon prio=5 tid=443 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.Object.wait(Object.java:338)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:537)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"timer7" daemon prio=5 tid=934 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-CloseContainerThread-2"  prio=5 tid=1042 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-groupManagement"  prio=5 tid=827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp896212135-586" daemon prio=5 tid=586 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$779/0x00007fe94053da38.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Client (1953044087) connection to localhost/127.0.0.1:15004 from runner" daemon prio=5 tid=950 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Server handler 41 on default port 15002" daemon prio=5 tid=301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ForkJoinPool.commonPool-worker-2" daemon prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkUntil(LockSupport.java:410)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1726)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1623)
        at java.base@17.0.11/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
"IPC Server handler 58 on default port 15002" daemon prio=5 tid=318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15009" daemon prio=5 tid=532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d911fb7d-ae06-4770-ac9a-ead30a7876df-PeriodicHDDSVolumeChecker" daemon prio=5 tid=761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 5 on default port 15004" daemon prio=5 tid=421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeReportManager-2" daemon prio=5 tid=603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-executor-3" daemon prio=5 tid=909 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 41 on default port 15009" daemon prio=5 tid=514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker"  prio=5 tid=1144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:302)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1119/0x00007fe940714488.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 85 on default port 15000" daemon prio=5 tid=145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15000" daemon prio=5 tid=140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp597906593-646" daemon prio=5 tid=646 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-DatanodeReportManager-1" daemon prio=5 tid=602 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater" daemon prio=5 tid=846 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:219)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:187)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 50 on default port 15001" daemon prio=5 tid=210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor1" daemon prio=5 tid=394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$739/0x00007fe9404e0b78.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Client (1953044087) connection to 0.0.0.0/0.0.0.0:15009 from runner" daemon prio=5 tid=718 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Server handler 20 on default port 15000" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"7c590364-16f9-412e-8d8f-583652a307a8-DatanodeStateMachineDaemonThread" daemon prio=5 tid=708 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:359)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:546)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1634/0x00007fe940c20ee8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=580 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 1 on default port 15001" daemon prio=5 tid=161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 54 on default port 15000" daemon prio=5 tid=114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 85 on default port 15009" daemon prio=5 tid=558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 94 on default port 15001" daemon prio=5 tid=254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15002" daemon prio=5 tid=309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"4873639b-1d87-440f-9147-409a0544c1cf-server-thread2" daemon prio=5 tid=1169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 23 on default port 15001" daemon prio=5 tid=183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ReconTaskThread-0"  prio=5 tid=1026 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 97 on default port 15002" daemon prio=5 tid=357 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor3" daemon prio=5 tid=732 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$739/0x00007fe9404e0b78.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 98 on default port 15001" daemon prio=5 tid=258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1940959701-698" daemon prio=5 tid=698 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=14 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/java.io.FileInputStream.readBytes(Native Method)
        at java.base@17.0.11/java.io.FileInputStream.read(FileInputStream.java:276)
        at java.base@17.0.11/java.io.BufferedInputStream.fill(BufferedInputStream.java:244)
        at java.base@17.0.11/java.io.BufferedInputStream.read(BufferedInputStream.java:263)
        at java.base@17.0.11/java.io.DataInputStream.readInt(DataInputStream.java:381)
        at app//org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:113)
        at app//org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:383)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)

2024-07-01 06:01:41,132 [main] INFO  scm.XceiverClientRatis (XceiverClientRatis.java:<init>(139)) - WatchType ALL_COMMITTED. Majority 1, 
2024-07-01 06:01:41,164 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(244)) - Successfully added container #2 to Recon.
2024-07-01 06:01:41,165 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 14 millisec, 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-07-01 06:01:41,192 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 15
2024-07-01 06:01:41,192 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:41,192 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:41,192 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 15 
2024-07-01 06:01:41,200 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 2, SequenceNumber diff: 7, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:41,200 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 7 records
2024-07-01 06:01:41,316 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
2024-07-01 06:01:41,663 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:41,664 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:41,664 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:41,664 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:41,664 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:41,664 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:41,664 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:41,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-07-01 06:01:42,203 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-07-01 06:01:42,203 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:42,203 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-07-01 06:01:42,203 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds) is shutting down. 
2024-07-01 06:01:42,204 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:42,204 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds, DS-afa75c00-b616-444c-8afa-8f1e266a329f) exiting.
2024-07-01 06:01:42,204 [main] INFO  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:shutdownScanner(206)) - On-demand container scanner is shutting down.
2024-07-01 06:01:42,207 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(418)) - 4873639b-1d87-440f-9147-409a0544c1cf: close
2024-07-01 06:01:42,208 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: shutdown
2024-07-01 06:01:42,208 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-07-01 06:01:42,208 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: shutdown
2024-07-01 06:01:42,211 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F848EAF35609,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:42,211 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState
2024-07-01 06:01:42,211 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState was interrupted
2024-07-01 06:01:42,211 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-F848EAF35609: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/sm/snapshot.1_0
2024-07-01 06:01:42,211 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:42,211 [Thread-936] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 7c590364-16f9-412e-8d8f-583652a307a8 Close channels
2024-07-01 06:01:42,212 [grpc-default-executor-0] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(121)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-07-01 06:01:42,212 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-F848EAF35609: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/sm/snapshot.1_0 took: 1 ms
2024-07-01 06:01:42,212 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:42,212 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:42,212 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:42,213 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:42,208 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-084CCD2B28B6,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:42,214 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-LeaderStateImpl
2024-07-01 06:01:42,214 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:42,215 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater: set stopIndex = 4
2024-07-01 06:01:42,215 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-084CCD2B28B6: Taking a snapshot at:(t:1, i:4) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6/sm/snapshot.1_4
2024-07-01 06:01:42,215 [Thread-939] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 Close channels
2024-07-01 06:01:42,216 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-084CCD2B28B6: Finished taking a snapshot at:(t:1, i:4) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6/sm/snapshot.1_4 took: 1 ms
2024-07-01 06:01:42,216 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater: Took a snapshot at index 4
2024-07-01 06:01:42,216 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-07-01 06:01:42,216 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server GrpcServerProtocolService now
2024-07-01 06:01:42,216 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 4
2024-07-01 06:01:42,218 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:4)
2024-07-01 06:01:42,220 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:42,221 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(121)) - 4873639b-1d87-440f-9147-409a0544c1cf: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-07-01 06:01:42,223 [grpc-default-executor-0] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(121)) - 4873639b-1d87-440f-9147-409a0544c1cf: APPEND_ENTRIES onError, lastRequest: bfc6da33-104c-4d07-98ee-1aed7336cdfb->4873639b-1d87-440f-9147-409a0544c1cf#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id:"4873639b-1d87-440f-9147-409a0544c1cf"address:"127.0.0.1:15043"dataStreamAddress:"127.0.0.1:15044"clientAddress:"127.0.0.1:15041"adminAddress:"127.0.0.1:15042"startupRole:FOLLOWER, id:"bfc6da33-104c-4d07-98ee-1aed7336cdfb"address:"127.0.0.1:15016"priority:1dataStreamAddress:"127.0.0.1:15017"clientAddress:"127.0.0.1:15014"adminAddress:"127.0.0.1:15015"startupRole:FOLLOWER, id:"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91"address:"127.0.0.1:15025"dataStreamAddress:"127.0.0.1:15026"clientAddress:"127.0.0.1:15023"adminAddress:"127.0.0.1:15024"startupRole:FOLLOWER, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-07-01 06:01:42,223 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server GrpcServerProtocolService successfully
2024-07-01 06:01:42,223 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-07-01 06:01:42,224 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2024-07-01 06:01:42,224 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-07-01 06:01:42,225 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(221)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (1) unchanged and retry.
2024-07-01 06:01:42,243 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaff6a543, L:/0.0.0.0:15044] CLOSE
2024-07-01 06:01:42,243 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaff6a543, L:/0.0.0.0:15044] INACTIVE
2024-07-01 06:01:42,243 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaff6a543, L:/0.0.0.0:15044] UNREGISTERED
2024-07-01 06:01:42,316 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:42,316 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:42,316 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:42,316 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:42,320 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:42,320 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:42,321 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
2024-07-01 06:01:42,629 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker close()
2024-07-01 06:01:42,667 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:42,667 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:42,667 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:42,667 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:42,667 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:42,667 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:42,667 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:42,877 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-07-01 06:01:43,157 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker close()
2024-07-01 06:01:43,158 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-4873639b-1d87-440f-9147-409a0544c1cf: Stopped
2024-07-01 06:01:43,321 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:43,321 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:43,322 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:43,322 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:43,323 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:43,323 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:43,325 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
2024-07-01 06:01:43,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:43,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:43,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:43,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:43,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:43,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:43,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:43,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-07-01 06:01:44,325 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:44,325 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:44,325 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:44,325 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:44,327 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:44,327 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:44,328 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
2024-07-01 06:01:44,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:44,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:44,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:44,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:44,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:44,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:44,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:44,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-07-01 06:01:45,168 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-205e25c1-5543-4288-a226-6c3910f61994/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-03f05026-6558-4a94-a93b-33a7a73f0436/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-76e85e00-675e-4383-b07b-e58193edac37/container.db]
2024-07-01 06:01:45,171 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db from cache
2024-07-01 06:01:45,171 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db for volume DS-afa75c00-b616-444c-8afa-8f1e266a329f
2024-07-01 06:01:45,171 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-07-01 06:01:45,172 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-07-01 06:01:45,172 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(628)) - Ozone container server stopped.
2024-07-01 06:01:45,181 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3c07d704{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:01:45,183 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@9f2d904{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-07-01 06:01:45,183 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:45,183 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2952a16{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-07-01 06:01:45,184 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@53568b43{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:45,185 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-07-01 06:01:45,185 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15039
2024-07-01 06:01:45,185 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15039
2024-07-01 06:01:45,186 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:45,186 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:45,193 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6, PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0, PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609]
2024-07-01 06:01:45,194 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6
2024-07-01 06:01:45,194 [Recon-EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-07-01 06:01:45,195 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 moved to CLOSED state
2024-07-01 06:01:45,195 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(226)) - Ignoring unsupported command closeContainerCommand for Datanode 4873639b-1d87-440f-9147-409a0544c1cf.
2024-07-01 06:01:45,195 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 moved to CLOSED state
2024-07-01 06:01:45,196 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 moved to CLOSED state
2024-07-01 06:01:45,197 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 10 pipelines in house.
2024-07-01 06:01:45,197 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:01:45,198 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd already exists in Recon pipeline metadata.
2024-07-01 06:01:45,198 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 already exists in Recon pipeline metadata.
2024-07-01 06:01:45,198 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 already exists in Recon pipeline metadata.
2024-07-01 06:01:45,199 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a already exists in Recon pipeline metadata.
2024-07-01 06:01:45,200 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(149)) - Removing invalid pipeline PipelineID=fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f from Recon.
2024-07-01 06:01:45,201 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: fba6c42c-84a9-4ffc-a1f8-3f456ffc0a9f, Nodes: d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d911fb7d-ae06-4770-ac9a-ead30a7876df, CreationTimestamp2024-07-01T06:00:37.387Z[Etc/UTC]] removed.
2024-07-01 06:01:45,201 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(149)) - Removing invalid pipeline PipelineID=83d0b075-21bf-48bf-ac12-3d02eec07596 from Recon.
2024-07-01 06:01:45,201 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 83d0b075-21bf-48bf-ac12-3d02eec07596, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:00:36.961Z[Etc/UTC]] removed.
2024-07-01 06:01:45,201 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(149)) - Removing invalid pipeline PipelineID=021f4cea-3012-4c29-83fe-bdbb6172c2d0 from Recon.
2024-07-01 06:01:45,202 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 021f4cea-3012-4c29-83fe-bdbb6172c2d0, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 07c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91, CreationTimestamp2024-07-01T06:00:54.860Z[Etc/UTC]] removed.
2024-07-01 06:01:45,202 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(149)) - Removing invalid pipeline PipelineID=6a54b320-18b2-409b-b307-9d3e094e5440 from Recon.
2024-07-01 06:01:45,202 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 6a54b320-18b2-409b-b307-9d3e094e5440, Nodes: bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) ReplicaIndex: 0bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:00:37.392Z[Etc/UTC]] removed.
2024-07-01 06:01:45,203 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(149)) - Removing invalid pipeline PipelineID=90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1 from Recon.
2024-07-01 06:01:45,203 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 90e565a2-1f79-4016-bdeb-9ae4f3f9c8f1, Nodes: 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:7c590364-16f9-412e-8d8f-583652a307a8, CreationTimestamp2024-07-01T06:00:37.803Z[Etc/UTC]] removed.
2024-07-01 06:01:45,232 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6, PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609]
2024-07-01 06:01:45,232 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6
2024-07-01 06:01:45,232 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-07-01 06:01:45,233 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 moved to CLOSED state
2024-07-01 06:01:45,233 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 moved to CLOSED state
2024-07-01 06:01:45,328 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:45,328 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:45,328 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:45,328 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:45,330 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:45,330 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:45,331 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
2024-07-01 06:01:45,386 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:45,587 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:45,676 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:45,676 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:45,676 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:45,676 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:45,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:45,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:45,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:45,787 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:45,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-07-01T06:01:45.232414221Z, pipelineID=PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6, owner=omServiceIdDefault} to 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) with datanode deadline 1719814275879 and scm deadline 1719814305879
2024-07-01 06:01:45,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-07-01 06:01:45,987 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:46,188 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:46,332 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:46,332 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:46,332 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:46,332 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:46,334 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:46,334 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:46,335 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
2024-07-01 06:01:46,388 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:46,588 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:46,679 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:46,679 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:46,679 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:46,679 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:46,679 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:46,679 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:46,679 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:46,788 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:46,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-07-01T06:01:45.232414221Z, pipelineID=PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6, owner=omServiceIdDefault} to 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) with datanode deadline 1719814276880 and scm deadline 1719814306880
2024-07-01 06:01:46,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-07-01 06:01:46,989 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:47,189 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:47,225 [timer3] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-AppendLogResponseHandler: Failed appendEntries (Repeated 10 times in the last 5.001s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-07-01 06:01:47,225 [timer4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(221)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender: Follower failed (request=null, errorCount=10); keep nextIndex (1) unchanged and retry. (Repeated 10 times in the last 5.000s)
2024-07-01 06:01:47,336 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:47,336 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:47,336 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:47,336 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:47,338 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:47,338 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:47,339 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
2024-07-01 06:01:47,389 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:47,590 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:47,667 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-07-01 06:01:47,668 [grpc-default-executor-4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(221)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender: Follower failed (request=null, errorCount=11); keep nextIndex (1) unchanged and retry.
2024-07-01 06:01:47,682 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:47,682 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:47,682 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:47,682 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:47,682 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:47,682 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:47,682 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:47,790 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:47,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-07-01T06:01:45.232414221Z, pipelineID=PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6, owner=omServiceIdDefault} to 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) with datanode deadline 1719814277881 and scm deadline 1719814307881
2024-07-01 06:01:47,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-07-01 06:01:47,990 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:48,191 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [4873639b-1d87-440f-9147-409a0544c1cf]
2024-07-01 06:01:48,196 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:48,198 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 moved to CLOSED state
2024-07-01 06:01:48,199 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 91926170-46b2-4d66-81ef-084ccd2b28b6, Nodes: 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:4873639b-1d87-440f-9147-409a0544c1cf, CreationTimestamp2024-07-01T06:00:37.601Z[Etc/UTC]] removed.
2024-07-01 06:01:48,199 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 moved to CLOSED state
2024-07-01 06:01:48,200 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: ee6424f6-b724-4afc-aa46-f848eaf35609, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:01:10.860Z[Etc/UTC]] removed.
2024-07-01 06:01:48,201 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 0 for DN 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:48,201 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(212)) - Removed a node: /default-rack/4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:48,209 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:generateUnhealthyRecords(483)) - Non-empty container 2 is missing. It has 1 keys and 7 bytes used according to SCM metadata. Please visit Recon's missing container page for a list of keys (and their metadata) mapped to this container.
2024-07-01 06:01:48,213 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:48,213 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:48,213 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:48,213 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:48,213 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-07-01 06:01:48,213 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:48,213 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:48,215 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-07-01 06:01:48,215 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:01:48,215 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd already exists in Recon pipeline metadata.
2024-07-01 06:01:48,216 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(109)) - Added new pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 from SCM.
2024-07-01 06:01:48,217 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(109)) - Added new pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 from SCM.
2024-07-01 06:01:48,217 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a already exists in Recon pipeline metadata.
2024-07-01 06:01:48,219 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  scm.PipelineSyncTask (PipelineSyncTask.java:syncOperationalStateOnDeadNodes(125)) - Node localhost DEAD in Recon, but SCM reports it as STALE
2024-07-01 06:01:48,235 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:48,236 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 close command to datanode 4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:48,236 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 91926170-46b2-4d66-81ef-084ccd2b28b6, Nodes: 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:4873639b-1d87-440f-9147-409a0544c1cf, CreationTimestamp2024-07-01T06:00:37.601Z[Etc/UTC]] removed.
2024-07-01 06:01:48,236 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 close command to datanode bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:48,236 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 close command to datanode 4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:48,237 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 close command to datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:48,237 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: ee6424f6-b724-4afc-aa46-f848eaf35609, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:01:10.860Z[Etc/UTC]] removed.
2024-07-01 06:01:48,237 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 5 for DN 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1)
2024-07-01 06:01:48,237 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(212)) - Removed a node: /default-rack/4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:48,339 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:48,340 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:48,340 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:48,340 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:48,341 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:48,341 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:48,343 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
2024-07-01 06:01:48,391 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 0 replicas on []
2024-07-01 06:01:48,687 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:48,687 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:48,687 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:48,687 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:48,687 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:48,687 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:48,687 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:48,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-07-01 06:01:49,343 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:49,343 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:49,344 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:49,344 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:49,345 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(529)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-07-01 06:01:49,345 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(482)) - Delta updates received from OM : 1 loops, 0 records
2024-07-01 06:01:49,347 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 22
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/MISSING ...
2024-07-01 06:01:49,419 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-07-01 06:01:49,433 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(237)) - HddsDatanodeService host:fv-az1786-697.10u40dmvycxuldx3oogyczyfqh.bx.internal.cloudapp.net ip:10.1.0.20
2024-07-01 06:01:49,434 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-07-01 06:01:49,434 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(293)) - Datanode State Machine Task Thread Pool size 2
2024-07-01 06:01:49,436 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-07-01 06:01:49,436 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds to VolumeSet
2024-07-01 06:01:49,437 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis to VolumeSet
2024-07-01 06:01:49,447 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db to cache
2024-07-01 06:01:49,447 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:loadDbStore(389)) - SchemaV3 db is loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db for volume DS-afa75c00-b616-444c-8afa-8f1e266a329f
2024-07-01 06:01:49,447 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 10ms
2024-07-01 06:01:49,449 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-07-01 06:01:49,450 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:01:49,450 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15042 (custom)
2024-07-01 06:01:49,450 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-07-01 06:01:49,450 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15041 (custom)
2024-07-01 06:01:49,450 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-07-01 06:01:49,450 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15043 (custom)
2024-07-01 06:01:49,450 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-07-01 06:01:49,450 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:49,450 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-07-01 06:01:49,451 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:49,451 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-07-01 06:01:49,451 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-07-01 06:01:49,451 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-07-01 06:01:49,452 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-07-01 06:01:49,452 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-07-01 06:01:49,452 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-07-01 06:01:49,452 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-07-01 06:01:49,453 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-07-01 06:01:49,453 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-07-01 06:01:49,453 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-07-01 06:01:49,453 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-07-01 06:01:49,453 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-07-01 06:01:49,453 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-07-01 06:01:49,453 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-07-01 06:01:49,454 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-07-01 06:01:49,454 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-07-01 06:01:49,454 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15044 (custom)
2024-07-01 06:01:49,454 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:01:49,455 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-07-01 06:01:49,455 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:01:49,455 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb255fc2c] REGISTERED
2024-07-01 06:01:49,455 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis] (custom)
2024-07-01 06:01:49,455 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb255fc2c] BIND: 0.0.0.0/0.0.0.0:15044
2024-07-01 06:01:49,455 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-07-01 06:01:49,455 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb255fc2c, L:/0.0.0.0:15044] ACTIVE
2024-07-01 06:01:49,455 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-07-01 06:01:49,456 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(266)) - 4873639b-1d87-440f-9147-409a0544c1cf: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/tmp
2024-07-01 06:01:49,456 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(271)) - 4873639b-1d87-440f-9147-409a0544c1cf: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/tmp is not a group directory; ignoring it. 
2024-07-01 06:01:49,456 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(266)) - 4873639b-1d87-440f-9147-409a0544c1cf: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6
2024-07-01 06:01:49,456 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - 4873639b-1d87-440f-9147-409a0544c1cf: addNew group-084CCD2B28B6:[] returns group-084CCD2B28B6:java.util.concurrent.CompletableFuture@1f0f60d5[Not completed]
2024-07-01 06:01:49,456 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(266)) - 4873639b-1d87-440f-9147-409a0544c1cf: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:49,457 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(101)) - 4873639b-1d87-440f-9147-409a0544c1cf: addNew group-F848EAF35609:[] returns group-F848EAF35609:java.util.concurrent.CompletableFuture@1b30f7ec[Not completed]
2024-07-01 06:01:49,457 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-07-01 06:01:49,457 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-07-01 06:01:49,459 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-07-01 06:01:49,459 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-07-01 06:01:49,460 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - 4873639b-1d87-440f-9147-409a0544c1cf: new RaftServerImpl for group-084CCD2B28B6:[] with ContainerStateMachine:uninitialized
2024-07-01 06:01:49,460 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:49,461 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:01:49,461 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:01:49,461 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:01:49,461 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15038
2024-07-01 06:01:49,461 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-07-01 06:01:49,463 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:01:49,463 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:01:49,463 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-07-01 06:01:49,463 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:01:49,463 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:01:49,463 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:01:49,463 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-07-01 06:01:49,464 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:01:49,464 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:01:49,464 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:01:49,465 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:01:49,465 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-07-01 06:01:49,465 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:01:49,466 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-07-01 06:01:49,466 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-01 06:01:49,466 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-01 06:01:49,467 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/meta/webserver
2024-07-01 06:01:49,467 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15038
2024-07-01 06:01:49,467 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-07-01 06:01:49,468 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:49,469 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:49,469 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:01:49,469 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:01:49,469 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:01:49,469 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:01:49,470 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(253)) - 4873639b-1d87-440f-9147-409a0544c1cf: new RaftServerImpl for group-F848EAF35609:[] with ContainerStateMachine:uninitialized
2024-07-01 06:01:49,470 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-07-01 06:01:49,470 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-07-01 06:01:49,470 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-07-01 06:01:49,470 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-07-01 06:01:49,470 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-07-01 06:01:49,470 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-07-01 06:01:49,470 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-07-01 06:01:49,471 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2024-07-01 06:01:49,471 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-07-01 06:01:49,471 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-07-01 06:01:49,471 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-07-01 06:01:49,471 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-07-01 06:01:49,471 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-07-01 06:01:49,471 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-07-01 06:01:49,473 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-07-01 06:01:49,473 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-07-01 06:01:49,473 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-07-01 06:01:49,473 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-07-01 06:01:49,473 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-07-01 06:01:49,473 [4873639b-1d87-440f-9147-409a0544c1cf-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-07-01 06:01:49,479 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-07-01 06:01:49,479 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-07-01 06:01:49,479 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-07-01 06:01:49,480 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@45547014{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-07-01 06:01:49,480 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3f72b182{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-07-01 06:01:49,507 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 is not found
2024-07-01 06:01:49,531 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] WARN  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$1(132)) - Failed to remove group group-F848EAF35609 of pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 on peer 4873639b-1d87-440f-9147-409a0544c1cf
java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:99)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:223)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:170)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:98)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:147)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:109)
	at org.apache.ratis.client.impl.GroupManagementImpl.remove(GroupManagementImpl.java:61)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$1(ClosePipelineCommandHandler.java:124)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179)
	at java.base/java.util.HashMap$ValueSpliterator.forEachRemaining(HashMap.java:1779)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:121)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:268)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:249)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:167)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:468)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:172)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:221)
	... 20 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: /127.0.0.1:15042
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.newConnectException0(Errors.java:166)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.handleConnectErrno(Errors.java:131)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Socket.finishConnect(Socket.java:359)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:715)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:692)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:491)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-07-01 06:01:49,538 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: remove    LEADER bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609:t1, leader=bfc6da33-104c-4d07-98ee-1aed7336cdfb, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLog:OPENED:c0:last(t:1, i:0), conf=conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null} RUNNING
2024-07-01 06:01:49,538 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: shutdown
2024-07-01 06:01:49,538 [grpc-default-executor-4] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F848EAF35609,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:49,538 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-LeaderStateImpl
2024-07-01 06:01:49,538 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-07-01 06:01:49,538 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-07-01 06:01:49,538 [grpc-default-executor-4] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:49,539 [grpc-default-executor-4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:49,540 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-F848EAF35609: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/sm/snapshot.1_0
2024-07-01 06:01:49,541 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Completed APPEND_ENTRIES, lastRequest: bfc6da33-104c-4d07-98ee-1aed7336cdfb->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id:"4873639b-1d87-440f-9147-409a0544c1cf"address:"127.0.0.1:15043"dataStreamAddress:"127.0.0.1:15044"clientAddress:"127.0.0.1:15041"adminAddress:"127.0.0.1:15042"startupRole:FOLLOWER, id:"bfc6da33-104c-4d07-98ee-1aed7336cdfb"address:"127.0.0.1:15016"priority:1dataStreamAddress:"127.0.0.1:15017"clientAddress:"127.0.0.1:15014"adminAddress:"127.0.0.1:15015"startupRole:FOLLOWER, id:"bd7a4aed-4c16-4f29-bb4e-36cd0e487b91"address:"127.0.0.1:15025"dataStreamAddress:"127.0.0.1:15026"clientAddress:"127.0.0.1:15023"adminAddress:"127.0.0.1:15024"startupRole:FOLLOWER, old:)
2024-07-01 06:01:49,541 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Completed APPEND_ENTRIES, lastReply: null
2024-07-01 06:01:49,541 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-F848EAF35609: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/sm/snapshot.1_0 took: 1 ms
2024-07-01 06:01:49,541 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:49,541 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:49,541 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:49,541 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:01:49,542 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Completed APPEND_ENTRIES, lastRequest: null
2024-07-01 06:01:49,542 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "bfc6da33-104c-4d07-98ee-1aed7336cdfb"
  replyId: "bd7a4aed-4c16-4f29-bb4e-36cd0e487b91"
  raftGroupId {
    id: "\356d$\366\267$J\374\252F\370H\352\363V\t"
  }
  callId: 14
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-07-01 06:01:49,543 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-07-01 06:01:49,543 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:49,604 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 is not found
2024-07-01 06:01:49,616 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609-SegmentedRaftLogWorker close()
2024-07-01 06:01:49,617 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:49,621 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(112)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: remove  FOLLOWER bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609:t1, leader=bfc6da33-104c-4d07-98ee-1aed7336cdfb, voted=bfc6da33-104c-4d07-98ee-1aed7336cdfb, raftlog=Memoized:bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLog:OPENED:c0:last(t:1, i:0), conf=conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null} RUNNING
2024-07-01 06:01:49,621 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: shutdown
2024-07-01 06:01:49,621 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F848EAF35609,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:49,622 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState
2024-07-01 06:01:49,622 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-FollowerState was interrupted
2024-07-01 06:01:49,622 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:49,622 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-F848EAF35609: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/sm/snapshot.1_0
2024-07-01 06:01:49,623 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-F848EAF35609: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/sm/snapshot.1_0 took: 1 ms
2024-07-01 06:01:49,623 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:49,624 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:49,624 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:49,624 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:49,629 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609-SegmentedRaftLogWorker close()
2024-07-01 06:01:49,630 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(471)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-F848EAF35609: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:49,630 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 command on datanode bd7a4aed-4c16-4f29-bb4e-36cd0e487b91.
2024-07-01 06:01:49,673 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1d9edbad{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/meta/webserver/jetty-0_0_0_0-15038-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-10051396366402898826/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:01:49,674 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7b14192c{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-07-01 06:01:49,674 [main] INFO  server.Server (Server.java:doStart(415)) - Started @97693ms
2024-07-01 06:01:49,674 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-07-01 06:01:49,674 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15038
2024-07-01 06:01:49,675 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-07-01 06:01:49,675 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15039
2024-07-01 06:01:49,676 [Socket Reader #1 for port 15039] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15039
2024-07-01 06:01:49,677 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(321)) - Datanode start with admins: [runner]
2024-07-01 06:01:49,677 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15039
2024-07-01 06:01:49,679 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-07-01 06:01:49,679 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15039: starting
2024-07-01 06:01:49,682 [4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(545)) - Ozone container server started.
2024-07-01 06:01:49,683 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(396)) - Shutting down the Mini Ozone Cluster
2024-07-01 06:01:49,683 [4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-07-01 06:01:49,684 [main] INFO  db.CodecTestUtil (CodecTestUtil.java:gc(50)) - gc 0
2024-07-01 06:01:49,759 [4873639b-1d87-440f-9147-409a0544c1cf-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/meta/datanode.id
2024-07-01 06:01:49,762 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:49,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:49,763 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:49,763 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1), {type: FCR, size: 1}
2024-07-01 06:01:49,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:49,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:49,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:49,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:49,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:49,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:49,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(412)) - Stopping the Mini Ozone Cluster
2024-07-01 06:01:49,860 [main] INFO  om.OzoneManager (OzoneManager.java:stop(2232)) - om1[localhost:15004]: Stopping Ozone Manager
2024-07-01 06:01:49,860 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15004
2024-07-01 06:01:49,861 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:49,861 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15004
2024-07-01 06:01:49,861 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:stop(600)) - Stopping org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer@416a6d16 at port 15007
2024-07-01 06:01:49,862 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(418)) - om1: close
2024-07-01 06:01:49,862 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - om1: shutdown server GrpcServerProtocolService now
2024-07-01 06:01:49,862 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - om1@group-C5BA1605619E: shutdown
2024-07-01 06:01:49,862 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-07-01 06:01:49,862 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2024-07-01 06:01:49,862 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:49,862 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - om1: shutdown server GrpcServerProtocolService successfully
2024-07-01 06:01:49,863 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 12
2024-07-01 06:01:49,863 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(481)) -  applied = (t:1, i:12)
2024-07-01 06:01:49,863 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(482)) -  skipped = 11
2024-07-01 06:01:49,863 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(483)) - notified = (t:1, i:12)
2024-07-01 06:01:49,863 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(484)) - snapshot = (t:1, i:12)
2024-07-01 06:01:49,874 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 12
2024-07-01 06:01:49,875 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 12
2024-07-01 06:01:49,875 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - om1@group-C5BA1605619E-StateMachineUpdater: closing OzoneManagerStateMachine, lastApplied=(t:1, i:12)
2024-07-01 06:01:49,875 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(527)) - Stopping OzoneManagerStateMachine:om1:group-C5BA1605619E.
2024-07-01 06:01:49,875 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(517)) - Stopping OMDoubleBuffer flush thread
2024-07-01 06:01:49,875 [om1-OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(581)) - OMDoubleBuffer flush thread om1-OMDoubleBufferFlushThread is interrupted and will exit.
2024-07-01 06:01:49,875 [om1@group-C5BA1605619E-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - om1@group-C5BA1605619E-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:49,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-07-01 06:01:50,174 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2024-07-01 06:01:50,174 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-om1: Stopped
2024-07-01 06:01:50,174 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service KeyDeletingService
2024-07-01 06:01:50,175 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service DirectoryDeletingService
2024-07-01 06:01:50,175 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service OpenKeyCleanupService
2024-07-01 06:01:50,175 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SstFilteringService
2024-07-01 06:01:50,175 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDeletingService
2024-07-01 06:01:50,176 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service MultipartUploadCleanupService
2024-07-01 06:01:50,176 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDirectoryCleaningService
2024-07-01 06:01:50,177 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1dfdac1f{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-07-01 06:01:50,177 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@157e14f2{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-07-01 06:01:50,177 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:50,178 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5406ce9f{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-07-01 06:01:50,178 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6c8e0773{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:50,183 [main] INFO  rocksdiff.RocksDBCheckpointDiffer (RocksDBCheckpointDiffer.java:close(306)) - Shutting down CompactionDagPruningService.
2024-07-01 06:01:50,186 [main] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1657)) - Shutting down executorService: 'SnapDiffExecutor'
2024-07-01 06:01:50,186 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDiffCleanupService
2024-07-01 06:01:50,187 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(471)) - Stopping the HddsDatanodes
2024-07-01 06:01:50,189 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-07-01 06:01:50,190 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:50,190 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-07-01 06:01:50,191 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds) is shutting down. 
2024-07-01 06:01:50,191 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:50,191 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds, DS-03f05026-6558-4a94-a93b-33a7a73f0436) exiting.
2024-07-01 06:01:50,190 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-07-01 06:01:50,191 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:50,191 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-07-01 06:01:50,191 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds) is shutting down. 
2024-07-01 06:01:50,191 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:50,192 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds, DS-76e85e00-675e-4383-b07b-e58193edac37) exiting.
2024-07-01 06:01:50,192 [ForkJoinPool.commonPool-worker-2] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(418)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: close
2024-07-01 06:01:50,191 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-07-01 06:01:50,192 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-07-01 06:01:50,192 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F: shutdown
2024-07-01 06:01:50,192 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-07-01 06:01:50,192 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:50,192 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-07-01 06:01:50,193 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds) is shutting down. 
2024-07-01 06:01:50,193 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:50,193 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds, DS-205e25c1-5543-4288-a226-6c3910f61994) exiting.
2024-07-01 06:01:50,193 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(418)) - 7c590364-16f9-412e-8d8f-583652a307a8: close
2024-07-01 06:01:50,193 [Thread-1066] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 4873639b-1d87-440f-9147-409a0544c1cf Close channels
2024-07-01 06:01:50,194 [Thread-1065] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 7c590364-16f9-412e-8d8f-583652a307a8 Close channels
2024-07-01 06:01:50,194 [Thread-1067] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb Close channels
2024-07-01 06:01:50,192 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BC378716716F,id=bd7a4aed-4c16-4f29-bb4e-36cd0e487b91
2024-07-01 06:01:50,195 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-LeaderStateImpl
2024-07-01 06:01:50,195 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:50,192 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:50,195 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-07-01 06:01:50,195 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds) is shutting down. 
2024-07-01 06:01:50,195 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:50,195 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds, DS-e1e9d739-af54-44d8-a0ec-81db78888cd6) exiting.
2024-07-01 06:01:50,193 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-07-01 06:01:50,196 [ForkJoinPool.commonPool-worker-3] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(418)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: close
2024-07-01 06:01:50,196 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(418)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: close
2024-07-01 06:01:50,196 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-07-01 06:01:50,196 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown server GrpcServerProtocolService now
2024-07-01 06:01:50,196 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:50,197 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown server GrpcServerProtocolService successfully
2024-07-01 06:01:50,197 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-BC378716716F: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/5b142fd5-bd6f-4167-9b55-bc378716716f/sm/snapshot.1_0
2024-07-01 06:01:50,197 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-07-01 06:01:50,197 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-07-01 06:01:50,197 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown server GrpcServerProtocolService now
2024-07-01 06:01:50,197 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-07-01 06:01:50,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-BC378716716F: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/ratis/5b142fd5-bd6f-4167-9b55-bc378716716f/sm/snapshot.1_0 took: 1 ms
2024-07-01 06:01:50,198 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-07-01 06:01:50,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:50,198 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown server GrpcServerProtocolService successfully
2024-07-01 06:01:50,198 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-07-01 06:01:50,198 [Thread-1076] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 4873639b-1d87-440f-9147-409a0544c1cf Close channels
2024-07-01 06:01:50,198 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:50,198 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A: shutdown
2024-07-01 06:01:50,199 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:50,198 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 7c590364-16f9-412e-8d8f-583652a307a8: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-07-01 06:01:50,199 [Thread-1078] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - d911fb7d-ae06-4770-ac9a-ead30a7876df Close channels
2024-07-01 06:01:50,199 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-888F41E9DE4A,id=bfc6da33-104c-4d07-98ee-1aed7336cdfb
2024-07-01 06:01:50,199 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-LeaderStateImpl
2024-07-01 06:01:50,199 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:50,199 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:50,199 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-07-01 06:01:50,199 [d911fb7d-ae06-4770-ac9a-ead30a7876df-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD: shutdown
2024-07-01 06:01:50,199 [d911fb7d-ae06-4770-ac9a-ead30a7876df-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-730640D1AADD,id=d911fb7d-ae06-4770-ac9a-ead30a7876df
2024-07-01 06:01:50,200 [d911fb7d-ae06-4770-ac9a-ead30a7876df-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-LeaderStateImpl
2024-07-01 06:01:50,200 [d911fb7d-ae06-4770-ac9a-ead30a7876df-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-PendingRequests: sendNotLeaderResponses
2024-07-01 06:01:50,200 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:50,201 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-888F41E9DE4A: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/3861e760-4c8e-4a89-95b5-888f41e9de4a/sm/snapshot.1_0
2024-07-01 06:01:50,201 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-888F41E9DE4A: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/ratis/3861e760-4c8e-4a89-95b5-888f41e9de4a/sm/snapshot.1_0 took: 0 ms
2024-07-01 06:01:50,201 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:50,201 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:50,201 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:50,202 [bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:50,202 [d911fb7d-ae06-4770-ac9a-ead30a7876df-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:50,202 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-730640D1AADD: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/5c411626-cbe8-45ee-a8fc-730640d1aadd/sm/snapshot.1_0
2024-07-01 06:01:50,202 [Thread-1079] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91 Close channels
2024-07-01 06:01:50,202 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-730640D1AADD: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/ratis/5c411626-cbe8-45ee-a8fc-730640d1aadd/sm/snapshot.1_0 took: 0 ms
2024-07-01 06:01:50,203 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater: Took a snapshot at index 0
2024-07-01 06:01:50,203 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-07-01 06:01:50,203 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:50,203 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-07-01 06:01:50,203 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown server GrpcServerProtocolService now
2024-07-01 06:01:50,203 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown server GrpcServerProtocolService successfully
2024-07-01 06:01:50,203 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-07-01 06:01:50,203 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-07-01 06:01:50,204 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-07-01 06:01:50,204 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown server GrpcServerProtocolService now
2024-07-01 06:01:50,205 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown server GrpcServerProtocolService successfully
2024-07-01 06:01:50,205 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-07-01 06:01:50,205 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - d911fb7d-ae06-4770-ac9a-ead30a7876df: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-07-01 06:01:50,207 [d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:50,215 [d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x19100d1b, L:/0.0.0.0:15035] CLOSE
2024-07-01 06:01:50,215 [d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x19100d1b, L:/0.0.0.0:15035] INACTIVE
2024-07-01 06:01:50,215 [d911fb7d-ae06-4770-ac9a-ead30a7876df-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x19100d1b, L:/0.0.0.0:15035] UNREGISTERED
2024-07-01 06:01:50,217 [7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0058c1b0, L:/0.0.0.0:15053] CLOSE
2024-07-01 06:01:50,217 [7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0058c1b0, L:/0.0.0.0:15053] INACTIVE
2024-07-01 06:01:50,217 [7c590364-16f9-412e-8d8f-583652a307a8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0058c1b0, L:/0.0.0.0:15053] UNREGISTERED
2024-07-01 06:01:50,223 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9854b6ad, L:/0.0.0.0:15017] CLOSE
2024-07-01 06:01:50,224 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9854b6ad, L:/0.0.0.0:15017] INACTIVE
2024-07-01 06:01:50,224 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9854b6ad, L:/0.0.0.0:15017] UNREGISTERED
2024-07-01 06:01:50,225 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-7c590364-16f9-412e-8d8f-583652a307a8: Stopped
2024-07-01 06:01:50,227 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x58494ccf, L:/0.0.0.0:15026] CLOSE
2024-07-01 06:01:50,227 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x58494ccf, L:/0.0.0.0:15026] INACTIVE
2024-07-01 06:01:50,228 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x58494ccf, L:/0.0.0.0:15026] UNREGISTERED
2024-07-01 06:01:50,347 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(284)) - Last known sequence number before sync: 22
2024-07-01 06:01:50,347 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(545)) - Syncing data from Ozone Manager.
2024-07-01 06:01:50,347 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(555)) - Obtaining delta updates from Ozone Manager
2024-07-01 06:01:50,347 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(462)) - OriginalFromSequenceNumber : 22 
2024-07-01 06:01:50,350 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "fv-az1786-697/10.1.0.20"; destination host is: "localhost":15004; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy86.submitRequest over nodeId=null,nodeAddress=localhost:15004. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2024-07-01 06:01:50,383 [bd7a4aed-4c16-4f29-bb4e-36cd0e487b91-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - bd7a4aed-4c16-4f29-bb4e-36cd0e487b91@group-BC378716716F-SegmentedRaftLogWorker close()
2024-07-01 06:01:50,384 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-bd7a4aed-4c16-4f29-bb4e-36cd0e487b91: Stopped
2024-07-01 06:01:50,610 [bfc6da33-104c-4d07-98ee-1aed7336cdfb-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-888F41E9DE4A-SegmentedRaftLogWorker close()
2024-07-01 06:01:50,610 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-bfc6da33-104c-4d07-98ee-1aed7336cdfb: Stopped
2024-07-01 06:01:50,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:50,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:50,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:50,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:50,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:50,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:50,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:50,769 [d911fb7d-ae06-4770-ac9a-ead30a7876df-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - d911fb7d-ae06-4770-ac9a-ead30a7876df@group-730640D1AADD-SegmentedRaftLogWorker close()
2024-07-01 06:01:50,770 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-d911fb7d-ae06-4770-ac9a-ead30a7876df: Stopped
2024-07-01 06:01:50,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-07-01 06:01:51,686 [4873639b-1d87-440f-9147-409a0544c1cf-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds
2024-07-01 06:01:51,691 [4873639b-1d87-440f-9147-409a0544c1cf-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds
2024-07-01 06:01:51,694 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-07-01 06:01:51,695 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds
2024-07-01 06:01:51,695 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds
2024-07-01 06:01:51,697 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis
2024-07-01 06:01:51,697 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis
2024-07-01 06:01:51,698 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-07-01 06:01:51,699 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:01:51,699 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15045
2024-07-01 06:01:51,699 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(562)) - Starting XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:51,704 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 1, Number of unhealthy containers found in this iteration : 0
2024-07-01 06:01:51,731 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:01:51,731 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:01:51,731 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis] (custom)
2024-07-01 06:01:51,732 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:01:51,733 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:analyzeAndRecoverStorage(118)) - Read RaftStorageMetadata{term=1, votedFor=4873639b-1d87-440f-9147-409a0544c1cf} from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6/current/raft-meta
2024-07-01 06:01:51,734 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: set configuration conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043]|listeners:[], old=null}
2024-07-01 06:01:51,735 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(296)) - group-084CCD2B28B6: Setting the last applied index to (t:1, i:4)
2024-07-01 06:01:51,737 [IPC Server handler 31 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for fv-az1786-697.10u40dmvycxuldx3oogyczyfqh.bx.internal.cloudapp.net
2024-07-01 06:01:51,737 [IPC Server handler 31 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-07-01 06:01:51,738 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:01:51,738 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:01:51,739 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:51,739 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:01:51,739 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:01:51,740 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:51,740 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:01:51,740 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:01:51,740 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:51,746 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-07-01 06:01:51,746 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-07-01 06:01:51,746 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis] (custom)
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:01:51,748 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:01:51,747 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/in_use.lock acquired by nodename 95295@fv-az1786-697
2024-07-01 06:01:51,748 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:01:51,748 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:01:51,750 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:51,750 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:01:51,750 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:01:51,751 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:01:51,754 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: set configuration conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043]|listeners:[], old=null}
2024-07-01 06:01:51,755 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  storage.RaftStorage (RaftStorageImpl.java:analyzeAndRecoverStorage(118)) - Read RaftStorageMetadata{term=1, votedFor=bfc6da33-104c-4d07-98ee-1aed7336cdfb} from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/current/raft-meta
2024-07-01 06:01:51,755 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: set configuration conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:51,755 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(296)) - group-F848EAF35609: Setting the last applied index to (t:1, i:0)
2024-07-01 06:01:51,756 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-07-01 06:01:51,756 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-07-01 06:01:51,756 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:51,756 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-07-01 06:01:51,756 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-07-01 06:01:51,756 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(175)) - Successfully read 5 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/91926170-46b2-4d66-81ef-084ccd2b28b6/current/log_inprogress_0
2024-07-01 06:01:51,756 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 (append) at position 554
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: start as a follower, conf=conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043]|listeners:[], old=null}
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: changes role from      null to FOLLOWER at term 1 for startAsFollower
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:51,757 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState
2024-07-01 06:01:51,761 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-cacheEviction-AwaitToRun,5,main] started
2024-07-01 06:01:51,761 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(184)) - new 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609
2024-07-01 06:01:51,761 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-07-01 06:01:51,761 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-07-01 06:01:51,762 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-07-01 06:01:51,762 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-07-01 06:01:51,762 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-07-01 06:01:51,762 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-07-01 06:01:51,762 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-07-01 06:01:51,762 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-07-01 06:01:51,762 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-07-01 06:01:51,764 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-07-01 06:01:51,764 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-07-01 06:01:51,764 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-07-01 06:01:51,764 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-07-01 06:01:51,765 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: set configuration conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:51,765 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  segmented.LogSegment (LogSegment.java:loadSegment(175)) - Successfully read 1 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/ratis/ee6424f6-b724-4afc-aa46-f848eaf35609/current/log_inprogress_0
2024-07-01 06:01:51,765 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-07-01 06:01:51,765 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 (append) at position 351
2024-07-01 06:01:51,766 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-084CCD2B28B6,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:51,766 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-084CCD2B28B6,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:51,766 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:01:51,766 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:01:51,766 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:01:51,766 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:01:51,766 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:01:51,766 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:01:51,767 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:51,767 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:51,767 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:start(389)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: start as a follower, conf=conf: {index: 0, cur=peers:[4873639b-1d87-440f-9147-409a0544c1cf|127.0.0.1:15043, bfc6da33-104c-4d07-98ee-1aed7336cdfb|127.0.0.1:15016, bd7a4aed-4c16-4f29-bb4e-36cd0e487b91|127.0.0.1:15025]|listeners:[], old=null}
2024-07-01 06:01:51,767 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(376)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: changes role from      null to FOLLOWER at term 1 for startAsFollower
2024-07-01 06:01:51,769 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 4873639b-1d87-440f-9147-409a0544c1cf: start 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState
2024-07-01 06:01:51,769 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 2
2024-07-01 06:01:51,771 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:51,771 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:51,771 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:51,771 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:51,771 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:51,771 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:51,771 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:51,777 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-07-01 06:01:51,777 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-07-01 06:01:51,777 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F848EAF35609,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:51,778 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-F848EAF35609,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:51,778 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-07-01 06:01:51,778 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2024-07-01 06:01:51,778 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-07-01 06:01:51,778 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-07-01 06:01:51,778 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-07-01 06:01:51,778 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-07-01 06:01:51,780 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(408)) - 4873639b-1d87-440f-9147-409a0544c1cf: start RPC server
2024-07-01 06:01:51,781 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 4873639b-1d87-440f-9147-409a0544c1cf: GrpcService started, listening on 15041
2024-07-01 06:01:51,782 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 4873639b-1d87-440f-9147-409a0544c1cf: GrpcService started, listening on 15043
2024-07-01 06:01:51,783 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 4873639b-1d87-440f-9147-409a0544c1cf: GrpcService started, listening on 15042
2024-07-01 06:01:51,785 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf is started using port 15041 for RATIS
2024-07-01 06:01:51,785 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf is started using port 15042 for RATIS_ADMIN
2024-07-01 06:01:51,785 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf is started using port 15043 for RATIS_SERVER
2024-07-01 06:01:51,785 [4873639b-1d87-440f-9147-409a0544c1cf-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(588)) - XceiverServerRatis 4873639b-1d87-440f-9147-409a0544c1cf is started using port 15044 for RATIS_DATASTREAM
2024-07-01 06:01:51,785 [JvmPauseMonitor8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-4873639b-1d87-440f-9147-409a0544c1cf: Started
2024-07-01 06:01:51,790 [4873639b-1d87-440f-9147-409a0544c1cf-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-07-01 06:01:51,790 [IPC Server handler 32 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-07-01 06:01:51,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-07-01 06:01:52,228 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-205e25c1-5543-4288-a226-6c3910f61994/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-03f05026-6558-4a94-a93b-33a7a73f0436/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-76e85e00-675e-4383-b07b-e58193edac37/container.db]
2024-07-01 06:01:52,229 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-76e85e00-675e-4383-b07b-e58193edac37/container.db from cache
2024-07-01 06:01:52,229 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-5/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-76e85e00-675e-4383-b07b-e58193edac37/container.db for volume DS-76e85e00-675e-4383-b07b-e58193edac37
2024-07-01 06:01:52,229 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-07-01 06:01:52,229 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-07-01 06:01:52,230 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(628)) - Ozone container server stopped.
2024-07-01 06:01:52,238 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@523e0ffb{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:01:52,238 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4dccaef5{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-07-01 06:01:52,238 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:52,238 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@160a5e87{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-07-01 06:01:52,239 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3e650f4{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:52,239 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-07-01 06:01:52,239 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15048
2024-07-01 06:01:52,239 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15048
2024-07-01 06:01:52,239 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:52,242 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-07-01 06:01:52,242 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:52,242 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-07-01 06:01:52,242 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds) is shutting down. 
2024-07-01 06:01:52,242 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-07-01 06:01:52,242 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds, DS-afa75c00-b616-444c-8afa-8f1e266a329f) exiting.
2024-07-01 06:01:52,242 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:shutdownScanner(206)) - On-demand container scanner is shutting down.
2024-07-01 06:01:52,243 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(418)) - 4873639b-1d87-440f-9147-409a0544c1cf: close
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6: shutdown
2024-07-01 06:01:52,243 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(501)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609: shutdown
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-084CCD2B28B6,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F848EAF35609,id=4873639b-1d87-440f-9147-409a0544c1cf
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater: set stopIndex = 0
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(119)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState
2024-07-01 06:01:52,244 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater: set stopIndex = 4
2024-07-01 06:01:52,244 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-FollowerState was interrupted
2024-07-01 06:01:52,244 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:4)
2024-07-01 06:01:52,244 [4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:52,243 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(153)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-FollowerState was interrupted
2024-07-01 06:01:52,244 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-07-01 06:01:52,244 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server GrpcServerProtocolService now
2024-07-01 06:01:52,244 [4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-07-01 06:01:52,245 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server GrpcServerProtocolService successfully
2024-07-01 06:01:52,246 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-07-01 06:01:52,246 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 4873639b-1d87-440f-9147-409a0544c1cf: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-07-01 06:01:52,246 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb255fc2c, L:/0.0.0.0:15044] CLOSE
2024-07-01 06:01:52,246 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb255fc2c, L:/0.0.0.0:15044] INACTIVE
2024-07-01 06:01:52,246 [4873639b-1d87-440f-9147-409a0544c1cf-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb255fc2c, L:/0.0.0.0:15044] UNREGISTERED
2024-07-01 06:01:52,351 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.net.ConnectException: Call From fv-az1786-697/10.1.0.20 to localhost:15004 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy86.submitRequest over nodeId=null,nodeAddress=localhost:15004 after 1 failover attempts. Trying to failover after sleeping for 4000ms. Current retry count: 1.
2024-07-01 06:01:52,389 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-205e25c1-5543-4288-a226-6c3910f61994/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-03f05026-6558-4a94-a93b-33a7a73f0436/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db]
2024-07-01 06:01:52,390 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-03f05026-6558-4a94-a93b-33a7a73f0436/container.db from cache
2024-07-01 06:01:52,390 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-2/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-03f05026-6558-4a94-a93b-33a7a73f0436/container.db for volume DS-03f05026-6558-4a94-a93b-33a7a73f0436
2024-07-01 06:01:52,390 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-07-01 06:01:52,390 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-07-01 06:01:52,391 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(628)) - Ozone container server stopped.
2024-07-01 06:01:52,399 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@f033ec6{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:01:52,399 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@27a18e3b{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-07-01 06:01:52,399 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:52,399 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2aa43b2e{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-07-01 06:01:52,400 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7eecccfb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:52,400 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-07-01 06:01:52,400 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15021
2024-07-01 06:01:52,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:52,401 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15021
2024-07-01 06:01:52,561 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f]
2024-07-01 06:01:52,561 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f, PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609]
2024-07-01 06:01:52,561 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f moved to CLOSED state
2024-07-01 06:01:52,561 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines []
2024-07-01 06:01:52,561 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f moved to CLOSED state
2024-07-01 06:01:52,563 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 5 pipelines in house.
2024-07-01 06:01:52,563 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:01:52,563 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd already exists in Recon pipeline metadata.
2024-07-01 06:01:52,563 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a already exists in Recon pipeline metadata.
2024-07-01 06:01:52,564 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(149)) - Removing invalid pipeline PipelineID=91926170-46b2-4d66-81ef-084ccd2b28b6 from Recon.
2024-07-01 06:01:52,564 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 91926170-46b2-4d66-81ef-084ccd2b28b6, Nodes: 4873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:4873639b-1d87-440f-9147-409a0544c1cf, CreationTimestamp2024-07-01T06:00:37.601Z[Etc/UTC]] removed.
2024-07-01 06:01:52,564 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(149)) - Removing invalid pipeline PipelineID=ee6424f6-b724-4afc-aa46-f848eaf35609 from Recon.
2024-07-01 06:01:52,564 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: ee6424f6-b724-4afc-aa46-f848eaf35609, Nodes: bd7a4aed-4c16-4f29-bb4e-36cd0e487b91(localhost/127.0.0.1) ReplicaIndex: 04873639b-1d87-440f-9147-409a0544c1cf(localhost/127.0.0.1) ReplicaIndex: 0bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:bfc6da33-104c-4d07-98ee-1aed7336cdfb, CreationTimestamp2024-07-01T06:01:10.860Z[Etc/UTC]] removed.
2024-07-01 06:01:52,567 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 7c590364-16f9-412e-8d8f-583652a307a8(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines []
2024-07-01 06:01:52,568 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-07-01 06:01:52,568 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:01:52,569 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd already exists in Recon pipeline metadata.
2024-07-01 06:01:52,569 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a already exists in Recon pipeline metadata.
2024-07-01 06:01:52,613 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-205e25c1-5543-4288-a226-6c3910f61994/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db]
2024-07-01 06:01:52,614 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-205e25c1-5543-4288-a226-6c3910f61994/container.db from cache
2024-07-01 06:01:52,614 [ForkJoinPool.commonPool-worker-3] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-1/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-205e25c1-5543-4288-a226-6c3910f61994/container.db for volume DS-205e25c1-5543-4288-a226-6c3910f61994
2024-07-01 06:01:52,615 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-07-01 06:01:52,615 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-07-01 06:01:52,616 [ForkJoinPool.commonPool-worker-3] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(628)) - Ozone container server stopped.
2024-07-01 06:01:52,623 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@25e58cbd{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:01:52,624 [ForkJoinPool.commonPool-worker-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5fe01354{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-07-01 06:01:52,624 [ForkJoinPool.commonPool-worker-3] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:52,624 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@14f5b751{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-07-01 06:01:52,624 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@510efcb7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:52,625 [ForkJoinPool.commonPool-worker-3] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-07-01 06:01:52,625 [ForkJoinPool.commonPool-worker-3] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15012
2024-07-01 06:01:52,625 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15012
2024-07-01 06:01:52,625 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:52,661 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a]
2024-07-01 06:01:52,661 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode bfc6da33-104c-4d07-98ee-1aed7336cdfb(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a]
2024-07-01 06:01:52,661 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a moved to CLOSED state
2024-07-01 06:01:52,662 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a moved to CLOSED state
2024-07-01 06:01:52,663 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-07-01 06:01:52,663 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:01:52,663 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd already exists in Recon pipeline metadata.
2024-07-01 06:01:52,664 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a already exists in Recon pipeline metadata.
2024-07-01 06:01:52,668 [timer4] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-AppendLogResponseHandler: Failed appendEntries (Repeated 4 times in the last 5.001s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-07-01 06:01:52,668 [timer5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(221)) - bfc6da33-104c-4d07-98ee-1aed7336cdfb@group-F848EAF35609->4873639b-1d87-440f-9147-409a0544c1cf-GrpcLogAppender: Follower failed (request=null, errorCount=14); keep nextIndex (1) unchanged and retry. (Repeated 4 times in the last 5.000s)
2024-07-01 06:01:52,761 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-084CCD2B28B6-SegmentedRaftLogWorker close()
2024-07-01 06:01:52,768 [4873639b-1d87-440f-9147-409a0544c1cf-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(248)) - 4873639b-1d87-440f-9147-409a0544c1cf@group-F848EAF35609-SegmentedRaftLogWorker close()
2024-07-01 06:01:52,768 [JvmPauseMonitor8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-4873639b-1d87-440f-9147-409a0544c1cf: Stopped
2024-07-01 06:01:52,773 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db]
2024-07-01 06:01:52,775 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:generateUnhealthyRecords(483)) - Non-empty container 2 is missing. It has 1 keys and 7 bytes used according to SCM metadata. Please visit Recon's missing container page for a list of keys (and their metadata) mapped to this container.
2024-07-01 06:01:52,776 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db from cache
2024-07-01 06:01:52,776 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-3/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-e1e9d739-af54-44d8-a0ec-81db78888cd6/container.db for volume DS-e1e9d739-af54-44d8-a0ec-81db78888cd6
2024-07-01 06:01:52,777 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-07-01 06:01:52,777 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-07-01 06:01:52,777 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(628)) - Ozone container server stopped.
2024-07-01 06:01:52,778 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:52,778 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:52,778 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:52,778 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:52,778 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-07-01 06:01:52,778 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:52,778 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:52,787 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@18547b0b{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:01:52,788 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@37347be1{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-07-01 06:01:52,788 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:52,788 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2c507e20{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-07-01 06:01:52,788 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7967b127{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:52,789 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-07-01 06:01:52,789 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15030
2024-07-01 06:01:52,790 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15030
2024-07-01 06:01:52,790 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:52,861 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd]
2024-07-01 06:01:52,861 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode d911fb7d-ae06-4770-ac9a-ead30a7876df(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd]
2024-07-01 06:01:52,862 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd moved to CLOSED state
2024-07-01 06:01:52,862 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd moved to CLOSED state
2024-07-01 06:01:52,863 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-07-01 06:01:52,863 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5b142fd5-bd6f-4167-9b55-bc378716716f already exists in Recon pipeline metadata.
2024-07-01 06:01:52,863 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=5c411626-cbe8-45ee-a8fc-730640d1aadd already exists in Recon pipeline metadata.
2024-07-01 06:01:52,864 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(111)) - Pipeline PipelineID=3861e760-4c8e-4a89-95b5-888f41e9de4a already exists in Recon pipeline metadata.
2024-07-01 06:01:52,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-07-01 06:01:53,782 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:53,782 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:53,782 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:53,782 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:53,782 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:53,782 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:53,782 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:53,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-07-01 06:01:54,771 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db]
2024-07-01 06:01:54,772 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db from cache
2024-07-01 06:01:54,772 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/ozone-meta/datanode-4/data-0/hdds/39382029-4984-4217-a702-5cf725356ff5/DS-afa75c00-b616-444c-8afa-8f1e266a329f/container.db for volume DS-afa75c00-b616-444c-8afa-8f1e266a329f
2024-07-01 06:01:54,772 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-07-01 06:01:54,772 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-07-01 06:01:54,772 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(628)) - Ozone container server stopped.
2024-07-01 06:01:54,779 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1d9edbad{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-07-01 06:01:54,780 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7b14192c{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-07-01 06:01:54,780 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:54,780 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3f72b182{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-07-01 06:01:54,780 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@45547014{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:54,781 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-07-01 06:01:54,781 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15039
2024-07-01 06:01:54,781 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15039
2024-07-01 06:01:54,782 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:54,782 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(486)) - Stopping the StorageContainerManager
2024-07-01 06:01:54,782 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1645)) - Container Balancer is not running.
2024-07-01 06:01:54,782 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1782)) - Stopping Replication Manager Service.
2024-07-01 06:01:54,782 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(329)) - Stopping Replication Monitor Thread.
2024-07-01 06:01:54,782 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1654)) - Stopping the Datanode Admin Monitor.
2024-07-01 06:01:54,783 [UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - UnderReplicatedProcessor interrupted. Exiting...
2024-07-01 06:01:54,783 [OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - OverReplicatedProcessor interrupted. Exiting...
2024-07-01 06:01:54,783 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1661)) - Stopping datanode service RPC server
2024-07-01 06:01:54,783 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-07-01 06:01:54,783 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15002
2024-07-01 06:01:54,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(938)) - Replication Monitor Thread is stopped
2024-07-01 06:01:54,787 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15002
2024-07-01 06:01:54,787 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:54,788 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:54,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-07-01 06:01:54,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:54,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-07-01 06:01:54,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-07-01 06:01:54,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-07-01 06:01:54,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-07-01 06:01:54,863 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(883)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-07-01 06:01:54,863 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1669)) - Stopping block service RPC server
2024-07-01 06:01:54,863 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(176)) - Stopping the RPC server for Block Protocol
2024-07-01 06:01:54,863 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15001
2024-07-01 06:01:54,867 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:54,867 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1676)) - Stopping the StorageContainerLocationProtocol RPC server
2024-07-01 06:01:54,867 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15001
2024-07-01 06:01:54,867 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(213)) - Stopping the RPC server for Client Protocol
2024-07-01 06:01:54,868 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15000
2024-07-01 06:01:54,872 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15000
2024-07-01 06:01:54,872 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1683)) - Stopping Storage Container Manager HTTP server.
2024-07-01 06:01:54,873 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@55cc4c61{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-07-01 06:01:54,875 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:54,876 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@46ff1aad{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-07-01 06:01:54,876 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:54,877 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@53da2aec{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-07-01 06:01:54,877 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@54e680fe{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:54,878 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1691)) - Stopping SCM LayoutVersionManager Service.
2024-07-01 06:01:54,878 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1703)) - Stopping Block Manager Service.
2024-07-01 06:01:54,880 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-07-01 06:01:54,881 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-07-01 06:01:54,881 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1727)) - Stopping SCM Event Queue.
2024-07-01 06:01:54,883 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-43b08e6f-fbc8-49de-b9d0-a34c234775b3: Stopped
2024-07-01 06:01:54,885 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1738)) - Stopping SCM HA services.
2024-07-01 06:01:54,885 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(152)) - Stopping RatisPipelineUtilsThread.
2024-07-01 06:01:54,885 [RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(183)) - RatisPipelineUtilsThread is interrupted.
2024-07-01 06:01:54,886 [BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(112)) - BackgroundPipelineScrubber is interrupted, exit
2024-07-01 06:01:54,886 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(128)) - Stopping BackgroundPipelineScrubber Service.
2024-07-01 06:01:54,887 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2024-07-01 06:01:54,888 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2024-07-01 06:01:54,889 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2024-07-01 06:01:54,889 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(148)) - RatisPipelineUtilsThread is not running, just ignore.
2024-07-01 06:01:54,889 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(123)) - BackgroundPipelineScrubber Service is not running, skip stop.
2024-07-01 06:01:54,889 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(128)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2024-07-01 06:01:54,889 [ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(112)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2024-07-01 06:01:54,889 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-07-01 06:01:54,890 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(339)) - Replication Monitor Thread is not running.
2024-07-01 06:01:54,890 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(327)) - Cannot stop Container Balancer because it's not running or stopping
2024-07-01 06:01:54,890 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1773)) - Stopping SCM MetadataStore.
2024-07-01 06:01:54,891 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopRecon(501)) - Stopping Recon
2024-07-01 06:01:54,891 [main] INFO  recon.ReconServer (ReconServer.java:stop(245)) - Stopping Recon server
2024-07-01 06:01:54,896 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1c0db15{recon,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/recon}
2024-07-01 06:01:54,897 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@74e37ad3{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-07-01 06:01:54,897 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-07-01 06:01:54,898 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@f284158{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-07-01 06:01:54,898 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@589c341d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-07-01 06:01:54,899 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-07-01 06:01:54,899 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15009
2024-07-01 06:01:54,907 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15009
2024-07-01 06:01:54,908 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-07-01 06:01:54,963 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(883)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-07-01 06:01:54,964 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping PipelineSyncTask Thread.
2024-07-01 06:01:54,964 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerHealthTask Thread.
2024-07-01 06:01:54,964 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerSizeCountTask Thread.
2024-07-01 06:01:54,964 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(469)) - Stopping SCM Event Queue.
2024-07-01 06:01:54,965 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(477)) - Flushing container replica history to DB.
2024-07-01 06:01:54,967 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:stop(322)) - Stopping Ozone Manager Service Provider.
2024-07-01 06:01:54,967 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:stop(230)) - Stopping Recon Task Controller.
2024-07-01 06:01:54,969 [main] INFO  recon.ReconServer (ReconServer.java:stop(270)) - Closing Recon Container Key DB.
2024-07-01 06:01:54,969 [Recon-SyncOM-2] WARN  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(572)) - Unable to get and apply delta updates from OM.
2024-07-01 06:01:54,969 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(581)) - Obtaining full snapshot from Ozone Manager
2024-07-01 06:01:54,969 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:checkAndValidateReconDbPermissions(646)) - Permissions for Recon DB directory '/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-39382029-4984-4217-a702-5cf725356ff5/recon' meet the minimum required permissions '750'
2024-07-01 06:01:54,970 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-Recon: Stopped
2024-07-01 06:01:54,971 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getOzoneManagerDBSnapshot(404)) - Unable to obtain Ozone Manager DB Snapshot. 
java.net.ConnectException: Call From fv-az1786-697/10.1.0.20 to localhost:15004 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:930)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:845)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1571)
	at org.apache.hadoop.ipc.Client.call(Client.java:1513)
	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy86.submitRequest(Unknown Source)
	at jdk.internal.reflect.GeneratedMethodAccessor117.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362)
	at jdk.proxy2/jdk.proxy2.$Proxy86.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:80)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:339)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceList(OzoneManagerProtocolClientSideTranslatorPB.java:1834)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerSnapshotUrl(OzoneManagerServiceProviderImpl.java:341)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:376)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:551)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:531)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:374)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:422)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:583)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:285)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:600)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:652)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:773)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:347)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1632)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	... 33 more
2024-07-01 06:01:54,971 [Recon-SyncOM-2] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to false.
2024-07-01 06:01:54,972 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(426)) - Failed to obtain a valid DB snapshot from Ozone Manager. This could be due to missing SST files or other fetch issues.
2024-07-01 06:01:54,972 [Recon-SyncOM-2] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from false to false.
2024-07-01 06:01:54,972 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:lambda$startSyncDataFromOM$0(289)) - Sequence number after sync: 0
2024-07-01 06:01:55,059 [shutdown-hook-0] INFO  recon.ReconServer (StringUtils.java:lambda$startupShutdownMessage$0(144)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at fv-az1786-697/10.1.0.20
************************************************************/
